<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ranjitha Rani">

<title>CS 670: Data Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="final_files/libs/clipboard/clipboard.min.js"></script>
<script src="final_files/libs/quarto-html/quarto.js"></script>
<script src="final_files/libs/quarto-html/popper.min.js"></script>
<script src="final_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="final_files/libs/quarto-html/anchor.min.js"></script>
<link href="final_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="final_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="final_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="final_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="final_files/libs/bootstrap/bootstrap-c0367b04c37547644fece4185067e4a7.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">CS 670: Data Science</h1>
<p class="subtitle lead">Network Traffic Analysis for Intrusion Detection</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ranjitha Rani </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>The rise in global cyber threats has heightened the importance of intrusion detection systems in modern network security. With organizations generating massive volumes of network traffic data, developing effective data-driven intrusion detection strategies has become increasingly critical. The UNSW-NB15 dataset is one such comprehensive resource that simulates real-world network traffic, including both normal activity and a wide range of synthetic attacks.</p>
</section>
<section id="data-selection-and-overview" class="level2">
<h2 class="anchored" data-anchor-id="data-selection-and-overview">1. Data Selection and Overview</h2>
<p><strong>Source:</strong> Australian Centre for Cyber Security (ACCS), UNSW Canberra<br>
<strong>Dataset:</strong> UNSW-NB15 Public Dataset</p>
<p><strong>Creator &amp; Purpose:</strong><br>
The dataset was generated by the IXIA PerfectStorm tool in 2015, simulating normal user behavior along with a variety of modern synthetic attack types. It includes raw traffic features and labelled records for supervised learning and analysis of cyber-attacks.</p>
<p><strong>Attributes &amp; Description:</strong><br>
The dataset includes over 2 million network flow records distributed over four CSV files. Each record contains 49 attributes representing:</p>
<ul>
<li><p><strong>Basic connection features</strong><br>
Source/destination IP, port, protocol</p></li>
<li><p><strong>Flow features</strong><br>
Number of packets, bytes, time duration, direction</p></li>
<li><p><strong>Content features</strong><br>
Login attempts, HTTP methods, service requests</p></li>
<li><p><strong>Labelled fields</strong><br>
<code>label</code> (binary), <code>attack_cat</code> (multiclass attack type)</p></li>
</ul>
<p><strong>Challenges and Considerations:</strong><br>
&gt; Some features like <code>is_ftp_login</code> and <code>ct_ftp_cmd</code> require special handling.<br>
&gt; Mixed data types and sparsely populated fields posed representation challenges.</p>
<p>This dataset serves as a strong foundation for detailed exploratory analysis, interactive visualizations, and classification modeling to detect network intrusions.</p>
</section>
<section id="import-libraries" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="import-libraries">Import Libraries</h2>
<p>This section loads all essential libraries used for preprocessing, modeling (classification &amp; regression), interactive visualizations, and evaluation.</p>
<div id="c92baeb0" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Click to show/hide library imports</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, LabelEncoder, OneHotEncoder</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, GradientBoostingClassifier</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression, Ridge, Lasso</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    confusion_matrix, classification_report, average_precision_score,</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve, roc_curve</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas.plotting <span class="im">import</span> scatter_matrix</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing">2. Data Preprocessing</h2>
<blockquote class="blockquote">
<p>The dataset is available in four csv files.</p>
</blockquote>
<section id="merging-dataset-using-features.csv" class="level3">
<h3 class="anchored" data-anchor-id="merging-dataset-using-features.csv">2.1 Merging Dataset using features.csv</h3>
<div id="554d4dac" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_csv(<span class="st">"UNSW-NB15_1.csv"</span>, encoding<span class="op">=</span><span class="st">"ISO-8859-1"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">"UNSW-NB15_2.csv"</span>, encoding<span class="op">=</span><span class="st">"ISO-8859-1"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd.read_csv(<span class="st">"UNSW-NB15_3.csv"</span>, encoding<span class="op">=</span><span class="st">"ISO-8859-1"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>df4 <span class="op">=</span> pd.read_csv(<span class="st">"UNSW-NB15_4.csv"</span>, encoding<span class="op">=</span><span class="st">"ISO-8859-1"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df_features <span class="op">=</span> pd.read_csv(<span class="st">"NUSW-NB15_features.csv"</span>, encoding<span class="op">=</span><span class="st">"ISO-8859-1"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>df1.columns <span class="op">=</span> df_features[<span class="st">'Name'</span>]</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>df2.columns <span class="op">=</span> df_features[<span class="st">'Name'</span>]</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>df3.columns <span class="op">=</span> df_features[<span class="st">'Name'</span>]</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>df4.columns <span class="op">=</span> df_features[<span class="st">'Name'</span>]</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Features:'</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>display(df_features.head())</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>merged_df<span class="op">=</span>pd.concat([df1,df2,df3,df4],ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Merged Dataset:'</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>display(merged_df.head())</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"dataset shape: "</span>,merged_df.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Features:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">No.</th>
<th data-quarto-table-cell-role="th">Name</th>
<th data-quarto-table-cell-role="th">Type</th>
<th data-quarto-table-cell-role="th">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>srcip</td>
<td>nominal</td>
<td>Source IP address</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>sport</td>
<td>integer</td>
<td>Source port number</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>dstip</td>
<td>nominal</td>
<td>Destination IP address</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>dsport</td>
<td>integer</td>
<td>Destination port number</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>proto</td>
<td>nominal</td>
<td>Transaction protocol</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Merged Dataset:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Name</th>
<th data-quarto-table-cell-role="th">srcip</th>
<th data-quarto-table-cell-role="th">sport</th>
<th data-quarto-table-cell-role="th">dstip</th>
<th data-quarto-table-cell-role="th">dsport</th>
<th data-quarto-table-cell-role="th">proto</th>
<th data-quarto-table-cell-role="th">state</th>
<th data-quarto-table-cell-role="th">dur</th>
<th data-quarto-table-cell-role="th">sbytes</th>
<th data-quarto-table-cell-role="th">dbytes</th>
<th data-quarto-table-cell-role="th">sttl</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">ct_ftp_cmd</th>
<th data-quarto-table-cell-role="th">ct_srv_src</th>
<th data-quarto-table-cell-role="th">ct_srv_dst</th>
<th data-quarto-table-cell-role="th">ct_dst_ltm</th>
<th data-quarto-table-cell-role="th">ct_src_ ltm</th>
<th data-quarto-table-cell-role="th">ct_src_dport_ltm</th>
<th data-quarto-table-cell-role="th">ct_dst_sport_ltm</th>
<th data-quarto-table-cell-role="th">ct_dst_src_ltm</th>
<th data-quarto-table-cell-role="th">attack_cat</th>
<th data-quarto-table-cell-role="th">Label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>59.166.0.0</td>
<td>33661</td>
<td>149.171.126.9</td>
<td>1024</td>
<td>udp</td>
<td>CON</td>
<td>0.036133</td>
<td>528</td>
<td>304</td>
<td>31</td>
<td>...</td>
<td>0</td>
<td>2</td>
<td>4</td>
<td>2</td>
<td>3</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>NaN</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>59.166.0.6</td>
<td>1464</td>
<td>149.171.126.7</td>
<td>53</td>
<td>udp</td>
<td>CON</td>
<td>0.001119</td>
<td>146</td>
<td>178</td>
<td>31</td>
<td>...</td>
<td>0</td>
<td>12</td>
<td>8</td>
<td>1</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>NaN</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>59.166.0.5</td>
<td>3593</td>
<td>149.171.126.5</td>
<td>53</td>
<td>udp</td>
<td>CON</td>
<td>0.001209</td>
<td>132</td>
<td>164</td>
<td>31</td>
<td>...</td>
<td>0</td>
<td>6</td>
<td>9</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>NaN</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>59.166.0.3</td>
<td>49664</td>
<td>149.171.126.0</td>
<td>53</td>
<td>udp</td>
<td>CON</td>
<td>0.001169</td>
<td>146</td>
<td>178</td>
<td>31</td>
<td>...</td>
<td>0</td>
<td>7</td>
<td>9</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>NaN</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>59.166.0.0</td>
<td>32119</td>
<td>149.171.126.9</td>
<td>111</td>
<td>udp</td>
<td>CON</td>
<td>0.078339</td>
<td>568</td>
<td>312</td>
<td>31</td>
<td>...</td>
<td>0</td>
<td>2</td>
<td>4</td>
<td>2</td>
<td>3</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>NaN</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>5 rows × 49 columns</p>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>dataset shape:  (2540043, 49)</code></pre>
</div>
</div>
</section>
<section id="identifying-numerical-and-categorical-columns" class="level3">
<h3 class="anchored" data-anchor-id="identifying-numerical-and-categorical-columns">2.2 Identifying Numerical and Categorical Columns</h3>
<div id="d6cec36a" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> merged_df.select_dtypes(include<span class="op">=</span>[<span class="st">'number'</span>]).columns</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> merged_df.select_dtypes(exclude<span class="op">=</span>[<span class="st">'number'</span>]).columns</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"There are </span><span class="sc">{</span><span class="bu">len</span>(numerical_columns)<span class="sc">}</span><span class="ss"> Numerical Columns in the dataset:"</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(numerical_columns)) </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">There are </span><span class="sc">{</span><span class="bu">len</span>(categorical_columns)<span class="sc">}</span><span class="ss"> Categorical Columns in the dataset:"</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(categorical_columns)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 40 Numerical Columns in the dataset:
['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'Label']

There are 9 Categorical Columns in the dataset:
['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'service', 'ct_ftp_cmd', 'attack_cat']</code></pre>
</div>
</div>
</section>
<section id="duplicate-handling" class="level3">
<h3 class="anchored" data-anchor-id="duplicate-handling">2.3 Duplicate Handling</h3>
<div id="56ff1780" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>duplicate_count <span class="op">=</span> merged_df.duplicated().<span class="bu">sum</span>()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Duplicates in dataset: </span><span class="sc">{</span>duplicate_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>total_rows_before <span class="op">=</span> merged_df.shape[<span class="dv">0</span>]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>merged_df <span class="op">=</span> merged_df.drop_duplicates()</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>total_rows_after <span class="op">=</span> merged_df.shape[<span class="dv">0</span>]</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New dataset shape after removing duplicates: </span><span class="sc">{</span>merged_df<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Duplicates in dataset: 480626
New dataset shape after removing duplicates: (2059417, 49)</code></pre>
</div>
</div>
</section>
<section id="missing-data-handling" class="level3">
<h3 class="anchored" data-anchor-id="missing-data-handling">2.4 Missing Data Handling</h3>
<div id="80de914e" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>missing_data <span class="op">=</span> merged_df.isnull().<span class="bu">sum</span>().reset_index()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>missing_data.columns <span class="op">=</span> [<span class="st">"Column Name"</span>, <span class="st">"Total Missing Values"</span>]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>missing_data[<span class="st">"% Missing"</span>] <span class="op">=</span> (missing_data[<span class="st">"Total Missing Values"</span>] <span class="op">/</span> <span class="bu">len</span>(merged_df) <span class="op">*</span> <span class="dv">100</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>missing_data <span class="op">=</span> missing_data[missing_data[<span class="st">"Total Missing Values"</span>] <span class="op">&gt;</span> <span class="dv">0</span>].sort_values(by<span class="op">=</span><span class="st">"% Missing"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>missing_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Column Name</th>
<th data-quarto-table-cell-role="th">Total Missing Values</th>
<th data-quarto-table-cell-role="th">% Missing</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">47</td>
<td>attack_cat</td>
<td>1959771</td>
<td>95.16</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">38</td>
<td>is_ftp_login</td>
<td>1014165</td>
<td>49.25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">37</td>
<td>ct_flw_http_mthd</td>
<td>933603</td>
<td>45.33</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="handling-attack_cat" class="level3">
<h3 class="anchored" data-anchor-id="handling-attack_cat">2.4.1 Handling ‘attack_cat’</h3>
<p>To ensure consistency :</p>
<p>-<strong>Handled Missing Values</strong> – Assigned “unknown_attack” to missing attack labels where label = 1 and “normal” otherwise.</p>
<p>-<strong>Standardized Attack Names</strong> – Trimmed spaces, converted to lowercase, and renamed ambiguous categories (e.g., “dos” → “denial_of_service”).</p>
<p>-<strong>Encoded Categories</strong>– Converted attack labels into numerical values using Label Encoding for machine learning compatibility.</p>
<div id="208f4d39" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Show code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'label'</span> <span class="kw">in</span> merged_df.columns:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    merged_df.loc[(merged_df[<span class="st">'attack_cat'</span>].isna()) <span class="op">&amp;</span> (merged_df[<span class="st">'label'</span>] <span class="op">==</span> <span class="dv">1</span>), <span class="st">'attack_cat'</span>] <span class="op">=</span> <span class="st">'unknown_attack'</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'attack_cat'</span>].fillna(<span class="st">'normal'</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'attack_cat'</span>] <span class="op">=</span> merged_df[<span class="st">'attack_cat'</span>].<span class="bu">str</span>.strip().<span class="bu">str</span>.lower()</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>attack_mapping <span class="op">=</span> {</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dos'</span>: <span class="st">'denial_of_service'</span>,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ddos'</span>: <span class="st">'denial_of_service'</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'worm'</span>: <span class="st">'worm_attack'</span>,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'backdoor'</span>: <span class="st">'backdoor_attack'</span>,</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'recon'</span>: <span class="st">'reconnaissance'</span>,</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fuzzers'</span>: <span class="st">'fuzzing_attack'</span>,</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'attack_cat'</span>] <span class="op">=</span> merged_df[<span class="st">'attack_cat'</span>].replace(attack_mapping)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>le <span class="op">=</span> LabelEncoder()</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'attack_cat_encoded'</span>] <span class="op">=</span> le.fit_transform(merged_df[<span class="st">'attack_cat'</span>])</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Unique values in attack_cat after processing:"</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(merged_df[<span class="st">'attack_cat'</span>].value_counts())</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Encoded values:"</span>)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(merged_df[[<span class="st">'attack_cat'</span>, <span class="st">'attack_cat_encoded'</span>]].drop_duplicates())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Unique values in attack_cat after processing:
attack_cat
normal               1959771
exploits               27600
generic                25378
fuzzing_attack         21795
reconnaissance         13357
denial_of_service       5665
analysis                2185
backdoor_attack         1684
shellcode               1511
backdoors                300
worms                    171
Name: count, dtype: int64

Encoded values:
Name            attack_cat  attack_cat_encoded
0                   normal                   7
19                exploits                   4
21          reconnaissance                   8
56       denial_of_service                   3
57                 generic                   6
2007             shellcode                   9
4989        fuzzing_attack                   5
7278                 worms                  10
17603            backdoors                   2
80022             analysis                   0
1087268    backdoor_attack                   1</code></pre>
</div>
</div>
</section>
<section id="handling-ct_flw_http_mthd" class="level3">
<h3 class="anchored" data-anchor-id="handling-ct_flw_http_mthd">2.4.2 ‘Handling ct_flw_http_mthd’</h3>
<p>To ensure data consistency, we impute missing values in ct_flw_http_mthd (HTTP flow methods) using a data-driven approach:</p>
<p>-<strong>Identified Mode &amp; Median –</strong> The most frequent (mode) and middle value (median) were computed. -<strong>Smart Imputation-</strong>If the mode is 0 and appears frequently, we assign 0; otherwise, we use the median to fill missing values. -<strong>-</strong>This method balances preserving common trends while preventing bias from extreme values.</p>
<div id="ff68d329" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>http_mode <span class="op">=</span> merged_df[<span class="st">'ct_flw_http_mthd'</span>].mode()[<span class="dv">0</span>]</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>http_median <span class="op">=</span> merged_df[<span class="st">'ct_flw_http_mthd'</span>].median()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>fill_value <span class="op">=</span> <span class="dv">0</span> <span class="cf">if</span> http_mode <span class="op">==</span> <span class="dv">0</span> <span class="cf">else</span> http_median</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'ct_flw_http_mthd'</span>].fillna(fill_value, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Filling missing values with: </span><span class="sc">{</span>fill_value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(merged_df[<span class="st">'ct_flw_http_mthd'</span>].describe())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Filling missing values with: 0
count    2.059417e+06
mean     1.188783e-01
std      4.983756e-01
min      0.000000e+00
25%      0.000000e+00
50%      0.000000e+00
75%      0.000000e+00
max      3.600000e+01
Name: ct_flw_http_mthd, dtype: float64</code></pre>
</div>
</div>
</section>
<section id="handling-is_ftp_login" class="level3">
<h3 class="anchored" data-anchor-id="handling-is_ftp_login">2.4.3 ‘Handling is_ftp_login’</h3>
<p>To maintain accuracy while filling missing values in is_ftp_login, :</p>
<p>-<strong>1.Group by Protocol (proto)–</strong> Since FTP-related logins depend on protocol type, missing values are filled using the most frequent (mode) value within each protocol group. -<strong>2.</strong>If no mode exists for a group, we assign 0 (assuming no FTP login). -<strong>3.</strong>The column remains in integer format for model compatibility.</p>
<div id="5ec46cd4" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'is_ftp_login'</span>] <span class="op">=</span> merged_df[<span class="st">'is_ftp_login'</span>].fillna(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    merged_df.groupby(<span class="st">'proto'</span>)[<span class="st">'is_ftp_login'</span>].transform(<span class="kw">lambda</span> x: x.mode()[<span class="dv">0</span>] <span class="cf">if</span> <span class="kw">not</span> x.mode().empty <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_to_binary(df, column):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    df[column] <span class="op">=</span> df[column].fillna(<span class="dv">0</span>)  </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    df[column] <span class="op">=</span> (df[column] <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">int</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>convert_to_binary(merged_df, <span class="st">'is_ftp_login'</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(merged_df[<span class="st">'is_ftp_login'</span>].value_counts())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>is_ftp_login
0    2019733
1      39684
Name: count, dtype: int64</code></pre>
</div>
</div>
</section>
<section id="handling-ct_ftp_cmd" class="level3">
<h3 class="anchored" data-anchor-id="handling-ct_ftp_cmd">2.4.4 ‘Handling ct_ftp_cmd’</h3>
<p>Some rows in the <code>ct_ftp_cmd</code> column contained empty strings instead of numeric values. To ensure consistency and avoid errors during modeling, replace blank entries with <code>'0'</code> and convert the column to integer type.</p>
<div id="9dd467ab" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'ct_ftp_cmd'</span>] <span class="op">=</span> merged_df[<span class="st">'ct_ftp_cmd'</span>].replace(<span class="st">' '</span>, <span class="st">'0'</span>).fillna(<span class="dv">0</span>).astype(<span class="bu">int</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="handling-sport-and-dsport" class="level3">
<h3 class="anchored" data-anchor-id="handling-sport-and-dsport">2.4.5 ‘Handling sport and dsport’</h3>
<div id="ae0d6db8" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'sport'</span>] <span class="op">=</span> pd.to_numeric(merged_df[<span class="st">'sport'</span>], errors<span class="op">=</span><span class="st">'coerce'</span>).astype(<span class="st">'Int64'</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'dsport'</span>] <span class="op">=</span> pd.to_numeric(merged_df[<span class="st">'dsport'</span>], errors<span class="op">=</span><span class="st">'coerce'</span>).astype(<span class="st">'Int64'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="exploratory-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-data-analysis">3. Exploratory Data analysis</h2>
<section id="attack-categorization" class="level3">
<h3 class="anchored" data-anchor-id="attack-categorization">3.1 Attack Categorization</h3>
<p>Before modeling, it’s essential to understand the distribution of attack categories in the dataset. This chart visualizes how network traffic instances are spread across different attack types in the UNSW-NB15 dataset.</p>
<p>This step is important because:</p>
<p><strong>-</strong>It helps identify class imbalance, which can significantly affect the performance of classification models.</p>
<p><strong>-</strong>It highlights which types of attacks are most and least represented, guiding feature engineering, model selection, and evaluation strategies.</p>
<div id="396f5f92" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"attack_cat"</span> <span class="kw">in</span> merged_df.columns:</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    attack_counts <span class="op">=</span> merged_df[<span class="st">"attack_cat"</span>].value_counts().reset_index()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    attack_counts.columns <span class="op">=</span> [<span class="st">"Attack Category"</span>, <span class="st">"Count"</span>]</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> px.pie(</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        attack_counts,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        names<span class="op">=</span><span class="st">"Attack Category"</span>,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        values<span class="op">=</span><span class="st">"Count"</span>,</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        title<span class="op">=</span><span class="st">"Attack Categories Distribution"</span>,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        hole<span class="op">=</span><span class="fl">0.4</span>, </span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"Attack Category"</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    fig.show()</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Column 'attack_cat' not found in the dataset!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
        <script type="text/javascript">
        window.PlotlyConfig = {MathJaxConfig: 'local'};
        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
        </script>
        <script type="module">import "https://cdn.plot.ly/plotly-3.0.1.min"</script>
        
</div>
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script>                <div id="21793c61-72a7-4680-8279-9bf6ad931ee7" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("21793c61-72a7-4680-8279-9bf6ad931ee7")) {                    Plotly.newPlot(                        "21793c61-72a7-4680-8279-9bf6ad931ee7",                        [{"customdata":[["normal"],["exploits"],["generic"],["fuzzing_attack"],["reconnaissance"],["denial_of_service"],["analysis"],["backdoor_attack"],["shellcode"],["backdoors"],["worms"]],"domain":{"x":[0.0,1.0],"y":[0.0,1.0]},"hole":0.4,"hovertemplate":"Attack Category=%{customdata[0]}\u003cbr\u003eCount=%{value}\u003cextra\u003e\u003c\u002fextra\u003e","labels":["normal","exploits","generic","fuzzing_attack","reconnaissance","denial_of_service","analysis","backdoor_attack","shellcode","backdoors","worms"],"legendgroup":"","marker":{"colors":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52","#636efa"]},"name":"","showlegend":true,"values":{"dtype":"i4","bdata":"W+cdANBrAAAiYwAAI1UAAC00AAAhFgAAiQgAAJQGAADnBQAALAEAAKsAAAA="},"type":"pie"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"legend":{"tracegroupgap":0},"title":{"text":"Attack Categories Distribution"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('21793c61-72a7-4680-8279-9bf6ad931ee7');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
<p><strong>Inference</strong>: From the chart, it’s clear that the dataset is highly imbalanced, with “normal” traffic making up 95.2% of the total data. All attack categories combined represent less than 5% of the data, with some categories like worms, backdoors, and shellcode appearing extremely infrequently (less than 0.1%).</p>
<p>This imbalance poses several challenges:</p>
<p><strong>-</strong>Models may bias toward predicting “normal” traffic to achieve high overall accuracy.</p>
<p><strong>-</strong>Rare attacks may be overlooked, resulting in poor recall for minority classes — which is unacceptable in intrusion detection.</p>
<p><strong>-</strong>It may require sampling techniques (e.g., SMOTE, undersampling), or cost-sensitive modeling to improve performance on minority classes.</p>
</section>
<section id="protocol-usage-across-attacks" class="level3">
<h3 class="anchored" data-anchor-id="protocol-usage-across-attacks">3.2 Protocol Usage Across Attacks</h3>
<p>Analysing how frequently each network protocol appears in the dataset, aggregated across all attack types.</p>
<p>This visualization is important because:</p>
<p><strong>-</strong>It helps identify which protocols are most common in both normal and attack traffic.</p>
<p><strong>-</strong>It highlights protocol-based bias in the dataset — models may overfit to common protocols.</p>
<p><strong>-</strong>It informs feature importance — if a protocol is strongly correlated with attacks or normal traffic, it may be a valuable predictive feature.</p>
<div id="23bb1911" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"proto"</span> <span class="kw">in</span> merged_df.columns <span class="kw">and</span> <span class="st">"attack_cat"</span> <span class="kw">in</span> merged_df.columns:</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    proto_counts <span class="op">=</span> merged_df.groupby(<span class="st">"proto"</span>)[<span class="st">"attack_cat"</span>].count().reset_index()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    proto_counts.columns <span class="op">=</span> [<span class="st">"Protocol"</span>, <span class="st">"Count"</span>]</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> px.bar(</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        proto_counts,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">"Protocol"</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">"Count"</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        text<span class="op">=</span><span class="st">"Count"</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        title<span class="op">=</span><span class="st">"Protocol Usage Across Attacks"</span>,</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        labels<span class="op">=</span>{<span class="st">"Protocol"</span>: <span class="st">"Network Protocol"</span>, <span class="st">"Count"</span>: <span class="st">"Number of Occurrences"</span>},</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"Count"</span>,</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        color_continuous_scale<span class="op">=</span><span class="st">"Teal"</span>,</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    fig.update_traces(texttemplate<span class="op">=</span><span class="st">'%</span><span class="sc">{text}</span><span class="st">'</span>, textposition<span class="op">=</span><span class="st">'outside'</span>)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(xaxis_tickangle<span class="op">=-</span><span class="dv">45</span>, height<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    fig.show()</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Columns 'proto' or 'attack_cat' not found in the dataset!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script>                <div id="92d1f141-ef44-41fe-99ec-7f9ad41f5eca" class="plotly-graph-div" style="height:600px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("92d1f141-ef44-41fe-99ec-7f9ad41f5eca")) {                    Plotly.newPlot(                        "92d1f141-ef44-41fe-99ec-7f9ad41f5eca",                        [{"hovertemplate":"Network Protocol=%{x}\u003cbr\u003eNumber of Occurrences=%{marker.color}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":{"dtype":"i4","bdata":"LgAAAC4AAAAuAAAAigAAAC4AAAAuAAAAAhoAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAADMAAAAuAAAAAgAAAC4AAAAuAAAALgAAAC4AAAAuAAAAXwAAAC4AAAAuAAAALgAAAC4AAADyAQAALgAAAC4AAAAuAAAALgAAADYAAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAABVAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAADEAAAAuAAAALgAAAC4AAAAuAAAAUQAAAC4AAAAuAAAALgAAAC4AAAAuAAAAMwAAAHwPAAAuAAAAUQAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAFwAAAAHAAAALgAAAC4AAAAuAAAALgAAAC4AAAC8AQAALgAAADMAAABRAAAALgAAAC4AAAAuAAAAMwAAAC4AAAAuAAAALgAAAC4AAAAuAAAAUQAAAFEAAAAuAAAAmhsWAC4AAAAuAAAALgAAAC4AAAAuAAAA+vgIAAgAAACdEgAALgAAAC4AAAAuAAAAMwAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAA"},"coloraxis":"coloraxis","pattern":{"shape":""}},"name":"","orientation":"v","showlegend":false,"text":{"dtype":"f8","bdata":"AAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAABAYUAAAAAAAABHQAAAAAAAAEdAAAAAAAACukAAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAIBJQAAAAAAAAEdAAAAAAAAAAEAAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAADAV0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAIH9AAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABLQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAQFVAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAIBIQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAABAVEAAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAACASUAAAAAAAPiuQAAAAAAAAEdAAAAAAABAVEAAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABXQAAAAAAAABxAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAwHtAAAAAAAAAR0AAAAAAAIBJQAAAAAAAQFRAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAACASUAAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAABAVEAAAAAAAEBUQAAAAAAAAEdAAAAAAJobNkEAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAPTxIUEAAAAAAAAgQAAAAAAAnbJAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAACASUAAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdAAAAAAAAAR0AAAAAAAABHQAAAAAAAAEdA"},"textposition":"outside","x":["3pc","a\u002fn","aes-sp3-d","any","argus","aris","arp","ax.25","bbn-rcc","bna","br-sat-mon","cbt","cftp","chaos","compaq-peer","cphb","cpnx","crtp","crudp","dcn","ddp","ddx","dgp","egp","eigrp","emcon","encap","esp","etherip","fc","fire","ggp","gmtp","gre","hmp","i-nlsp","iatp","ib","icmp","idpr","idpr-cmtp","idrp","ifmp","igmp","igp","il","ip","ipcomp","ipcv","ipip","iplt","ipnip","ippc","ipv6","ipv6-frag","ipv6-no","ipv6-opts","ipv6-route","ipx-n-ip","irtp","isis","iso-ip","iso-tp4","kryptolan","l2tp","larp","leaf-1","leaf-2","merit-inp","mfe-nsp","mhrp","micp","mobile","mtp","mux","narp","netblt","nsfnet-igp","nvp","ospf","pgm","pim","pipe","pnni","pri-enc","prm","ptp","pup","pvp","qnx","rdp","rsvp","rtp","rvd","sat-expak","sat-mon","sccopmce","scps","sctp","sdrp","secure-vmtp","sep","skip","sm","smp","snp","sprite-rpc","sps","srp","st2","stp","sun-nd","swipe","tcf","tcp","tlsp","tp++","trunk-1","trunk-2","ttp","udp","udt","unas","uti","vines","visa","vmtp","vrrp","wb-expak","wb-mon","wsn","xnet","xns-idp","xtp","zero"],"xaxis":"x","y":{"dtype":"i4","bdata":"LgAAAC4AAAAuAAAAigAAAC4AAAAuAAAAAhoAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAADMAAAAuAAAAAgAAAC4AAAAuAAAALgAAAC4AAAAuAAAAXwAAAC4AAAAuAAAALgAAAC4AAADyAQAALgAAAC4AAAAuAAAALgAAADYAAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAABVAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAADEAAAAuAAAALgAAAC4AAAAuAAAAUQAAAC4AAAAuAAAALgAAAC4AAAAuAAAAMwAAAHwPAAAuAAAAUQAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAFwAAAAHAAAALgAAAC4AAAAuAAAALgAAAC4AAAC8AQAALgAAADMAAABRAAAALgAAAC4AAAAuAAAAMwAAAC4AAAAuAAAALgAAAC4AAAAuAAAAUQAAAFEAAAAuAAAAmhsWAC4AAAAuAAAALgAAAC4AAAAuAAAA+vgIAAgAAACdEgAALgAAAC4AAAAuAAAAMwAAAC4AAAAuAAAALgAAAC4AAAAuAAAALgAAAC4AAAAuAAAA"},"yaxis":"y","type":"bar","texttemplate":"%{text}"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Network Protocol"},"tickangle":-45},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Number of Occurrences"}},"coloraxis":{"colorbar":{"title":{"text":"Number of Occurrences"}},"colorscale":[[0.0,"rgb(209, 238, 234)"],[0.16666666666666666,"rgb(168, 219, 217)"],[0.3333333333333333,"rgb(133, 196, 201)"],[0.5,"rgb(104, 171, 184)"],[0.6666666666666666,"rgb(79, 144, 166)"],[0.8333333333333334,"rgb(59, 115, 143)"],[1.0,"rgb(42, 86, 116)"]]},"legend":{"tracegroupgap":0},"title":{"text":"Protocol Usage Across Attacks"},"barmode":"relative","height":600},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('92d1f141-ef44-41fe-99ec-7f9ad41f5eca');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
<p><strong>Inference</strong>: - From the plot, we can see that TCP, UDP, and ICMP dominate the dataset. Specifically:</p>
<ul>
<li><p>TCP appears more than 1.4 million times, indicating it’s the most common protocol involved in both normal and attack traffic.</p></li>
<li><p>UDP and ICMP follow, with substantial counts.</p></li>
<li><p>All other protocols (e.g., EIGRP, GRE, IPIP, etc.) have very low frequencies — some are almost negligible.</p></li>
</ul>
</section>
<section id="source-vs-destination-port-mapping" class="level3">
<h3 class="anchored" data-anchor-id="source-vs-destination-port-mapping">3.3 Source vs Destination Port Mapping</h3>
<p>This scatter plot maps source ports to destination ports across network flows to visualize traffic patterns. Each dot represents a connection, and color intensity reflects destination port values.</p>
<p>This visualization is important because:</p>
<p><strong>-</strong>It helps identify common port pairs used in the traffic — particularly patterns associated with attack behavior.</p>
<p><strong>-</strong>Certain ports (e.g., 0, 80, 443) are often associated with specific services or vulnerabilities.</p>
<div id="d2bbb295" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"sport"</span> <span class="kw">in</span> merged_df.columns <span class="kw">and</span> <span class="st">"dsport"</span> <span class="kw">in</span> merged_df.columns:</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    top_sport <span class="op">=</span> merged_df[<span class="st">"sport"</span>].value_counts().nlargest(<span class="dv">15</span>).reset_index()</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    top_sport.columns <span class="op">=</span> [<span class="st">"Source Port"</span>, <span class="st">"Count"</span>]</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    fig3 <span class="op">=</span> px.scatter(</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        merged_df.sample(<span class="dv">5000</span>),  </span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">"sport"</span>,</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        y<span class="op">=</span><span class="st">"dsport"</span>,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        title<span class="op">=</span><span class="st">"Source vs Destination Ports Mapping"</span>,</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        labels<span class="op">=</span>{<span class="st">"sport"</span>: <span class="st">"Source Port"</span>, <span class="st">"dsport"</span>: <span class="st">"Destination Port"</span>},</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"dsport"</span>,</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        color_continuous_scale<span class="op">=</span><span class="st">"Viridis"</span>,</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        opacity<span class="op">=</span><span class="fl">0.6</span>,</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    fig3.update_layout(height<span class="op">=</span><span class="dv">600</span>)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    fig3.show()</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Columns 'sport' or 'dsport' not found in the dataset!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.0.1.min.js"></script>                <div id="5599cfce-c562-43f6-8a8b-658a1d2752cf" class="plotly-graph-div" style="height:600px; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("5599cfce-c562-43f6-8a8b-658a1d2752cf")) {                    Plotly.newPlot(                        "5599cfce-c562-43f6-8a8b-658a1d2752cf",                        [{"hovertemplate":"Source Port=%{x}\u003cbr\u003eDestination Port=%{marker.color}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"","marker":{"color":{"dtype":"i4","bdata":"NQAAADUAAAAZAAAA1HEAAFAAAADYFgAALuMAAGU3AABQAAAAmZwAADUAAADJkAAARhQAAGphAAAWAAAAK4oAADUAAABRNgAAZpQAAFAAAABGFAAARhQAADUAAAC7BgAAbwAAABkAAAAsSgAA4RoAAC0VAADqDgAAvBEAADUAAADTRwAAWCAAADUAAACf3AAA5\u002fkAADUAAABGFAAAbwAAAI6TAAAN6QAAy3AAAG8AAABvzQAAUAAAAOMEAACOYQAANQAAABHbAACn1wAAUAAAADUAAADpKgAAoGMAALMAAAAVAAAAUAAAANtwAACzAAAANQAAACQXAAA1AAAARQAAAEMbAABGFAAA6gwAADm9AACzAAAAFQAAAEYUAAD\u002fogAANQAAAFAAAACPAAAANQAAADUAAADopQAAuwYAAMu7AAA1AAAAy3AAADUAAADhGgAANQAAADUAAAA1AAAAUAAAAOoIAABGFAAANQAAAHhJAAA1AAAANQAAADUAAABKlgAANQAAAG8AAABvAAAAPkEAADUAAAAADwAARhQAADUAAAAVAAAAUAAAAG8AAAAhWgAA4RoAABkAAAAZAAAA3GMAABYAAAA1AAAA4RoAAKPeAADM\u002fQAAHqkAAPfpAAA1AAAAgjYAAAAAAABQAAAAeWIAAMsRAABQAAAANQAAACFmAAAZAAAAuXsAAJV7AABvAAAARhQAAEYUAAB8VwAAUAAAAL+aAAA1AAAAswAAADUAAAA1AAAAjwAAAEnUAABi6AAAUAAAAKJPAAAlZAAAtVwAADUAAADhGgAAbwAAAGdKAAA3fwAAFQAAAFAAAAA1AAAAz7MAAE2wAAA1AAAAbwAAABqkAABGFAAAzfMAAMg5AADVOQAAg+sAADUAAABEbAAAuOgAADUAAABvAAAAUAAAAG6XAAA1AAAAUAAAADUAAAA++QAAFgAAAAgCAADhGgAANQAAAG8AAAA1AAAAGQAAADUAAAA1AAAAc+sAAM53AAA1AAAAToUAAEdHAADhGgAANQAAADUAAAAVAAAAc6UAADUAAABeagAAyKMAAIvGAAAVAAAAM6QAAI4FAABvAAAAZ5QAAAXuAACJOwAANQAAABUAAABQAAAAbwAAAEYUAAAVAAAAFgAAAN95AACPAAAA7JAAAI8AAABPFQAAjwAAAOEaAACn0gAACAIAADUAAAA1AAAAlf8AABB\u002fAAA1AAAAFk0AAOEaAAAVAAAANQAAABUAAAA1AAAA4RoAAMmOAAAWAAAANQAAAFAAAABQAAAAZKMAADUAAAA1AAAARhQAAOEaAABQAAAA4RoAADUAAAC1hgAAUAAAAM+mAAA1AAAANQAAAAAAAADhGgAARhQAAP\u002fCAAAYYwAAcC4AAPOKAADZ4AAAGQAAAE3EAAA1AAAAGQAAAC7CAABGFAAA254AAD9pAACPAAAAFxUAAEheAACPAAAANQAAADUAAACPAAAA4RoAAG8AAABPywAANQAAAI8AAABskQAAGQAAAMQeAADhGgAAbwAAADUAAADBXwAANQAAAAgCAACPAAAAAgIAAFAAAABGFAAAFgAAABUAAABvAAAAUAAAAFAAAABX4wAAESYAADUAAAD74gAAvMoAAEYUAABGFAAARhQAAFAAAADhGgAAFQAAAK68AADhGgAAUAAAADUAAAAZAAAANQAAABUAAAA5UgAAFF8AAFAAAABGFAAAogQAAFAAAACzAAAAbwAAABUAAABIbQAAGQAAAEFeAAA1AAAAmbgAAEYUAABogAAAgH0AAN1UAABM7QAAx7UAAIRoAAAfKwAAMdAAADUAAABvAAAAUAAAADUAAAA1AAAA0fcAADUAAAC95wAA2RsAAFAAAADxMQAAEowAAAAAAABQAAAANQAAAG8AAACTUAAAswAAADUAAADEHAAANQAAAAICAACPAAAANQAAANfFAADhGgAAFQAAABiiAABQAAAAUAAAAFAAAABvAAAANQAAAFTlAACPAAAANQAAAG8AAABvAAAAbwAAAG8AAABQAAAAQ9AAABXkAAA1AAAANQAAAIOpAAAZAAAAGQAAADUAAABQAAAAFQAAAPYLAAB8BQAASG0AAPDkAABQAAAANQAAAAAAAABGFAAAcvwAALbBAAD2FAAAmPIAADUAAAA1AAAANQAAAEYUAAA1AAAANQAAALhbAAA1AAAAFQAAAJsWAADhGgAANQAAAAMPAAAUZwAAA4QAAOeTAADhGgAA4RoAAFAAAABvAAAAUAAAAG8AAADhGgAAbwAAAAAAAABGFAAAGQAAAEEiAABQAAAArH0AABYAAABQAAAAjEIAAGAuAAC85gAA4RoAAN7tAABvAAAAUAAAAFAAAACLvQAAvIkAADUAAABV4gAAW1cAAFAAAACPAAAAMOUAALTbAABQAAAAOxQAANPpAAAWAAAANQAAAG8AAACVsQAA3G4AAFAAAABQAAAAzkUAADUAAAC1IgAAbwAAAI8AAABQAAAAFQAAAACXAACWBQAANQAAAGW\u002fAABWnwAAUAAAAKI+AABvAAAA4RoAAEYUAAA1AAAAVEEAAI8AAAA1AAAAFQAAAFAAAAAIAgAA31UAAFAAAAAZAAAAFo8AAMhpAAAWAAAAGQAAAEYUAAA1AAAA4RoAAFAAAAA1AAAAbwAAAFAAAABhsgAAbwAAAPh1AABdmQAANQAAADUAAABQAAAAolAAADUAAAA1AAAAp2kAAFAAAAA1AAAAUAAAADUAAABO8gAAGQAAADUAAAA5JAAAYXQAAI8AAABQAAAAGQAAAHwuAADhGgAApCMAAI8AAABQAAAAFgAAAG8AAADELAAANQAAAFAAAAAAAAAAGQAAAJJsAADhGgAANQAAAC\u002fbAABvAAAAdykAAFAAAACPAAAAFQAAABkAAABLhQAAMQQAAMTMAAAqlgAA9iAAABYAAADhGgAAz1oAADUAAADqEgAAOesAABDqAADyfwAAHXoAAJVcAADhGgAAUVEAAEIfAABzMwAA4RoAAFAAAABIYAAAGQAAADUAAABQAAAAEIQAAL0BAAA1AAAANQAAABkAAAAfkAAAxBMAAOCpAAA1AAAAAAAAAEYUAACJeAAAjwAAAFAAAAAVAAAAUAAAADUAAAAvgwAANQAAAOEaAAA1AAAANQAAADUAAADHbQAANQAAADUAAADNZwAAUAAAADUAAAA1AAAAvQEAAPCoAACYugAACAIAADUAAAAVAAAAqWcAABf5AABZegAAwJEAAM8aAAD8pwAANQAAABUAAABQAAAANQAAACzGAACPAAAA4RoAAMgfAABQAAAAwDkAAEYUAAA+hAAAASIAAADwAADUvQAA4RoAABkAAAACAgAANQAAADUAAAAVAAAAQuAAAKAtAADZNgAARhQAAFAAAAA1AAAAUAAAAPCuAABKWQAAATUAAEYUAABABAAANQAAAFAAAABIwAAAuSoAAIDzAAAVRQAANQAAAC63AACDfQAAGQAAAOEaAAAOfQAAupkAAAAAAABcAwAANQAAADUAAAD7awAAFQAAADUAAAA1AAAA4RoAAJcSAACAiwAAJkkAANPQAABFAAAA4RoAAB8GAADKjwAAAAAAAN\u002fAAABXRQAAjwAAAO5RAABGFAAAZ0kAADUAAABm\u002fwAAxBMAAFAAAAAZAAAANQAAADUAAAA1AAAAGqwAADUAAAA7PAAANQAAADUAAABQAAAANQAAAOEaAAC9sQAA4RoAADUAAAA1AAAAUAAAAG8AAAD68wAANQAAAB7TAABoogAA4RoAAKlhAABGFAAAUAAAAI8AAAB1TgAAwp8AAG8AAAAWAAAAlToAACPQAAAHcAAAki4AADUAAAC7BgAAXMIAAOEaAAA1AAAAhwAAAAAAAAAZAAAANQAAAFAAAABvAAAAEN4AALQsAADhGgAAAAAAAJEuAAAWAAAANQAAAONYAAA1AAAAfs8AADfYAAAZAAAAO\u002f4AADMVAAAFUQAAUAAAADUAAABZwAAARhQAACxMAAA1AAAARhQAABUAAADXTQAA0d4AAOtwAADGNAAAGQAAAEYUAABQAAAAvWEAAOEaAAAhHwAAQc4AAF0yAAAZuwAANQAAAIicAAAWAAAAbwAAADUAAAA1AAAAbwcAAOEaAABQAAAAv9YAAFAAAAAIAgAAll4AAEYUAAAZAAAAj4IAAFAAAAC+6wAA+KMAANN4AAAZAAAAbhIAAJfBAABvAAAAbwAAAEYUAAB\u002f1wAANQAAAOEaAABQAAAAUAAAADUAAABQAAAANQAAAFAAAABOWAAANQAAABYAAADWOwAANQAAAKRFAADhGgAAUAAAAC7yAADGIgAA7pwAAAgCAABRoAAAxz0AADUAAAA1AAAANQAAADUAAACAVQAANQAAAFwDAAA1AAAAFQAAAGPoAAA1AAAANQAAACRyAACShAAAGQAAAP+sAAA1AAAAYsAAACpyAACemwAA4RkAAFdWAABvAAAAr3cAAOEaAABGFAAAJ9cAAN6GAAA1AAAAUAAAADUAAAAcGwAA3UMAADUAAAAcbQAAUAAAACApAABPGwAAUAAAAH2hAAA1AAAANQAAAPZUAAAqIwAAbwAAADUAAAAT1QAAyzMAAEYUAAD4PgAAKdMAADUAAADOjgAAKIUAAHqSAAA1AAAANQAAAFAAAACWYQAAZu4AAJFUAADhGgAA9xQAADUAAAD3QAAANQAAABMOAABQAAAARhQAADUAAAA1AAAAREoAAI8AAAAAAAAA4RoAAHryAAC7dwAAFgAAADUAAABvAAAANQAAABkAAADDvwAAeoAAAOEaAACo7QAAswAAAHvyAABGFAAAFQAAABYAAAAVAAAARhQAAKudAADHdAAAUAAAADUAAADFcgAANQAAAI6BAAAwZwAAk4kAAFAAAACkWgAAE38AADUAAAAiMwAAhaoAAAhpAADJdQAAGQAAAI8AAADhGgAARtsAADUAAAA1AAAAbwAAAG8AAADhGgAAUAAAADUAAABXHgAAguoAAOEaAAAZAAAA4RoAABILAACPAAAA+a0AAHOgAAAZAAAAUdcAAALZAABQAAAANQAAAIvwAAA1AAAAwXgAAA2qAACPAAAA4RoAAAAAAABQAAAANQAAAEKVAAAIAgAAFgAAABkAAAAVAAAAuwYAAM5oAABQAAAAIHoAANK4AABGFAAAbwAAAEYUAAB1WAAARhQAADjEAABxSQAA4RoAAEYUAABQAAAATQcAAD2TAABQAAAAidMAAOEaAACkZAAAGQAAADUAAAA1AAAAtDMAADx8AABvAAAANQAAAFAAAABLxwAAKJ4AADUAAAAytwAANQAAADUAAAA3qwAA4RoAAEYUAACMIwAA+j8AAI8AAAASOwAA\u002f6wAALkfAABvAAAAbwAAADUAAAA+bAAA+eIAAMJLAAD2CwAAbwAAAFAAAAAlLAAAFQAAAISfAABQAAAA2tAAAFAAAAA1AAAAUAAAAAVDAAB7WQAANQAAAFAAAABvAAAA6QYAAG8AAABQAAAAEdoAADUAAABGFAAAUAAAAC\u002fnAABQAAAAjwAAAFAAAABGFAAAUAAAAOEaAABGFAAANQAAADUAAAA1AAAAx1gAAFAAAADfdgAAFgAAALsGAAAFXwAAmR8AADUAAAA1AAAA4RoAAFaZAABQAAAAzO8AAIp0AACzAAAARzQAAG8AAAA1AAAALj8AAOEaAADhGgAA\u002fJwAAEYUAAA1AAAAFQAAABYAAACg1AAA7KkAACv+AABvAAAANQAAAFAAAABQAAAAbgAAAI8AAAAUwAAACAIAAEYUAAC3mwAAGQAAAC5YAAAZAAAA4RcAAOM9AAASjwAAgXYAADUAAABQAAAAUAAAAI8AAAC8DAAANQAAAEYUAADhGgAAUAAAAEYUAABYxAAAbwAAADUAAABGFAAAFgAAADUAAACJhQAANQAAADUAAAA1AAAA1tYAAEYUAADULQAANQAAADUAAADhGgAAnlEAAG8AAADhGgAAFQAAAFAAAAA1AAAAGQAAAOEaAABHcAAAjwAAAFAAAADfpgAAUAAAADUAAAA1AAAABQUAANMOAADhGgAACAIAADUAAABQAAAAqyoAAOEaAADhGgAA49QAABUAAAD6IwAA4xwAADUAAAA1AAAAqioAANkRAABKtAAAGQAAAFAAAACzAAAAw40AAOw4AAA1AAAA4RoAADUAAACPAAAAsH8AADUAAAA1AAAANQAAACEtAAARRwAA4RoAAAJzAAA1AAAANQAAAFAAAADhGgAABkEAADUAAABtdwAA4RoAABkAAAAvwQAANQAAADUAAACzAAAA9a8AAL\u002fjAAA1AAAARhQAAFAAAAA1AAAARhQAADUAAADZlAAAJS0AADUAAABvAAAANQAAAEQrAAB5hAAA4RoAAFAAAABvAAAARhQAAI8AAABcAwAAjwAAAJAkAAA1AAAAAAAAAHLRAAAppgAANQAAAKjEAADhGgAANQAAAOEaAAA1AAAARhQAAGCuAABsRQAA8UAAAOEaAAA1AAAAnqYAADUAAADhGgAA8zIAAKzCAADX5wAAdDIAAEYUAAAPhgAAXUEAAFAAAAA1AAAANQAAAEYUAABIWwAAbwAAADUAAAAZAAAAUAAAABUAAAA1AAAAGQAAAG8AAAAKdgAAX8gAAFAAAABfhgAAGQAAAA3hAAA1AAAAcA8AACz2AABQAAAAU7MAAPzqAAA1AAAAbwAAAEgJAACLcwAARhQAAKdTAABbfgAA4RoAACIyAAA1AAAANQAAAGYFAACBXQAAFQAAABYAAABqsQAAfmMAAGZvAADz5AAAPjMAADUAAABQAAAAAfIAADUAAACYLwAAUAAAAHxKAABvkQAANQAAADUAAADhGgAAGQAAAHrBAAD94wAAbwAAAKmRAABvAAAAAAAAAGwlAAA1AAAAUAAAADUAAABGFAAAUAAAANQaAAA2LwAAGQAAAI8AAAA1AAAAGQAAAMN0AADhGgAA\u002fVwAAI8AAADZvQAAUAAAAGXHAABvAAAANQAAABYAAAA1AAAAI14AABUAAABGFAAA4RoAAJxOAACPAAAARhQAAIkFAABQAAAAFgAAABTKAABcAwAAjR4AADzlAABvAAAAFgAAAF4jAADwmAAANQAAAHXIAAC6CQAANQAAABVAAAA1AAAAuWcAAEYUAABvAAAAAAAAAEYUAABQAAAAbwAAAFAAAAAZFwAAUAAAAFAAAAAkVgAArPgAAOEaAAA1AAAA3XsAALAmAABGFAAAGQcAAI8AAAAAAAAAAgIAAFAAAACPAAAAwy8AAJb\u002fAACqGgAAUAAAADs4AADhGgAAUAAAABkAAADJCgAARhQAAPHmAABvAAAAbwAAAFAAAAA1AAAAy\u002foAADUAAADhGgAANQAAAI8AAABfJwAAFgAAADUAAAA1AAAA4RoAACXTAAA1AAAArx4AAEYUAACzAAAAOjgAAKAtAAA1AAAARhQAAJSyAABntAAA4RoAAOYEAAA1AAAANQAAADUAAAAZAAAA2gQAAFAAAAAWAAAAUAAAADUAAADaaAAANQAAAPe\u002fAAA1AAAANQAAAFAAAAAVAAAAUAAAAJ3lAABvAAAAUAAAABYAAAD7WgAANQAAAFAAAAAWAAAAFgAAADUAAABQAAAA4RoAAD74AABQAAAA2XYAADUAAACZCwAARhQAAOEaAAA1AAAAAgIAAI8AAAA1AAAAQxsAAI8AAAB6owAAjwAAAByoAABQAAAANQAAADUAAAAhpwAARhQAALMAAAC9YQAAFQAAAELAAAA1AAAAx2UAANHnAAA0IwAAdWIAAGiUAABzHwAANQAAAGybAADOYAAA4RoAAKpcAAA1AAAANQAAAKLcAAA1AAAArxYAABDfAABGFAAAcn8AALKbAAA1AAAAzXkAAG8AAACrtgAABtYAAHv\u002fAACHAAAAUAAAANr4AAB\u002fPgAAYW0AAFAAAAA1AAAANQAAAI8AAABQAAAAMS0AAOEaAABrfQAAUAAAAAvCAAAWAAAA\u002f6wAAFAAAAA1AAAA2jYAABUAAACPAAAAbwAAAAAAAADhGgAAswYAABYAAADhGgAA4RoAAM3xAADv0wAANQAAABkAAAD4OgAAjwAAALOsAADhGgAAYG0AAFAAAACPAAAANQAAAFAAAAA1AAAAUAAAADUAAADhGgAAuOAAAFkaAAA1AAAA4RoAAKYHAAA1AAAAVmMAADUAAABQAAAAw3AAADUAAACYZgAANQAAAOEaAAD\u002fGwAAUAAAAPjyAACPAAAAADkAAO93AABvAAAAUAAAAFAAAAD\u002fUAAAtDEAAEYUAABQAAAAUAAAAHmxAAA\u002fFQAAUAAAAOEaAAA1AAAA9d8AAI97AABvAAAANQAAADUAAAA1AAAA4RoAAI8AAABQAAAAmF8AADUAAAD\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\u002fJgAABYAAABuAAAAGQAAAOEaAACD1wAA540AABYAAABQAAAANDoAABkAAADUQgAAbwAAAH6wAAA1AAAANQAAAKPvAAAZAAAA0EgAALMAAABQAAAANQAAADUAAABQAAAANQAAAOX6AAC7BgAAYrUAAPGdAABRlwAAjwAAAG8AAAC5BQAAUAAAAG8AAAAVAAAANQAAABkAAACPAAAANQAAAEYUAABvAAAAUAAAADUAAABGFAAANQAAADUAAAA1AAAAUAAAAI1tAABB+AAANQAAAG8AAAAZAAAAFXwAAEYUAABBbwAAto4AAEYUAAAZAAAANQAAADUAAABQAAAAWjAAABS6AACEdwAA9CsAADQkAAC3ygAAFQAAADUAAABQAAAA4RoAAFAAAADhGgAAyasAAFAAAABoLwAA4RoAAAQXAABQAAAANQAAADUAAADsdgAAJOMAABUAAACcjwAAGQAAAFXVAAA1AAAAGQAAABkAAABJ7AAAbwAAAEYUAACPAAAAbwAAAHqqAACzAAAANQAAAP3VAAA1AAAANQAAAD0MAAA1AAAAaaIAAEYUAAArbwAARhQAAL22AAA1AAAAUdkAAA+2AAA1AAAARhQAAFAAAACIygAAbwAAAEYUAADVvwAAZuQAAG8AAAB1eAAAY6UAAAAAAAA1AAAAFsoAAEYUAAClQQAAGQAAANP7AAAr2gAA4RoAADUAAAA1AAAANQAAAOEaAAA1AAAAidsAAEp8AABZogAANQAAACG0AABGFAAAFgAAAFAAAAAtLgAAkgQAABYAAABvAAAARhQAAMbEAADhGgAAEGcAAL0BAAD7\u002fwAANQAAABkAAADhGgAAbwAAADUAAADE9AAAjwAAAGERAABvAAAAIhQAAOEaAAAWAAAAbwAAAN0vAACXnwAA2ncAAMlNAACPAAAA0qMAALp4AADauQAAqkYAAOEaAABrEQAAxykAABYAAAA1AAAANQAAADUAAAA1AAAAs\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\u002fXAABQAAAANQAAAEYUAACB0wAARhQAADUAAAA8rQAASRIAADUAAAA1AAAA4RoAAFAAAAA1AAAAumoAAAgCAABKcwAAVAcAAJcPAADqDAAANQAAAOEaAAB1UQAAweEAABYAAACzAAAANQAAAEYUAABvAAAAbwAAANB7AADLLAAARhQAAGHLAAAZAAAAsjoAADUAAABlVwAARhQAAOEaAABQAAAANQAAAG+HAABp8AAAqr0AADUAAAAZAAAAVN4AAMBdAABQAAAA7GoAAO9VAADcggAAGQAAANszAABGFAAATHYAABkAAAAMZgAAbwAAAN+HAACd4gAANQAAADUAAABQAAAAUAAAAAlcAAA1AAAANQAAAFAAAAA5XgAA5BwAABYAAACovwAAxAoAADUAAABArwAANQAAAG8AAABGFAAAAAAAAN2NAAAcrwAAswAAAEYUAABQAAAA5lsAAD+lAAA1AAAA4RoAAMdeAABAtQAAuCwAADUAAABGFAAAswAAAEYUAAB4gwAAjwAAABUAAABGFAAACvEAAGkdAACPowAAUAAAADUAAADDjQAAcTAAAIDEAAA0ogAAAAAAADUAAABQAAAAjwAAABYAAAAZAAAAuBYAAOoEAABvAAAAWXEAADUAAABQAAAAVx4AAI8AAAA06QAA9AYAAG8AAABvAAAANQAAAFAAAAAVAAAANQAAAOZbAAA1AAAANQAAAEsaAAC6wQAAFQAAAEoIAAD+hQAA3f0AAFAAAAAVAAAANQAAAFAAAABGFAAAhr4AADUAAADhGgAANQAAAG8AAAAVAAAAkq0AADUAAABvAAAAV9QAANMnAAB8gAAAuwYAAEYUAAAZAAAARhQAAEYUAAAEpgAAG5MAADUAAABvAAAAn1cAAIB9AABvAAAAQwoAAG8AAAA1AAAANQAAAEYUAAAdTwAANQAAABUAAAA1vQAADB0AAEYUAABQAAAA1ccAAOEaAAAVAAAAM9cAAOEaAACzAAAARhQAABkAAAAWAAAAIa0AAEYUAACPAAAA0w4AADUAAAAvXwAAbwAAAG1gAABQAAAAUAAAAN73AAAX0wAAfDgAAFAAAAAE3wAANQAAAIafAAB++QAANUkAAMxyAAAWAAAAjGIAAPwSAAA1AAAAEDEAADUAAAA1AAAANQAAAFAAAABQAAAAeQcAAHqpAAA1AAAAFQAAABkAAAA1AAAAUAAAACeDAAA\u002fUwAA5BcAAGG0AABQAAAAUAAAAB2lAAA1AAAA0RsAAOEaAAA1AAAA36AAAMp9AAA1AAAA4RoAAFvzAAA1AAAANQAAAG8WAADZ4AAA4RoAAEV+AAA1AAAA5hQAAGj2AABGFAAAuwYAAI8AAAA1AAAABkoAALMAAABQAAAANQAAAEYUAADhoQAANQAAALhCAABGFAAAPP8AAFAAAABQAAAAHlQAAEYUAADhGgAAWRwAAF8QAADqBAAAMs0AAJsuAADJBwAA+60AADoTAABvAAAAbwAAAG8AAABGFAAAhOAAADUAAABQAAAARhQAADUAAAA1AAAANQAAAI8AAADj3gAANQAAAFskAAA5DwAAkBIAABkAAAA3OAAA3kMAABYAAAA1AAAAVIIAABYAAAD7EgAARhQAACYLAAAZAAAAAAAAAG8AAABGFAAAAAAAADUAAABQAAAABW4AADUAAADhGgAANQAAALsBAAAfYwAAhvMAAMLpAAAVAAAAFgAAAOEaAABQAAAANQAAAJ4LAABdDQAAUAAAAOAaAAAuwAAAFgAAABkAAAAWAAAAfvkAAG8AAAAkgQAAAAAAAI8AAABvAAAAvQEAAFAAAAAZAAAAT\u002fsAAE7rAACarAAA4RoAAITyAACa9wAAco8AABkAAAD\u002ftgAAFAUAADUAAABGDQAANQAAAI+\u002fAAA1AAAANQAAAG7dAAA1AAAANQAAADUAAABQAAAA70QAADUAAADWYwAANQAAADUAAACpBgAA\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\u002fAAA1AAAA0isAADUAAABGFAAAUAAAADUAAAD2WwAAUAAAAFAAAABumQAAGQAAALG3AAA71QAAUAAAAI8AAAA1AAAAvt8AAE2wAABGFAAAGQAAAHXhAAA1AAAAa3IAADUAAAA1AAAARhQAAIReAAA1AAAAeG8AADUAAAA1AAAANQAAADUAAAA1AAAANQAAABkAAAA8+gAAUKEAADksAAA1AAAAUAAAAI8AAAA1AAAANQAAAGcdAABIUAAANQAAAFAAAACApQAAGQAAAOEaAAA1AAAANQAAABYAAABI6AAAl+sAABRoAAAVAAAA4RoAAPZTAADdQQAANQAAAOEaAAAWAAAANQAAAOEaAAA1AAAANQAAAFAAAAA7OwAAKbIAAFAAAADSaAAAJ2IAAG8AAABQAAAAUAAAAI8AAAA1AAAApp4AAP4XAADlRwAANQAAADUAAADhGgAAFgAAAPkTAAA1AAAAyO8AADUAAACn+gAAbwAAAEYUAACMtQAANQAAAEaaAABQAAAA62YAADUAAAB8wAAAiX0AAFAAAAA1AAAAZOgAAFAAAAAZAAAAbwAAADUAAAA1AAAANQAAAFAAAAA1AAAAjwAAACpuAACcTAAAQwoAAI8AAAADOgAAZUsAAG8AAAC32gAAobIAABkAAABodwAANQAAAEYUAABGFAAANQAAADERAAAZAAAAXXcAADy1AABlzgAAUAAAAFWfAAAL6wAAN\u002fAAAG8AAABvAAAAFQAAAG8AAABGFAAAw18AABYAAAA1AAAANQAAAOEaAAC5gAAAxccAAEiYAACDDgAAFgAAABkAAAAVAAAAXlMAAFAAAAAu2gAAXYoAACn\u002fAAA1AAAAbwAAAFAAAADbrAAA+bwAAG8AAACPAAAA\u002fZkAADUAAABOiwAAklUAAG8AAAD\u002fxQAANQAAABkAAAAWAAAANQAAADekAABQAAAANQAAAD5aAAAjBAAA4RoAAOEaAABQAAAANDgAABYAAAAZAAAAHm0AACD1AAA1AAAAl1EAABxsAACPAAAANQAAAHmTAACPAAAARhQAAGx5AAA1AAAAUAAAAJAlAAA1AAAAM2EAAGb+AAAAAAAApswAAOEaAABvAAAA4RoAAOEaAAA1AAAAktMAAEXuAACPAAAANQAAAHuoAACzAAAANQAAADUAAADhGgAA4RoAAG8AAAA1AAAAGQAAADUAAABQAAAARhQAAEYUAAAVAAAAWoUAAIAFAABQAAAARhQAAP\u002fjAACVOgAAtSIAADUAAABGFAAAMeAAAEYUAABQAAAActYAAMxzAAA1AAAAdLUAAP1qAAA1AAAAOywAAEYUAAAfwQAANQAAAHCAAABQAAAAUAAAADdQAADhGgAAeEkAAG8AAABvAAAARe0AABkAAADKUwAAvAwAAOEaAABQAAAAcu8AAI+QAAAJXgAAGQAAABkAAABQAAAANQAAALm\u002fAAAlngAARhQAAFAAAAAqJwAAWWkAAPT6AAApGgAAULoAAFtDAABqqwAAjwAAAInOAAAZAAAA7GUAAJkfAAA1AAAA+r8AAAgCAAA1AAAAGFwAAAGQAAAWAAAAjg4AAODyAACq4QAAO0wAAC9fAABQAAAANQAAADTIAAA1AAAAZdUAAMesAAAVAAAAckEAAFAAAAA1AAAAAAAAALMAAABQAAAA4RoAADUAAAChKQAAcBoAALsGAAAm3QAANQAAAJuEAAAWAAAAbwAAAEZtAAA1AAAAUAAAADUAAADhGgAAfcMAAIYHAAA1AAAA6mkAAMrMAADhGgAAFgAAABV+AAAVAAAARhQAADUAAAA1AAAAbwAAAONtAAB9UwAAB5YAAKfaAABQAAAAUc0AAEYUAABvAAAAG+UAAOEaAADJNQAA9nUAAI3WAADsGAAANQAAAFobAAA1AAAAILYAAIreAABQAAAAXsgAAA9NAAA1AAAAUAAAAFAAAABQAAAAArYAAI8AAAA1AAAAnyUAAL0BAADJpgAANQAAAFAAAAC9AQAAbwAAAHYPAACc5QAANQAAAG8AAABQAAAA4RoAAEYUAABaKAAAme4AABkAAAARHwAAAAAAABkAAADKnAAAjwAAAOEaAABs1gAACMYAAHVfAAAVnQAANQAAADUAAADTCQAANQAAADUAAABQAAAAUAAAAOzRAABQAAAAFQAAADUAAAAELgAANQAAAG7AAAA1AAAACAIAAGMdAAAZAAAAAu0AAEYUAABQAAAAAQgAABYAAAA1AAAANQAAAOEaAACzAAAAAAAAAOEaAAAAAAAAFQAAAI8AAACPAAAANQAAAMLjAAAVAAAAQb0AAGDnAACzAAAAbwAAAFAAAAAZAAAAqAYAAI8AAABT1gAAbz0AAEYUAADZEQAANQAAAFAAAADZEQAAGQAAAAAAAABLkQAAUAAAAHPUAABQAAAA\u002fHAAAE69AABQAAAAsJ4AAEfPAABvAAAAjwAAAAfUAADCXAAAdXwAAKjyAAA1AAAA2zQAALsGAAAZAAAA2bYAAI8AAAA1AAAANQAAAEYUAAA1AAAAwFIAAFAAAAD7lQAAJysAANG6AADK1AAAUAAAAFAAAAA1AAAA4RoAANnLAAAWAAAAUAAAANAWAADUYwAAlWQAAFyIAAAVAAAAFQAAABkAAABQAAAAMdsAAL0BAAB3sgAARhQAADUAAACEqQAAMhUAAOzaAAAVAAAANQAAADUAAAAAxgAAFgAAAFAAAABvAAAA5z8AAABYAACzPQAAcx8AAEYUAABQAAAAFQAAAEWfAABGFAAAmRgAABYAAABabAAAQlMAAGvcAAA1AAAAUDYAAMylAADPBAAAGQAAAG8AAAA1AAAAQZ8AACc2AACrPQAAbwAAADUAAAAZAAAARhQAAG8AAAAWAAAAVK4AABkAAAA1AAAA4RoAAI8AAAC82QAAAwUAADUAAAA1AAAAswAAAFAAAABvAAAAGQAAADUAAAAVAAAAGQAAADUAAABR2QAAbwAAAPq\u002fAADhGgAANQAAAF7xAADx\u002fQAA8ykAAFAAAAA1AAAAY7sAAG8AAACC3gAANQAAADUAAAAAAAAAfxIAAM0jAADUvQAARhQAADUAAAA1AAAAjc0AABkAAAAAAAAAUAAAACcqAADREwAAGQAAAIG9AAD9vAAAOzwAADUAAABQAAAADlAAABkAAAA4UAAA93kAAOEaAAA1AAAA+k8AAN+xAAC6gQAANQAAAFhCAAB91wAAMQgAAHXhAAA1AAAA3xIAAJG4AABJQQAA\u002fYsAAFAAAAAAAAAAlCUAADUAAACdBwAAjwAAAOEaAAA1AAAANQAAAFAAAAAVAAAAbDYAAJTTAABGFAAA4RoAABYAAAAWAAAAlM8AADUAAAA1AAAA4RoAANUFAAAZAAAANQAAABfAAABGFAAAUL4AAAd7AABQAAAANQAAADUAAABQAAAAp7cAAEYUAABGFAAAWkEAALSGAAA1AAAAUAAAADUAAAA1AAAAUAAAAChLAABvAAAANQAAAIEHAABGFAAA9QUAAAN0AAAVAAAANQAAAFAAAAA1AAAAkkMAAAyJAAA1AAAANQAAAN\u002fEAABQAAAAvw4AALGJAAAkWQAAbwAAADUAAAA1AAAA4C4AAH\u002f9AADWrAAAFgAAANEMAAA1AAAAAAAAADUAAADhGgAANQAAADUAAABiigAA4RoAAEYUAABhKQAA4RoAABXrAAA1AAAA4RoAADUAAABQAAAANQAAADZCAABGFAAARhQAAMdSAABQAAAANQAAAEYUAADdSwAAUAAAADUAAACeBgAAUAAAADUAAAAxzgAARhQAAJf2AAAxhgAAUAAAAFAAAAA1AAAAlo8AADUAAABQAAAANQAAAEYUAABHzwAANQAAADUAAABqeQAAFgAAAI8AAAA1AAAAUAAAAOEaAAADwQAAbC4AABkAAABvAAAARtoAALehAABQAAAAjwAAADUAAAAX1wAA6vMAADUAAAA1AAAANQAAAEYUAAD0OQAARhQAADUAAACzAAAANQAAADUAAADZSAAANQAAAC+gAAA1AAAARhQAADUAAAA1AAAA2g8AADUAAAA1AAAANQAAADUAAAA5kwAAUAAAABYAAABQAAAAUAAAALMAAAAZAAAAQosAABiXAACf0AAAhwAAAJPiAABQAAAAi7MAADUAAAD3\u002fAAA+5UAADUAAAA1AAAAjwAAAOEaAADA1AAARhQAAIgeAAChawAARxgAAKZlAAA1AAAAUAAAADUAAABQAAAAEiUAAGOJAABQAAAANQAAAO2qAADhGgAAGQAAAFMJAACqpgAAv3gAAFAAAABdTwAAUAAAANx6AAAZAAAAUAAAADzOAACsmQAARhQAADUAAADhGgAAnuYAAI8AAADr2AAAqJgAAOEaAABOIwAAZOoAABUAAADhGgAAYR8AAEEgAABQAAAAAAAAAI8AAACPAAAADkAAAJDQAAD6bgAAGQAAAEkGAAC7yQAAtW0AADUAAAAAAAAASj0AAFAAAAD\u002fawAA4RoAAFAAAAB5MgAAxSEAAFAAAAALFAAAbwAAAEYUAAAZAAAANQAAADUAAAA1AAAA4ZMAABYAAADcKwAANQAAAFAAAABz1wAANQAAAOEaAACPAAAAAAAAAF5aAADsKAAAoqwAADUAAAAAAAAANQAAAFAAAABQAAAAy68AAEVgAAA1AAAAFgAAABlJAABJEAAA344AAFAAAAAKQAAAUAAAAKj4AACjIAAAFQAAAFAAAADaQgAAbwAAAOMiAADhGgAANQAAAHAPAABQAAAAGQAAAAgCAAAGnQAAbRwAAG8AAAA1AAAAkIAAADUAAADChgAANQAAALKBAABQAAAACAIAADUAAABQAAAARhQAAHS\u002fAABQAAAAfocAAGsaAABGFAAAGQAAAOEaAABGFAAACw4AALbHAACFZQAANQAAABUAAAAm\u002fwAA0c8AAL8jAABxYQAAAuEAAEYUAAAUUgAAxDgAADUAAAA1AAAANQAAABDzAABQAAAAbwAAADUAAADhGgAAJhIAANtdAACWfwAAaW0AAOEaAABQAAAAGQAAAA3TAAA1AAAA4RoAAC41AAADdwAANQAAAFbcAABQAAAAVIcAAIdkAAA1AAAAwpgAALgZAABvAAAA4RoAAMYgAABbRQAAFQAAABkAAAB+FwAARhQAAPB8AAAHewAA4RoAAI8AAABvAAAAeqUAAFAAAACgrgAAhZ0AAK4rAAA1AAAAFgAAAFAAAADLYAAA4XMAAKVJAAA1AAAAFQAAAHpaAABQAAAAy\u002foAAFAAAABnRAAAujMAALMAAADL0AAANQAAADUAAABGFAAANQAAAFDJAAA1AAAAswAAAG8AAAANvAAA4RoAAFAAAABGFAAA4RoAAEYUAAA1AAAANQAAAGgdAAA1AAAANQAAAG8AAAAVAAAARhQAAPbsAAA1AAAANQAAAG8AAADhGgAANQAAABkAAAA5UgAANQAAADUAAABTbQAAmGYAAGaHAADM3wAA2L0AADUAAAA1AAAAAAAAABYAAABGFAAARhQAAFAAAAA1AAAAFQAAABztAAAVnwAA\u002fLEAAPM6AABQAAAANQAAAB+qAACJUAAAptoAAFAAAACYNwAAxPUAAOEaAADvNgAAkbEAAJX+AAAcfgAAFgAAAG8AAADTRAAAfdIAADUAAAAhkgAAn7YAADUAAADMcwAAUAAAALb\u002fAACO5QAAXOEAABYAAADprAAAjwAAAC+lAABGFAAAutMAAERKAABQAAAAGQAAADUAAADhGgAAh0YAAD2hAAA1AAAA4mEAADUAAABGFAAA+L0AAG8AAAA1AAAAGQAAAAAAAAB2dwAANQAAADUAAABpawAANQAAADUAAABDAAAAz\u002f0AANSeAADWywAA2tAAAKofAAA1AAAA8\u002foAAFAAAAD\u002f+gAANQAAAPWoAAA1AAAAGQAAAFAAAACrZQAAoFcAAIxLAABwDwAAswAAAMGyAABQAAAANQAAAFAAAADhGgAA9zQAAOEaAACPAAAAFQAAAAr+AAAZAAAAjwAAADUAAAC\u002fIwAA2o0AAAAAAABQAAAAGQAAAFAAAAA1AAAAGV0AADUAAABQAAAAAgIAADUAAACurQAAGQAAAOEaAACAYQAANQAAAEYUAAA1AAAAH3kAADUAAABGFAAAZg0AAGTPAAA1AAAAbwAAAG8AAABQAAAAFQAAAFAAAABMCwAARQAAALtDAABGFAAAH7QAAI8AAAA1AAAA4RoAAFAAAAA1AAAARhQAAFAAAAAuKwAAdY4AAAICAABQAAAARhQAAG2NAAAsLQAA4RoAAGflAABGFAAAhGMAADUAAABQAAAARhQAADUAAACTBgAAOb8AAFAAAACPAAAANQAAAL3XAAA1AAAA2n0AAF9sAADhGgAA7R0AADUAAACaKAAANQAAADUAAADhGgAAvJoAAF06AACPDgAAjwAAABUAAABDggAAUAAAAJAfAABGFAAANQAAAEO5AAA1AAAAUAAAAFAAAAAZAAAAwvYAADUAAACzAAAAUAAAAOEaAAD4MgAA9z4AAKqXAABN+QAAmAYAAFxmAAAWAAAAGQAAADUAAACzAAAAFgAAADUAAABa8gAAgtoAAIUdAAAZAAAANQAAAFAAAABvAAAAgV0AAKWUAACLOgAANQAAANeuAADb1gAA+oYAAC8YAAA+SwAANQAAAFAAAAAnfwAAUAAAADUAAACSIQAA4RoAAG8AAABQAAAAFQAAAFAAAACPAAAAuqkAAFwDAAAKuQAADSwAADUAAAAZAAAAr60AADUAAABQAAAAU60AABGzAABQAAAA2MIAADUAAADhGgAAFQAAAHw\u002fAABhQwAAjwAAAMrRAABQAAAAUAAAAOEaAAA1AAAAUAAAAIIYAACsvgAAUAAAADUAAABvAAAANQAAAC4KAABDNgAAsdAAAFpGAAA5fAAANQAAADUAAABGFAAANQAAAOhXAAA1AAAAQJ8AAOEaAAB5DgAANQAAAEYUAAA1AAAAXHwAADUAAABnZwAAbwAAAF81AABQyAAAUAAAAEYUAADhGgAAYVkAAAzRAACiXQAA4RoAAAAAAAAZAAAA7lYAAPdSAABGFAAAh6wAADUAAADhGgAA4RoAAHWWAAA1AAAARPEAADUAAABQAAAARhQAADUAAAA1AAAA3tkAAHMfAABQAAAAvYgAAOYHAABSiAAArroAAI4PAACb7QAAU\u002f0AAJ3UAAAYjQAAUAAAAOnXAADhGgAAR4YAADUAAACs9wAAAAAAABkAAADhGgAANQAAABkAAAA1AAAADcsAAFAAAACunAAAjwAAAL0tAABGFAAAFgAAABkAAABESgAAoR0AAG8AAABssgAANQAAAMdhAAA1AAAAEDcAAEYUAADtFwAA4RoAABkAAADfVgAARhQAAKJKAABvAAAAkqQAAFAAAABUigAANQAAAOEaAAA1AAAAxhIAABUAAAAZAAAANQAAALL4AAC0LgAAt28AAEBFAABQAAAAGhgAAFcFAAA1AAAAOLAAAEYUAAA1AAAAbwAAAH6NAAA1AAAAUAAAADUAAABvAAAARhQAAMOJAABQAAAANQAAADUAAAA1AAAAbwAAADUAAAA1AAAAdnMAAG8AAAAZAAAA4RoAABkAAADmnwAAUAAAAKwLAAA1AAAAjwAAADedAABquAAANQAAAFAAAABQAAAARhQAAJ6zAABLdAAANQAAAOEaAACJbQAAghoAAGvDAADYSAAAJUUAAAdoAAA1AAAAjwAAAGw3AAA1AAAAUAAAAN3IAABGFAAAzuIAAEIvAAA1AAAANQAAADUAAABvAAAA6pYAAEiXAAA1AAAANQAAADUAAAAZAAAAbwAAAFAAAAAaCwAAUAAAADNXAABQAAAANQAAADUAAADr9QAAPMoAAFAAAADIcAAANQAAAH\u002fFAABQAAAANQAAABkAAAA1AAAANQAAAG8AAADezQAAfo0AAI3WAADMTAAAGQAAADUAAAA1AAAANQAAADUAAABQAAAAGQAAAN0PAAA1AAAAUAAAAEC3AAAbMQAANQAAAObNAACPAAAAYLkAAHluAABQAAAAtysAADUAAABQAAAAA6AAABB\u002fAADhGgAARhQAABumAAAAAAAANQAAABkAAACLswAAUAAAAHWpAAC0gAAAD6IAACRjAAAMmQAAUAAAALMAAAA1AAAAjwAAAJQjAAA4OwAAFN4AAKpcAABQAAAA1OUAAG8AAABvAAAANQAAAAZDAADhGgAAXFgAAEshAADRWQAANQAAAI8AAAA1AAAAvMYAADUAAAA2vAAAbwAAAOoMAACavQAAAmwAANxUAABIXgAANQAAAGMpAABGFAAANQAAABkAAABGFAAAbwAAAEh+AAATywAAmwsAAEYUAABSUwAAbwAAABYAAADlQgAA1Z4AAKdIAAA1AAAAtToAAPhlAAAZAAAAigsAABUAAABvAAAAUAAAAN70AAA="},"coloraxis":"coloraxis","opacity":0.6,"symbol":"circle"},"mode":"markers","name":"","showlegend":false,"x":{"dtype":"i4","bdata":"CPcAANlhAAANHwAAtH4AAFr9AACyPAAAiHUAAGtPAACAPQAAaIQAAB7\u002fAADu6wAAgpEAAPNmAABcEwAAZPYAANUqAAAEPAAAbosAAAu1AAAlywAAoOQAAAvuAADHzgAAxBAAADNPAAAS\u002fAAAVPEAAPSxAABJwgAADhAAAE+5AAAtRAAAcKIAABmjAACReAAAO\u002fcAAIMeAACPbAAA+9IAAGyWAAA18QAAxKQAAOnCAAAfHAAAxecAAD0OAAB27AAAXWwAAKJ1AAD3cwAAxnQAAAvJAAAj6AAAdtcAAFj0AAD6sgAAX28AALu5AAATfgAAJTEAAIIeAAD3kgAAJJsAAMC+AACz7wAAQ+EAADQOAAA6ZwAAx3IAAO+PAADNNwAADscAAAWiAAB\u002fHwAAwPYAAJ8kAACiHwAAScEAABAQAAD7jgAAadEAAPmYAACT7wAA\u002fpYAAAXlAAA5sgAABGcAAHMQAAAe\u002fwAAeQcAAAz9AACK0wAAq\u002fwAABMEAABsOAAAjUIAAPt1AAAmPgAAl48AAARcAAB4rgAAae0AAPX8AACpuQAAgPQAAPSfAADEgQAAzD8AAGVIAADBugAA5OIAAD+DAABsKQAAifsAAFWeAACI5QAAdrIAAATwAABQhwAA7esAAAAAAAAIGgAAMdYAAHClAAD3wAAAT7kAAKTLAABCDwAANLwAAOgZAACKqQAAZiQAAL\u002f5AACu8wAAopAAAAQ1AACluQAAzfkAAEOFAADY4AAAHJUAAMlwAAAxVQAAEyEAAKHpAACK7wAA7u0AAGzpAAAdlAAAeI0AAHMEAACduwAAB4AAALFWAADqyQAAOCgAAFcKAACs\u002fgAAwm8AAE8dAAAhyQAAxmMAAI4uAAAkQgAAZRUAAIWhAACW3QAA3bEAAFcqAAApVQAAcXYAAFYzAADMGAAAFg8AAIPKAACL4gAADIIAANASAADwVgAAJSQAAGgIAAADrAAA2QYAABgPAAB2HQAADmIAAInTAAAPrQAAsUEAAJJhAAAUPQAAlsoAAFKGAAC8UwAAQCMAAAhYAAD+3AAAqDYAAIeDAABYbwAAQLEAAFbnAAC9fQAA1iQAAKvSAAAqRAAApqkAANs8AADypQAAKeYAAK\u002foAABCogAAqhgAAJLHAAA6UwAA9UUAAMuoAAD1IAAADIMAALebAACjuwAAo5kAAG+4AACndQAAuFgAADNoAAAruAAAcFQAADPOAABHwQAA5dAAAEe4AACYTAAAWHoAAMT9AAAUBAAATywAAHCZAACgJgAA9S0AAB9BAABuaQAAMiIAAAyxAABhVwAA8ggAAOlcAABokwAAH\u002fgAAM2uAAA64wAA8PgAAAAAAADowAAAoz8AABKrAABu1gAAhaMAALBfAADeNwAAr40AAI7QAABPuQAAitUAABc1AAD\u002ftwAAlVUAAE0tAADClgAAXkkAAITqAABvWAAA3DkAAPbPAABAawAA3\u002fgAAKX3AAANtQAANE8AAI57AAAZVAAAFNoAAIMmAAAEJgAAMb4AAJjoAACuVQAA+PYAAPmLAAC8lAAAkHEAAK72AACmnAAAezgAAJxbAAC2fwAA5QcAAAMgAAAMcQAA3i0AABMEAAAabgAAeoMAAILRAACFkQAAbM0AAINAAACCfgAAdX8AAJapAAAwcgAAAbgAAH97AACqfQAAQ8oAAOwXAADRGgAA4GMAADO9AAA8ywAAyfMAACqBAACv8gAAdIUAAH3DAACBLgAABQ4AANdHAAB1EAAADLEAADaaAAButAAAyQoAACdfAAD\u002f2AAAWBEAAO3cAAB1nwAAaQQAAO3FAADNjgAAQvgAAJdfAABjCgAA\u002fT0AAJIyAACkaQAA6a8AAJ7mAADmOQAAE0EAAAAAAAAxjQAAT7kAAF4dAADj5AAA1KUAAMINAACJrAAAW\u002fAAABheAACeTQAAEwQAAKvfAACYnQAA4LkAAEGfAAAWKQAA4bYAAAGHAAAdhAAA73cAAITtAAAu6wAA00cAAFBUAAB\u002fHwAALCwAALZnAACILgAA+swAACHYAAAoGgAA+hYAABexAABZCwAA0\u002fkAALZ3AADGFAAAjsEAAKvgAABCWAAAIjkAAEheAAAytAAAuXsAAAAAAACPrwAAJ08AAHO+AADfsAAAZMYAAA5YAACt8wAA6wQAAMM3AAC2XQAAHS4AAD3wAACr\u002fwAA5DUAAEIaAABf9wAAWDMAADooAABB2gAA55MAAA3uAACJKQAATHEAAK7MAABD7AAAc+8AAE5YAAClkAAApFcAAAAAAAD4QwAALs4AAFOdAACyDAAAqgUAACUwAACjewAAAI8AANeGAADBYgAA\u002fF0AALarAAADzQAAB7MAAC9hAADkpQAA05EAAKCwAABFfgAAOe0AACkrAABKrAAAsWEAAG3gAAC\u002fcgAA1RwAAM\u002fZAABS0AAASxgAAExhAACeJQAA68oAAPVkAADX\u002fwAAF\u002fkAAAxAAAAfaQAAT5wAACXcAACWdgAAcckAABQ6AADOWgAAEwQAADqnAABM9QAA\u002fS0AAOpEAAAZCgAAQ6EAAEiVAAAjCAAAFYEAAJv5AADLIgAAIioAAFq\u002fAADmeAAACAUAAJMTAADODwAAcGQAAKrbAADm5wAAnjgAAE65AADe9AAATA8AAHOOAADy\u002fAAAu3EAAI9tAADFOAAAfHgAAAu1AADBGAAAWAcAAOsWAAAA9AAAhskAAJ7qAABwQAAA7d0AALY3AAACPAAAc2oAAD81AAD5OAAAPxkAAOq1AABDDwAA+NAAAPpGAABF4wAAnI0AAM2fAAC1lwAAA68AAAbRAAB\u002fHwAAtSQAACUEAAARDAAAzaQAAKYiAAAAAAAAz+oAAOhzAADnGQAAlBoAAGviAAC8PwAApogAAD\u002f0AAAF2QAAWF4AABk2AAAn\u002fgAA5QgAAOeoAACNrwAAEC8AAOTaAAA36QAA4WIAAGLKAAAWpwAAFV8AAHmSAAB0vwAAo3IAABVkAADg3wAAUHcAACYfAACGPgAASH0AAJBBAADyWwAA9QcAABZ6AAB79gAAV0AAAFsmAADYJgAAT7kAAP63AADUjwAAloYAADweAADrEwAAAAAAAJFwAADW7wAALSUAADy0AABQYQAAWNkAAJypAACstwAA9akAAOzLAAAzLAAAtFQAAAaCAADBdwAAop0AANGKAADI8wAAhUwAACKSAADn0gAAlZcAAJocAABNtwAAQCUAAC+YAADLJAAA0tUAACL2AAA2zAAARPkAAKC+AAAZIQAABesAAD3vAABiKgAAngUAADyBAACyMQAAF0cAACg9AABlcQAAfkMAAJz7AABT+gAAHTEAAMHvAACZJAAABNMAAC+0AABo\u002fQAA26AAAMcqAAC7swAAwHEAANIkAAAnkwAAKlEAAK59AAArBAAAM1EAALYvAAD0YAAA\u002fjQAAB31AADwCwAADToAAN9zAABEEwAAoSgAAKZnAACtnwAAa5gAAHa9AAAdzwAAxFMAAM2SAAAUBAAAsioAAAAAAABOzgAA0tMAAMvwAABX3wAAKDMAAIZOAAAMKwAAcU0AAAWnAAA5VAAAykoAADK5AAAOcgAAmjAAABDhAABMTAAAAAAAAJO+AABHUgAAwFEAAJFZAAC6QgAAkP4AADL5AADS5wAAyoYAAIU2AAAwvAAAkQYAABMEAABeVwAAGJQAABwWAAABCgAAZtkAAAKYAACrFgAAUaoAABbXAADKsgAASyIAAGIhAAC2uQAA3+UAAP1OAACRZwAA5CwAABAHAABAzQAABGYAAC51AADBugAATDkAAEn0AABgVwAAjdsAAGTTAACSDQAAI4wAAGXUAAD5dgAA688AAE+5AAD4GgAAvKkAADsYAACRFgAAnNMAAAAAAAB+NgAAEwQAAOmWAABgVQAAFHcAALnoAAAregAAAAAAAO1dAABdVQAAqgUAAOHzAAATBAAAPLQAABR9AAB0IQAA5OUAAIymAAAVWwAA1M0AAOLaAACpxQAAX6gAAMgEAACjlQAAfBUAAIu+AAAS\u002fAAAZ6cAAD\u002fKAAAJPAAAvSMAAMkKAAChdwAAh\u002fAAAKzWAAATkQAAT7EAABGGAACnpAAANqYAANI4AACSDwAAKX4AAH7HAAAJBgAAkesAAAZ6AAC+OwAAm9YAAKryAAAk6wAAU+8AANSgAAAe7QAAUbYAAMLYAABIJwAAsTcAAIEVAAABkQAAKDMAAL+cAABrfgAABO4AAMlKAABYKwAAF88AAFCbAAAiSgAAW40AAE+5AACCsAAAifoAALwEAAAG6QAAAT4AANvUAABXSwAAbKYAAIOiAAA+3wAAGrMAAIPbAAAPhgAAzvQAAKnsAADbBAAA444AAEMMAADNeAAAPiQAAL9YAABfewAAllYAABzxAACOtwAAJ4IAANrvAADFRgAAQzYAAAt5AAA1kwAACewAAMhOAACwqwAAScEAAJuDAACHoAAADiIAAHReAADgjgAAoNcAAJUYAADv0QAA8cUAAClCAACQdQAA\u002frIAACHzAACNrwAAkPcAAAYKAACEeQAA5MgAAJf\u002fAACtIgAAmcUAAAg0AACp5gAAWGUAAF3uAAA+lwAAskMAAFfIAAAtQwAAcS0AAKxSAADlcQAAzMwAAEDeAAAhPQAAxkQAAIVFAABVTAAARZIAAJSYAACfaQAATVwAAPhbAAARPQAA+KkAAJnoAAAj9QAAp+IAAC+tAADv+AAAgYQAANg7AABPuQAAWHAAAJYoAAAAAAAAJDwAAB3vAAD8fwAANzsAAE+5AADXmwAAnxsAAHffAACrqQAAonsAAMiHAAAp1gAAy\u002fcAAGCyAACI1AAAcHEAAHA3AACDzgAASqoAAMKNAAAgsgAADOkAAPmCAADbDgAAWWUAAGa1AAC+YwAA\u002fTwAAIi2AAA87gAAE7gAAGCkAAC98QAAeRsAAJWrAAC5egAAJjsAAN09AACXpgAA0m4AAPlCAABPuQAAjsQAANW1AABHlgAABNcAAJlHAAA6xAAAbtsAAJWLAACOwAAAR7EAABG\u002fAAD6IAAAhZUAAPn4AAD+zwAAb3QAAENsAABqiQAAV6MAALfuAADMiwAAehMAAP4dAAD5BgAAd6EAAAAAAADvGQAAJ6IAAFcxAAAluQAAswcAAPJHAAB8UQAAkBcAAExwAAC8wQAA9skAALqrAACblQAAnFoAAAWsAACNSgAAKBkAAIl4AABeUQAAeYUAAHLpAAA35wAAAAkAAOD6AADaKQAA3gcAABCsAADB2QAAjj8AAJaWAACmpAAA6\u002fkAACprAADLJwAAT7kAAB7uAAA3gQAAJYsAADVUAACRpAAAFQYAAKdgAACCHgAA\u002fnAAAL8sAAArlwAAO0kAAOUmAADTQgAAHE8AAFwnAACioQAAT6IAAOnHAACDewAA47kAADjsAABwhwAA65IAADUcAADGjgAALngAAMeHAADXuwAAEH8AANLwAADfXAAApAoAAGD1AAAi8gAAa+sAACQJAADfPwAAGBQAAIFOAAA7FwAA2VQAAKoXAABBfgAApOYAABB2AAA9hAAAZCIAAKIIAABwSgAAQsgAALEUAAAaggAA1kMAAABJAAAWGgAAAV0AAEriAAAK0wAAAx8AACufAABN5wAAXpQAABMEAAAwvwAAYbgAACCWAAAcGwAADuAAADbeAACwwwAAWIcAAOuLAACV7gAAmegAAE4YAAClVQAAbzkAAEWKAAA4pgAAoSMAAM15AACDvgAAtREAAK3lAAC8HwAAZjoAADHQAAB\u002fxgAA4swAAOP6AABBFAAAjMIAAKOjAACSogAA6\u002fsAAJ3sAABcdAAAv5sAACxBAADsSgAAbNIAALMKAAA+4gAAVcIAAF+JAACI3gAAPYAAABNQAACSSwAAbGIAAIzJAACzzAAAwnAAABMEAAAC\u002fwAAG2sAAKdjAAAPwwAAK1kAAEJOAAATBAAAeWcAAAdkAADgiQAAT7kAAL8EAAA9ZgAAKUcAABEYAABreAAA5IwAAOX3AABzxQAAL\u002fMAAFEbAACBqwAAbGQAAECaAAAQmAAA9pYAACnYAAA3WwAAk1UAAMCqAACvVAAA3m8AADnVAADihAAAxpEAAAB1AACVjwAA38MAADFHAAAzlQAAGfIAAF+pAADpDgAAJJwAAMQTAACMGwAAArMAAABeAAAGfgAAsM4AAHZXAADNgQAAIRMAADhEAABGFgAADbQAAGdiAACuYQAA8FQAAJ0YAAAT\u002fAAACusAAAV4AABkqAAAgYwAAAI6AAD\u002fcQAA3msAALw4AAAhIgAA3foAABLlAABgvQAA+HUAAPwzAADCZgAAhaAAADR9AACi+AAACzwAALCKAABDNwAASt4AAF8YAACHnAAA3J0AAGKbAADKXAAAW8EAAJ8yAABoOwAAO3cAADDAAACxuQAAaLwAAIVYAADEzQAAyb0AABigAABsZgAAAAAAAF2DAADKLQAACEIAALp\u002fAAAZfwAAYBgAAK3hAACYUgAA6FYAAItFAAAiyQAAhUEAAPltAAAAWgAAxiIAAL6ZAABChwAAgqAAAI\u002fNAADmYwAAwvIAALqWAABM9AAA2PQAAIDnAABTkQAAsloAALUcAAA51AAA1YkAABR4AABL\u002fwAAAIAAAIdLAACU1AAAoqIAAPudAADnCAAA4H0AABOtAACiOwAAWW0AABYAAAAMOwAAJQYAAOX7AADTwAAAqZoAAFLzAAABqgAAla0AALW8AABubgAAKYcAAFmOAACtzwAAMoEAAApIAACcMQAANjkAAOy6AAAYuwAA0wgAAOZtAADjmwAAbmsAABXLAACpygAAUDgAADFvAAAmMQAAFXQAAA0FAAB7iAAAVH4AADRKAABn7wAAWgUAAEuaAADNXgAAuakAABixAADBzgAAY0wAABBCAABWYAAAAAAAAAKJAAD9hQAAsbwAALQhAAAkmQAApDIAAAkhAAANiwAA08MAADR0AACUGAAA9fYAAErRAADdHwAAXWEAAJCyAABJpgAA1OgAAMLZAAAEvQAAJAkAAKhqAABGNgAA+FoAAJmZAACVlwAAV+gAAHRUAABu8QAAsKAAAAA8AABvZwAAj0YAADp+AAAy1AAAnJkAAN\u002fsAACdXgAA\u002fHoAAK6ZAAAaIAAA97MAALDHAADLwgAARdYAAA30AACHlwAASXAAABF2AAC2yAAAAAAAAPJWAAD25AAAsIsAAJvgAABMHwAATcwAABB3AADdUwAAcVkAAIqrAAApRwAArsUAAPb6AAA3sQAATOoAAD67AAAAAAAAFWcAAG10AADqHwAA8ooAAMNEAAD8hgAAaIMAALM9AADOEAAAeLYAABVIAAAvvQAAFBAAALhqAAD0MQAAE94AALvUAACN+wAANS4AAOh4AAAVfAAAcL4AAAEFAABPowAAmjwAAKk4AAATBAAAUo4AAIiBAABY2wAAfVYAAB6bAACUCAAAbZMAAJMLAABMaQAAbzIAABCaAABhvQAAIDYAAN1OAACOBQAAuhkAAKqNAABT7wAAubEAAJIcAAA+PAAAmJQAAE+5AABavQAAP+4AAP+FAAAp\u002fAAAEwQAAFncAACtoQAA+AkAAECeAADLfgAAqgQAAKfzAAAs1AAA6UoAAKOlAACqCwAAv48AABvWAAD4RwAA3UAAAEOMAACkMgAAsXMAAAUEAABzJQAAhL0AAA72AACX3AAAtGkAAJHYAADeQAAAgFsAAHFkAACWOgAAq8gAAGqmAAB6NAAAAwsAANuXAACyIAAAwHQAAF9gAABXbgAAMSMAAB4YAADubAAA\u002fLkAAJ7jAAAExAAA09wAANxMAADUZwAAI1kAANYsAAB3ZQAAf\u002fAAAOgrAABPuQAA88EAAEx4AAAo6AAAVbAAAJ1xAAA8BQAAP8EAAIqhAAB+wAAAzYAAACurAAATwQAAet0AAJzQAABqMwAA0x8AAP+LAADDRwAAQOEAAG9tAADe2gAADXsAAPVxAADQqAAAb4kAAId3AADZBQAAwuAAAEsWAAD4LQAAu7wAAMhiAABqXQAA7ocAAGEKAACb9AAAmsIAAAAAAAAFQQAA\u002f1MAAOf6AADoygAAcFUAAIxiAAAouwAA6SEAAMIqAAC19AAAA48AAA4vAAAB3AAA+MgAAKikAADYXgAATyQAAMB5AACJ0AAAt9cAAPPUAAC6XwAAb2sAACfPAAC1EgAAR2wAAPhcAACiYAAAPNoAABW8AAB+SQAAcF4AAEsJAACuZAAAxEwAAF2ZAABMpwAAJrUAADdkAADZrwAAX44AAJp\u002fAAAGdwAA4mkAAKh4AABvaQAAdUYAAJmsAADryQAAay0AANYdAAB8pwAAARkAAKV+AAAlaQAAzMcAAE4RAADZNgAAT7kAABaqAAAYYAAASNIAAIDSAACvZgAAaLoAAI5bAAB5JAAAxsQAAD7sAAA+1gAAEHcAAJixAACjZwAA+vEAAOORAABTfwAA9qIAAFUJAABZNQAARDEAALqkAACaiwAAiyQAAFCZAAAcKAAAkw8AABgiAADf0QAAzR8AAOpfAAD70wAAtgUAAJYnAABXowAAgTUAABDvAAAKtAAA5Q0AACHOAADpnwAAT7kAAFfDAADTZAAAf4oAAHthAAC2LwAA6doAACHNAABVwwAAg0AAANumAAAIvgAATGoAAD1yAAAKQgAAjHsAAFjKAAC6YAAAI1kAAFNYAACgEQAAN2MAAFFkAACOcAAA+1IAALk7AABPpwAAU9UAAHP0AADMUwAABywAAOvOAABftAAAjSEAAEBeAAAnmgAAz8gAANPuAAAgLgAA10YAAJzrAABxGgAAON4AADQsAACgGQAA6n4AAH\u002fxAAAzhQAAeY0AAGpnAAAUYwAAYH8AAGbQAAB+TwAAHqwAAO7hAAD8MgAAdGUAAO4WAABv5AAAxhgAAHNhAADG+gAA7KcAAMhTAAB91gAAGtkAADSlAABGrAAA5CgAAO42AAD8zAAA8gkAAHsxAACihQAAn74AAD+1AAAjLAAAbPgAAIz1AAAuXQAA9cAAADGcAAAJuQAA4MkAALxCAAAPfwAA+goAAIEGAACYLQAAcL8AAKTSAADAQgAABGIAAFTPAACZ7gAAt\u002f4AAMeFAACH8gAA8A8AAB2UAAAfrQAAd\u002fQAABMEAAD2PQAADwwAACwuAAATBAAAKqoAAHDYAADwBQAA8NQAAAVEAABNSQAAB4AAACqVAACxQwAAwngAAC2nAAB7\u002fQAAt7oAADpZAAAQqAAAp4QAAMEFAAAxgAAAYn8AAB2rAAAvTgAAsUgAACOgAADOcAAAHoIAADwoAAAskQAA61AAADznAADlYQAA0gcAALuWAAA8egAArRYAAIDEAABBHQAA8CQAAE5fAADypgAAE5YAAMiBAAAjKgAAnKwAAJHnAADSoQAAWU8AABFKAABr7wAAp30AANz7AAA8LQAAiXIAAMRpAABhiAAAkcsAAOuoAADHoQAAAAAAAKGSAAATBAAAZvsAAGfZAACTFQAAJTsAALEcAAC+VAAAA70AAAAAAACH+wAAKEoAAAxCAABjmQAANtgAAL0HAACEJgAAd1EAAL8bAAD+UgAA55MAAIT8AAD+gwAAiaoAAM\u002fXAACCmwAAwgcAAD0dAAA98AAAz7IAAD\u002f\u002fAACXwAAAhfMAAKbZAABo+AAAhJsAACfLAAA2awAA0VkAADqPAABzmgAAiuIAAKzVAACFYwAAzHkAAM89AAAnrgAAAAAAAOgoAAA+MgAAUEsAAIXkAAA4TAAAiMwAADbuAADxTgAAEwQAAOEuAAA1RgAAGAcAAI7GAADl+QAAbf8AACyZAAChkQAA6q8AABHbAADwUAAAAlAAAEA2AAAvcAAA7\u002foAAC8xAABEbAAAhpoAAOEoAAAfDAAAlgoAABI3AABepwAAZLYAAFciAACzJgAACXQAAEa7AACs5AAAB4UAAGvkAACYFgAAwD4AAOX4AACbygAAh8UAADQZAABoGQAA0LoAADChAADCoQAAgRMAAG\u002fUAAC+ywAAsysAAK6zAADVPwAAAn8AADkcAABz3gAAusQAAH7PAACJMgAAOf4AAB+EAAA7HgAAT7kAAAKtAABX3wAAztwAAEVdAADSNAAAg1wAAIOMAAAcgwAABlMAAHF7AAAYYgAALUAAANoqAADzJwAAexwAAHMUAADlIwAAfCQAABvPAADn5gAA8LwAAOTfAAC05gAAf9kAAIynAABy1wAAs88AAND7AACIogAAb74AACVMAADufQAASQQAAJcrAABPuQAAAAAAAIRDAADt2QAAQ\u002f4AANstAAB+uwAA3cMAAP8YAAClBQAA+usAAFcHAACGPAAAHogAACtyAAADEAAAee8AAIBlAAAT\u002fwAA1EQAANf9AABnQwAAr4cAAAhdAABWvgAAd\u002fAAAG7JAACxUQAAz+8AALzkAACd6QAAXd4AANnAAADhQAAAkUoAAJecAAAzSAAAHC8AAD1QAAATBAAAFQcAAKSSAAALDwAAAAAAAKO4AAAU6gAAyxoAADLkAAAC5QAAetgAAFelAADSCwAA3jkAACsQAABeKQAAmcwAANbHAACfrQAAXLcAAA1eAADZPAAAohoAAI0KAADsxgAAMfwAALTMAACEvwAAEwQAANt+AABQKAAA2jkAAHpvAAB02wAAp7UAAAAAAAC\u002fgwAABJIAAB4mAADcJgAAM3IAAJGLAADdbAAA6GsAALqjAABfcgAATtkAABtbAABXBgAAT7kAAOP8AADD7QAApQUAAJR5AABlewAAbKAAAF47AACZCQAA0pUAAEIuAADC3gAAl1AAAFHeAABiLgAAOEgAAI1mAACW8QAADpYAAM2YAAAqGgAASXoAAIu6AAAs3QAASLIAAFOyAABpwQAAEwQAAGu9AAD1dAAA8\u002fYAAApUAAA49gAA5rwAAHI5AAALkAAA9dgAAC2ZAACT6gAAJUcAAEe4AABvBgAA+P4AAOBAAACK5gAAJtcAABSzAAByhAAAZWoAAMLqAAC6lAAAY3YAAN6lAAApZgAAVFQAAPbRAAB0xgAAIWMAADKnAACa7gAAZIMAAOt2AADSBwAAaGEAAIvIAAC+JwAA5h4AACHSAAA9gQAA8T8AAEoLAADB0wAASDMAALqVAACi0gAAdCEAAB68AAAj4wAAJ2kAAD0JAAD9awAAGQAAAM8sAAAgNAAACEIAAFOzAADySwAAlM4AAFqvAAD5ygAAw3AAAPlzAACCUgAAcxIAAFSNAACKlgAANEwAAP1oAAAw2gAALqYAAIhxAABfLgAAmf8AALwhAAAkGgAA5mgAAEzjAACjjAAAEwQAAEcRAACD1QAAjVAAAGANAAAWdgAAN0IAAHbNAABIFwAAaa8AAO6zAAC5dwAA3KAAAMe1AABf0gAAACAAAJRKAABLkAAAnPEAANMjAAD2zAAAmbQAAAAAAABhwwAAJnQAAHnuAAAeRwAAUogAALVPAABdyQAA1LcAANlPAABPmwAAo2cAAC6rAABhhwAAh+MAANTQAADpRAAA\u002fFIAAB3BAABpRgAANwUAAJ7VAABuhgAAkrUAAM1yAACPSwAA7dgAAIfMAAB6GwAAEO8AAF\u002f1AABhWwAA41cAAEhrAAAf3AAAMCcAAKz+AABTGQAAmr0AACOlAAAnjwAAZjsAAA\u002fYAAD6BgAAEUgAAOYrAAC2hgAAUn0AAHDqAACQmgAASoQAAADXAAAFDQAAs0kAAM3YAAChGQAAe0YAAFmPAAAFWQAAAs8AAJRwAAB6twAAzFoAACfNAABK+wAAkEkAAE9wAAAWZAAAa0wAAPhMAADUuAAACGwAABOhAADv2gAAZvEAAH6bAACfrQAAhyEAACBgAAAAQwAAndIAABvIAAApNAAAtjwAAACHAACK+AAAUKcAAJcSAACVkQAAlP4AAGKqAADd0wAAhC4AAKxtAAD6igAAASYAADsIAAD5rQAAAAAAAOB2AAAqYwAAijcAAGS8AADHtwAA9dMAACjoAACgzAAAVwcAAIkfAAAIgQAAQegAAIVgAAAbOAAAvBQAAOyeAADodQAA5vMAAH7gAAAaSwAAw5oAAM9uAADE+wAAymEAAMepAACbhAAApIIAAMK9AAA8XQAAMAYAAFlVAAAAFAAAxTEAALxnAACgpwAA6yEAACQpAABAIwAAQZsAAD4GAABehgAAiHEAAL55AABsNAAAVBwAAMS9AADgBQAA9psAANE\u002fAACGuAAAnGYAAFE6AADakQAAhWgAAGkWAABIggAAEwQAAAXcAAAjyQAA8mEAADaKAADMQQAAS1QAAFMZAABPuQAAMoMAAOUyAADXVQAAhDIAAIAaAABK1AAA9o8AAAk0AAAvtwAAd98AANZCAAAoWwAAKUcAAHWBAAAMSgAAUg0AAIF6AAB4HwAAm74AAHheAACdngAAiFEAANzAAAA8vgAAdzcAAIUeAADJwAAABdsAAFIZAADHGAAA5okAAGhPAADsugAA03sAACCQAAAFRgAA5hYAALAlAAArKQAAd5EAAGYeAABc\u002fgAAJwgAAEaKAADPEAAADwUAANVVAABYCQAAG3cAAL9zAAA3zAAAupcAAOhcAAB+bAAAwtAAAIISAAAX3QAAMmsAAImYAAAlowAAVVgAAG\u002ftAABbPQAAMHEAAHrXAAAH1gAAGs0AABMEAAD5YwAA51kAAPg6AABuYAAAwL4AABkUAADAcwAAKQQAAEY+AACuIgAAun0AANmmAAB5JgAAksEAAAOzAABWNQAAIN4AAKpvAABTPwAA8rUAAP3eAAAKFQAAv2YAAHfbAADpNwAAlX4AAOOOAAC1HQAA8WEAAN1tAAAMDwAA6vsAADtrAADVbQAAEwQAAGm\u002fAADZOwAANmAAAG99AABvQgAAHGIAAJEcAADsyQAA4jQAAODmAAA+nwAA2\u002fwAAE+5AACjlwAAnm8AABZLAADTtgAAKI0AANVnAADzjAAAL\u002f0AAOceAACvJAAA4fsAAF11AAAEDQAA+qgAALVOAACQcAAACYAAAKLkAAA3WgAAFn8AAIiwAABbjQAArD8AAKSqAABFfwAAat4AAFJWAACryAAATegAABQQAAA3xQAAKV4AAIqpAACmUwAAWgQAABvUAAD1aAAAKRAAACvEAACvwwAAO5sAAE+5AACuoQAAa0YAAEKJAAAFkAAAoUMAABxiAAC6QAAAoskAABohAADTHgAA7mMAAK39AAChDQAAjS0AAJSDAAA1OwAAcAQAAOXwAADc5gAA60MAAHqyAAAhbAAAAAAAAMiEAAAYVAAAzSIAAJY2AAAdNgAAFRMAAIXdAAAY9QAAdiUAAF9jAAAbewAAcIUAAFXZAACbQQAAT7kAAIw5AAAvnQAAAAAAAGZHAAD66wAAxR8AAKivAABTegAAhdcAAFaTAAAh+AAA2c4AAE55AACBDAAAT7kAAGrnAAA\u002foAAA08kAABrxAACgigAAsJMAAK+lAABnEQAAvigAAELMAAB5kgAA0NUAALy7AAAH8wAAHQ0AAJGGAABPuQAAqUgAAFafAACeTgAAg2MAAA2CAAAdHQAARXYAAESOAADmcQAAb00AANhOAABSLQAADeYAALNLAABhvwAAUKgAAHQ0AAAuBgAA4y4AALJQAADurAAA9jIAADpFAACa5gAAAnEAAAxrAAAfqQAAXDQAALevAADEBwAAX8gAAKA0AAA\u002flAAAT7kAAOKUAACEbQAATWwAACXJAABhvgAAIDEAAPcHAAAFUAAAWIoAAK3VAABmHQAAiwUAAHp1AAC9BAAAmDgAAAmGAABRVAAAJFQAAByUAAASRwAA3H8AAMzBAACz7QAAMX8AABB+AADuogAAVasAAFwGAAANlQAACCAAABsyAAATBAAAXbgAAIJ0AABIIAAAEXIAAD09AADsegAARlgAADYYAAANvQAAcWgAAC7MAABO8gAARHMAAP59AADQiAAAT7kAAL4qAAAW0QAAghkAAJzPAACyLwAAZfoAAH\u002fSAAC4GgAADXUAAArAAAC\u002fQgAAgaEAAGE1AADnWQAA03cAAHlUAAB05QAAFd0AABMEAABVngAANcAAAP5nAACTtgAA7G8AAAE\u002fAAD5tQAAeJYAANTlAABtwgAAAwoAAM0cAABjfQAAS\u002fgAABaGAADUfAAAZ90AABN9AACQ2AAApsAAAFN3AACH2gAA+BMAAHx6AABaZAAA+AUAAIvoAAAFsAAAL7wAACOvAACBDQAA0MgAAGxxAACPUgAAAAAAAA\u002f9AADW\u002fwAAdQQAAMJKAADlmgAAZwQAACAeAABYgAAAgj0AAHBmAAAwEQAAMIUAALMtAAAKwgAANx4AAFcHAAC8rwAAMxkAAKYmAAAwyAAAC9kAADQiAACTNwAANgYAAIjVAAB9gAAAu1QAAIq7AADmiQAAAAAAAB9WAAC+hwAAI6gAAKb7AABUCgAAYq8AABYGAAAj5QAAFGUAAFBsAADeBwAAv5cAAKs0AAD7WgAAqVwAADVYAACReAAAXEoAAHt1AADLLAAAVGQAADfyAADReQAAEwQAAPM3AADaFQAAx80AADPAAAAf+wAARRIAAOFCAAAhXQAAbP0AAH82AADhWAAAYbwAAE+5AADKDwAA+IwAADhpAAAz8AAAQ6wAALXZAAAyCAAAi90AADyjAADtuQAA3woAAN7EAADb4gAA0EsAAD4uAABdSAAA\u002fOgAANFVAAC5DAAAQ9QAAB25AAANwAAARJEAAME6AACKgwAAB\u002fkAAAJKAADjWwAAkowAAH0mAAC1KAAAIyUAADaQAACsfwAArMYAAAdQAABgPwAAYdcAAL58AAD1ugAACcUAAI4OAADpMgAAjtIAAHifAADM3gAAJxQAABMEAAD87AAAGNwAAEtOAADGuwAAm7wAAH23AAApxAAAV0AAAJYkAABi3wAAT7kAAKuGAAA1tgAAMVoAAK+6AAA6kgAAu3kAAGMOAAD5EQAAujgAAMUtAAB2PAAAA8gAAK54AABYFgAA14EAAAYjAACTcAAA0VIAAIAhAADMQQAAeTIAAMYHAACa1AAA8ooAAEkPAAAKKgAAd2IAALuyAACaBQAA8SIAAGlSAACa5wAAdTEAAP+1AAD3FwAAvMAAALPMAAAfOAAAoiQAALIiAADC7wAAJ9UAAKjBAAA2MQAAHLEAAFrrAAA16gAApCwAAGoVAADsBgAA+0QAALvwAADerAAA\u002fm4AAByYAAAZhAAAc80AADuOAADu5QAA\u002fOwAAM+SAAD\u002fBgAAJOUAABHFAADsGAAAjpgAAP+rAABw8AAAvg0AACY3AAAy5AAAFkYAANymAABBZwAAbbAAACGjAAA+bgAAZdMAANIKAADtcgAAeeAAAN3JAACrsQAANmAAAEI+AADt1AAAmykAAN2fAACDtgAAbpYAAKvTAADMTAAAVJIAAGNxAAC2gQAAJL0AAKxgAAAMGwAAQbIAACAeAAAOnAAAAAAAAL5mAADZfwAAAAAAAE+5AACXzQAAU9gAAJbSAAAkhQAA+AcAAEYJAABXagAAavEAAGJ8AAA7nAAA2WsAADK3AAAKJwAAiGkAAHqoAAC3EgAAsr0AABCvAABTHwAAyLEAAJtoAAB1KwAAeR0AAPnKAABnFwAAAAAAAHEEAAAUPgAAbfUAANo\u002fAAARBwAA1tcAAEfzAABDlAAA3M4AAOLuAAAd\u002fwAAYfYAAG\u002fMAAAopgAA01UAAJDRAABptgAA85cAAIwbAAA9aQAA1UsAALm0AACYTgAATXgAAIG+AAB54wAAZwQAAA4qAADJawAAxOEAAD7ZAACKGAAAqigAAPD6AAAfEQAAZCcAAAwvAACUTwAAc0sAAF69AADmeQAA4joAAH0TAACE7AAAMi8AACktAABcaQAACoMAAHBLAACcgwAA2ZcAAHYlAAAKOAAAKPwAAKFFAABscwAAA8IAALJ3AABylQAA1n4AAEuHAABucgAAMNwAAAuuAAB4ywAAI7UAACUmAAAlhQAAbygAACQUAABrxgAALcsAAJOzAAAgTwAA8h0AADTmAADMjQAABT4AAJ2uAABaBAAAH6sAABHmAAButAAAzVwAAIs3AABI9gAAB4wAAB3QAAC6LQAAoQYAABMEAADS7gAAT+YAAM5gAACRBgAAcdUAAKLJAABIoQAAxPgAAAAAAABu4gAAh7MAACEhAACnsAAArNYAACIqAADDWwAAuJ4AACYLAABqfQAAfv4AAMjcAACDgQAAgsUAAJZTAAANjQAA0aEAACEVAAB7kgAAa\u002fUAAMj0AADthwAAAAAAAIyuAABPuQAAcH8AAD4LAACUhAAA4f8AAPdQAAAesgAAhkwAAHh6AACp3QAAnh0AADUUAACqswAAKO0AANmsAAC7ZgAAHAcAAI3uAACLegAAk8UAAITCAAAPoAAAy+0AADK9AACPRAAAhLAAABgQAABN9AAAimoAAEK1AAB23wAAorcAAOJ3AACSWwAAwUwAACB7AAC0dgAA06cAAPB6AACWRwAAbJkAAAkwAAB6vwAALCQAAEXxAAD56QAAHBMAAC7sAAATBAAAqz0AACeHAACLXgAA9uQAAC7WAABhJQAABOYAANDHAAAsIAAAie0AAPvKAAAjUwAAHBgAAKhNAAAqMwAAIbcAAI+aAAAdpwAAbe8AAAfUAACyKwAAN5gAALzPAACKywAA0j0AACHGAAAwxwAA+BEAACMOAADEkAAAZY8AAFc5AADvMAAAEwQAAIlnAABf1AAAK5QAAKyKAACpFwAAx\u002fwAAIlyAAAfOQAARXIAAKa+AAAAAAAA7RsAALFuAAD5vgAAygQAABT0AABPuQAARAAAAK9WAACwLQAA8mUAAPEjAAAgMQAAkk4AAKJtAACYagAA1VAAADXyAABZBgAAaL0AAE+5AACcZQAAQ3sAAKX1AADDYAAAKBoAALCXAABe8QAA9xMAAOVQAADTSQAAHO8AAH6tAABi9gAAJxQAAIntAACT6AAA4OkAADjOAAA2ogAANhkAAAbuAAD0tAAAMG4AACbRAABtgwAAJusAAMizAAAucwAAKqYAAH5RAACg\u002fgAA1SMAAJlCAACY+QAAa4cAAFvaAACUpQAAIboAAGQLAABrtAAAPIAAANQsAAA2kQAACx0AAAPkAAADhAAAi5oAAI\u002ffAADKSAAAsPEAAETxAABpoAAAsVoAAMzaAABGRQAAAAAAANApAADqoQAAinAAAIp3AAA4iQAA\u002fawAAFu9AACHXQAAu9oAAKaEAAAP\u002fgAATfkAAEcqAADPsAAAY9cAACQ9AAD++QAAMTwAABK1AAAq8AAAPBgAAB+JAACxcQAAsPIAAII4AACMYAAA6v8AAJL8AAB\u002fsQAANm4AAFptAADoZAAAcoEAACXiAACKRgAA0bsAABZWAADmpAAAfEQAAEbnAACQSAAAFoQAALYGAAAo9QAAZ3MAAN7OAADIhAAAMxEAAAVWAAA+wQAACTcAALS5AAAThQAAZzkAAE+5AABsqAAAT4wAAKk6AABxsgAAZAYAAP7uAAAxrQAA7xoAAAAAAAA8IgAAci4AAKwlAAAUBwAAgG8AAPxMAAD3YwAALIAAAFp6AACsiAAAOF8AAMvzAAA7zwAAo+EAAJHAAAC4SQAAMiMAAKq6AAA7ywAAQ0AAALghAABA1gAAki0AAB1UAACs7AAAOSkAANj+AAC30gAAZ78AAJZTAAC98AAAjJUAAAa\u002fAACPqgAA+DkAAGZpAADA+gAAimAAAK6VAABw2QAAshIAAAGVAABIwAAAviUAAGAEAAANcgAARoEAAAfjAADxqAAAoxUAAIjNAABD4QAAHkUAAMYpAADM\u002fgAAZUAAAPjXAADsSAAAmzsAALEcAAAAHQAAqoYAAEG1AABv+wAAsL4AADIJAAAJ+AAAWkUAAAbVAABckQAAF8MAACZ7AAC6PgAAn0MAABRYAABITwAArS8AAKm4AABzOQAAaEgAAKCNAAAPgQAAGUwAABskAABS0QAA2x4AABB+AABtawAABfwAAOTXAACU3QAAlTQAANacAAAAAAAAqWUAAA7nAAAM5gAAbzAAAC+GAADqFgAAkAYAAM5aAAANZgAAzgsAAH7\u002fAACgLgAAaO8AADrzAACOiAAAVnkAAMqWAADAwQAAXvAAAGx1AAClJQAAzrgAAIzmAAC1EQAAaQQAAPkpAADD2AAAZGcAAI6BAADcHAAAEkoAAOdZAAB6ywAAcTMAAPzQAAB+kQAA9rYAAEyjAAAj2AAARREAAKYKAABJ\u002fAAAoVYAACARAADvUgAADZ8AAGYkAABSyAAAIcUAAKYIAAA1KAAAyIMAAJCOAABCkwAAwX8AAAUjAADGmgAA6PYAAFI2AABTMgAA7eAAAAjMAAD\u002fGgAAIYcAAMNVAABYLgAAFG8AAPXGAAA0TQAAKqMAAPehAAAafgAAjNcAAK71AADfcQAAT7kAAKWsAACadQAAtXQAAJnjAACpsgAAh\u002fgAAADmAACQLwAACisAACPmAAA14AAAsfEAAKRsAADv+QAA7z4AAKVYAAA+SQAALbAAADtRAACutwAAPmkAAKceAAC5HgAANpAAAFpXAAA09wAAZa8AAC3KAADxxAAAZGwAACM6AADxdwAAeEoAAEgrAADOHQAAv1YAANoUAADJTwAAIogAAAN4AACeVgAAI1sAAKikAAD0qgAATtwAAMDgAAAU6QAA+ewAAOEQAACXugAAaFgAAIUrAAAlDwAAPckAAOz0AACbFAAAfcUAAJdhAADlqwAAQ\u002fAAAFLNAAC4CQAAQ2MAAOLuAACUhQAA8cEAANQEAABPuQAAd8sAAKjHAABHjAAAUgsAACTHAACR+wAA1tgAAHYZAABR2AAAwBgAAC0NAACwaQAAT7kAAMvAAAARRAAAF3kAAGilAABYiAAAQH8AAGwQAAA7BwAAFmwAABU7AABGWAAAndgAABPjAACivwAA9q0AANFZAAATyQAAWGUAAAQeAAC4kAAAdqoAAEbrAAD3wgAATYEAACiYAAB7ugAAe7YAAIeqAACXVAAAsk8AAHQHAACi1wAA2pIAAIz+AACtwAAAvPEAAOMoAAAHsAAAFMAAAJRiAAAhSgAAdJoAAKmQAABnPgAA\u002f\u002fEAAC+RAAB1fQAAwfAAAG46AADTngAAEwQAAHcIAACBpQAA1kkAAF7tAADEYQAAUZIAAPJBAABEwgAAEUAAAFeRAAAMjwAAZCsAAPFgAACinQAAd1kAAPFyAAC1agAAT7kAAJ5EAADQfgAAQugAAJ7SAADPgQAAwiYAAF2hAABeyAAATWkAAMpcAAAAAAAAzcAAAOfTAADrVAAAdCIAABdoAAAKCgAAf7sAAM11AAA9iAAA8YoAACEaAAC+pgAAEwQAAGBfAAAxoQAAGHEAAE3aAADQowAAUJUAABBwAADStgAAvKsAAKlrAACsjgAAQwUAALnBAADyLgAA5SYAAAZ4AABcQgAAg30AAON5AAAmHwAAnFIAAAKCAAA8agAAdHEAAHb1AAB1VwAAnRAAAChrAAA43AAAfjUAANWUAACZSwAA1f8AALAFAABQEwAA6CsAAB1SAAAeqgAAjk8AANndAAAkewAAaeIAABN7AADlWQAAOcQAAOqfAABbkAAAJ9cAAIM9AABGWQAAckwAAOD\u002fAACC5AAAYbwAAJqqAAA4NwAAKHUAAArPAACRLQAARdwAAHtOAAC\u002fIQAAbr8AANH2AABJmAAAK1sAAHwJAAB9JQAA5W0AAAHjAADguAAAEDQAAPj1AACRJAAACNoAADz7AAC3JAAAarAAANnUAAB+4AAAgegAAA5nAADn8wAA4ioAABN8AADd3QAASt8AAIOaAADKhAAArvUAAGpIAABU8wAAAAAAAMHPAAA+hAAAkgYAAKvQAADPLwAA9jgAAE+UAABObgAA5y0AAP49AAC2\u002fgAAirAAANefAACZVAAAmboAABMEAACmvQAA170AABpPAACZpwAAw90AADYFAADyJgAAB00AAIG6AAA8ZwAAEKUAAPkVAADzagAAtygAANEEAACt2gAAthsAANZjAAD+lQAAZzAAAL1VAACUfAAAzlQAAJ1LAACXkQAARNMAAENyAABTIAAAmqEAAALJAAA9BAAAfr0AADvHAAA9RAAAFskAABPoAADPxQAAUBsAACqAAAAPxgAAeBoAAIscAADQ2AAAw4YAAF7DAADAoQAAI4QAALHXAABxJQAAH9cAAJcyAADe7QAAJkMAAHzNAACnxQAAMtMAAIJmAABZ8AAAzQoAAMDSAAAZJgAAAAAAAE4hAAA4OQAATZoAANeuAACsmgAAcMAAAF1zAADgbgAAT7kAAKs9AAB9KwAAfNAAAIL5AAByzAAAAXgAAKz0AACnaQAAma4AAFjMAAC0ngAALi0AAAiKAAAB\u002fAAAZwQAABwdAACnkAAA9mEAALXZAADxKAAA+QIAAG9dAABPuQAA8gcAAEiKAAACBQAAAAAAAJZVAAAAAAAAmOYAAIPCAADuJAAAKqQAAObOAABJpAAAxhgAAInuAAAidgAA8Q4AAAuzAADE5AAAiFMAACwxAABMbwAAxjAAAItDAADEEwAAop0AALamAADEEwAAXrYAAAAAAABCSgAAZfAAAObjAAA0zwAAtvQAAEI0AAAT6wAAaDsAAFcgAAAwegAAhokAAJnhAAB5CAAAtfAAAAGyAABn7wAAIsAAAHXPAAA2KwAAoxMAAC\u002fDAADEfgAAbUoAAHk6AAC6fgAA7FoAAPixAACFwAAA954AAETAAAAZxwAAiooAAJH2AABTagAA2vcAAOSoAADrkQAA5d0AABMeAAAo5wAAanAAAEc5AAD7lgAAyaIAAG+VAACgoAAA2Z4AAPQnAABmJAAAHk0AAJTlAAD0lQAAE7EAAJfbAAAbWgAAk2IAAOnbAAAROQAAC2sAABKgAACXygAAzQcAAPDJAABskQAA764AAJY0AAB\u002fnAAATf0AAM9UAABNkAAAdCIAAEWkAABPbgAAzloAANJ6AACPkgAAA3wAAJitAABrwgAAJgwAAO3vAAD1bgAANDsAAPGWAABD+QAA3+kAABkdAABqsAAAmq4AAMQ8AAAOHwAAJqEAAFFeAAB\u002fmAAAQc4AAFRsAADnbQAAIdwAAGUdAADEWAAAr7IAALydAADwrgAAFZwAADLWAAAg2AAAeT0AAJmMAAAZ1AAALwYAAEpjAABe7gAAWY8AALvYAABodAAA0C4AAK60AADRRQAAYbQAAC6wAADcBgAAEwQAAGLyAAAAAAAAYBgAANTyAAA6lgAAH10AAOfiAADmiwAA0AkAAFP1AAAAAAAAQV4AAGieAABEvgAAlGUAAGQWAABlvQAA4EMAAH8LAABDBQAAQ+sAANFxAAC76wAAOn8AAP9hAABJYwAAi9cAADmJAACPBwAAlMgAABFIAAA3cAAAk6cAANV5AAD+XAAA8bEAAL26AAAM6QAAnz8AANu+AAAAAAAAbJcAAFozAACyDwAA\u002flAAAFR7AAAkmAAAHxEAACxjAAAFBwAAdT4AALDNAAC3agAAjegAAB\u002fJAAAqgQAA4w4AAGnLAAD9QwAAWpsAAJPBAABq5wAAEwQAADgPAADzswAA36YAANUxAAAQ3gAAGG4AALZQAADLewAAaBgAAOn1AADdqAAArEgAAFAAAABBhwAAsL4AAPj5AABpxAAABLIAAP9PAABYhwAAT7kAAGCoAACVHwAA2g0AAF3HAAB3VwAAu9UAABeyAABwwAAAiuwAAAU9AADn0gAAT7kAANbfAACEJgAAuscAAMw6AAD2YAAA7woAALaFAAAhLgAA7DcAAAJbAACJpQAAE5YAAMdiAAD9xQAAAAAAAMtsAAB+TwAApesAAOb+AADoWwAAuIUAAFY4AACCnAAAv70AAABfAAATiwAAUR0AAM0NAAD4BAAAEwQAABNKAAAx5gAAwZcAANvrAADBuQAAD9oAAKVVAAAzmwAAvI8AANzKAAAsVQAA0BgAAEkkAACDpwAAxR4AAAZSAABfjgAAKhwAAGXeAAClZwAAnUoAAG7gAADvmwAAH3oAAB6IAACReAAA1koAABMEAADplgAAsEwAAC7\u002fAADUCAAAZFAAABjcAAA+qQAAki8AALLrAAB8cwAA320AAOUtAAD78QAA2BcAAJaxAACQcAAAOGgAAH64AABMIgAAY2YAABkQAACMPwAANncAALJuAADzjwAAdzgAAE+5AAAphQAA+VgAAJ38AAB6awAAKoEAALGHAACCpwAAlS0AAHrnAADAJwAANIoAAEQ3AAD7+gAAUigAAFQyAAByLQAAB9oAAJzgAAD5fwAAD+kAALxLAAAZ0gAAvtgAAJTJAADGPQAAiVwAAAG2AACH5AAAQp8AAFfoAAALOwAAIQ4AAB1QAADqcAAArvsAAP0mAABHtAAAm5UAAMH8AAC63AAA6qAAAE+5AADOBgAADS0AAPOQAAAdlwAALeMAAPA6AACrGgAAcS8AACcLAAAfrgAA5wUAAOr4AAD2VwAAe5AAADtrAACuuAAAkWcAAJY5AAD89gAA83EAADoPAABVsAAAl+0AAAcjAAAO2AAAkSwAAE\u002fOAADhlAAAR2IAAKJ4AAClTgAANZsAAOEnAADF6AAAAAAAAIWpAABGQAAAafQAAELNAAC43wAA6PgAAF27AADZ0AAAQ8sAAOSIAAAAAAAAVPkAAJThAADGcwAAX48AAM2sAAC1hgAAIFAAAEBIAABbVQAAXYEAABrSAABSDQAACrwAAEM0AABPuQAAMb4AAHjIAACw7gAAjPMAAF6EAACbXwAAiE0AAAQvAAASOAAAAAAAAIjtAACJIgAAxSYAANNRAAAAAAAA1pcAACjaAACHfgAA4J0AAOB\u002fAAAMywAA81oAAD38AADqqwAAW\u002fUAAP6MAACm+wAA3CgAAALWAADlKAAAlZsAAPyaAADV6wAAceMAAPYqAADHqAAACYkAABG\u002fAAA3hwAAQMAAAKobAAA8OAAAY68AAH+cAACDfQAAJ0YAAANEAAC5+wAAZx4AAP+1AAA9hAAAEEMAALhOAABhCAAAHhkAAEXcAABG5AAAu1oAAGwiAACuyQAARREAAOuXAAC9BAAAHg4AAB7PAAAV2QAAHZ0AAG\u002fyAACs\u002fwAAzLcAAJErAABLYQAADskAALPbAADK8gAAJ0EAAE+5AABPuQAAQ\u002fkAAFftAAAitgAAx9wAAAgRAAA5nQAANhoAAOxiAAC2ugAAPtMAACzWAADUzQAA8SkAADEGAAA5ngAAlgUAALU7AACn0gAAZUIAANqvAABNugAA0xYAAN3XAADcFAAAqpUAADWuAAA4GwAAy2YAALSZAABsTQAAQksAAD0zAACaewAAGbQAAI4EAAC\u002fcQAA0IgAAKsTAABB9wAAqCAAANnwAAArlwAAEkAAAHKfAABIvgAAXrcAALaJAADw1AAAKoMAABtPAABZfgAA7kMAAHLkAADa9QAA47oAAI8aAADUCwAAYDsAAF6RAADNcAAAlWEAAE+5AADHHwAAnmIAAL\u002fDAACiUQAAwugAAA3tAACqIgAAwGAAAJ7OAACU3AAA5lMAANoLAAATBAAAkroAACCZAAATBAAA1GMAABQJAABQoAAAqh8AAHxoAABPuQAAhMEAAHWhAADuygAAMhQAACULAABStQAAFegAAE+5AACkyAAArIsAACJAAAC80AAAcRAAAHv4AAAB2wAAAAAAABTdAAAp+QAAa9cAAEU+AADKPgAAz7EAAEJoAACuRAAA5SIAAHFCAAA\u002fJgAAgSQAAKaxAACKBwAAxXMAAM4PAAB7PAAA2LsAALQqAABeXQAASisAALTbAADRSQAA\u002f8AAALbTAADc9QAAOboAAD5WAADrRgAAgrIAAC94AACHpwAAfyQAAEVxAACc2gAA\u002fMgAACg5AAAJmgAAxAgAAAutAAC6cQAAlpIAAAG2AADgIAAAGpgAALA8AADbIAAA+qAAAOQxAADaZwAA33sAAPdhAACmGwAAlZcAAFfxAACpqwAA98QAAAAAAAAvfwAAtD8AABMEAADi3wAAslsAAF52AABEAAAAud0AAOo5AACkfAAAoYEAAFSZAAC1MQAAoEsAALVpAABHVwAAB\u002fMAAOcxAAA\u002f3QAAujAAAFO1AABAfwAAHHQAAB\u002fpAABlkwAAjdcAAFSaAABNyAAAe8YAADFEAAAwBQAAzEUAAIOjAAALtQAArT0AAHFBAACe\u002fAAAygYAABlbAACzngAAr0wAAAAAAADZdAAAi3IAAHRHAACw8QAALO4AAMBjAAASnAAAivgAAOU0AAAC1QAA32oAAHuWAACzxAAA624AAIMGAADjsAAAmc0AAHwMAACnCgAATRUAAHrRAABcjAAAP9EAAJ+NAAAGZgAAPmYAAN3WAABUsgAA34MAAIlQAAAslwAAlMMAALsfAABxigAAjNIAADN3AABjbgAAxt4AAO6DAAAjnwAA13oAAEaxAADrdgAAHH8AADvmAABx+wAAkmIAAL3aAABI+QAAJXMAAJ0uAABkQwAAgvIAABMEAABqCwAAF6cAAPhLAAADzwAA27wAAJnYAABiZwAAZgUAAJZLAACe5QAABSMAAFoeAACZYAAAh6YAAGW7AAC\u002f3QAAxKIAAOH7AADrewAAzgkAAB0PAACXvAAA6hgAAOvFAACuBgAA3M8AAL8KAABGTgAAfZIAAGSvAAAGBwAAdPsAAGF4AACA9AAAWNkAAA60AACqhAAAg\u002foAAFklAAAJSwAA91UAALrhAAAVmwAAuW8AANLSAACYHQAAG9QAABntAAB\u002fEQAAzmcAAO8rAADBKwAAVc0AAHLRAAAnBAAAoDwAAM4xAABO0QAAGkEAAJWhAAB4cgAADIwAAKmzAADGBgAAp3AAANjXAACfugAAea4AAH\u002fxAABJQQAArqQAADiHAABfYQAANZEAAIwbAABoHQAAJp8AAJXeAABAwAAAAYkAAIGsAAC8jwAATqoAAFCJAAAKNgAAQJUAAMY0AAAROQAAliwAAD\u002feAADmWgAAuBMAAN4ZAADaOgAABNIAAOd7AACdOQAAU\u002fcAANO0AAA4MwAAPwoAAMzcAAAcHAAAvcEAABMEAACv6gAAwsMAAO0YAAAxyAAABKMAANtOAACPfwAAgmEAAMT9AABh3wAAS3MAACzSAABdRwAArCYAABBxAADhwQAApqkAADZNAACX8gAAdIMAAB4LAABmtAAAEXUAAD6TAACGzAAA8A0AAAotAAAD2AAAneMAAAQFAABX2QAAYkUAAAAAAACrnwAAu14AAIBqAACy5gAA0iIAAHmHAACJoAAAg\u002f0AAP6RAAAtYgAA4e0AAOCXAABHCwAAzTkAAJ2LAAD5YQAAHeIAAI0nAACB0AAA4YUAAOCgAAAPkAAAWc8AAK73AAAc7wAAiwcAAMqSAAAV+gAAJKIAAOVwAABxtgAAfTIAACURAABVkgAAAAAAAFbvAADv\u002fgAAXGoAAGqPAACfcQAAVdIAAIPzAABshAAARL4AAEVLAABMaQAAO\u002fYAAIEaAAAgPwAAc5kAAMZVAACCIwAAVrwAAFjvAACAgQAAaPcAACsaAADEEwAApN0AAGe3AAAX+gAAEPQAAAFpAAC6hgAA67sAAO2uAABpdwAAUBwAADIZAADgQQAAFhgAAKPXAADcSgAAcboAACFTAAB2OgAAD3UAAFNUAADBIgAAsM8AADXBAAC7mwAA6CIAAF\u002fUAAATfgAAylcAAB5OAADjIgAA\u002fmYAANu4AAD2yAAAeMkAADSRAAAvEQAAEQgAAF6nAADwyQAAW3MAADTLAADNggAA6XMAABaZAAD76wAAbKYAAHNhAAC4OAAAcOMAAMq8AAAo4gAA7XsAABMvAADkwAAAGWMAAI5oAACXhwAAyBAAAGeZAAD6xQAAu5IAAK6aAAC\u002fyAAAP98AAHarAACo\u002fAAAOwUAABJpAACorAAANc4AAH4wAADCFgAAb+AAAGQFAACoIwAAW8sAAMTmAACiOQAAaGYAANj5AAAkpQAAfZ8AAG2fAAA2qwAASzwAADYQAADq6wAAgaoAAKTQAADuEgAAEJ4AAE5VAABXxAAAF6kAAH9WAAAL\u002fAAASYAAACsRAAAdzgAA88YAAAHNAAA8rAAAC58AAEbtAABcMgAACREAAL7oAAAsugAA6ycAAILeAACn6AAAqXYAAMz3AADCMQAAEwQAALviAAAk8QAAwQoAAOWrAACqbAAA9SUAACcwAABWOQAAWGgAANMJAADqfgAAWAoAAILAAAA+VwAAJr8AAKK5AAB4GQAA\u002fTMAANYdAADbigAAZ\u002fMAAIj4AAAAAAAAVbQAAEhpAAAwjgAAaN4AACCxAACQLQAA2TUAAFbXAAAE\u002fwAADVMAAFz2AACDtAAAiBUAABUrAABsQQAAVvwAAHMHAAApkAAAOLkAAFArAABdGwAAtaAAAJ3uAADqegAAgt4AADOtAACkggAAEwQAAMnOAAD94QAAhNsAAD6dAADNgQAAiiwAAP6ZAADWrwAAp3AAAIpbAAAj4AAAxu8AANcwAAAnDwAAEwQAAPDhAACGPwAA\u002f0wAACYkAACHNwAA06QAANjtAABMGAAA2bUAAAhmAABp9AAApzkAAKxNAADfmQAAqhYAAIFtAAAxxAAAqL4AAG8LAADkLgAAg8UAADq6AAA="},"xaxis":"x","y":{"dtype":"i4","bdata":"NQAAADUAAAAZAAAA1HEAAFAAAADYFgAALuMAAGU3AABQAAAAmZwAADUAAADJkAAARhQAAGphAAAWAAAAK4oAADUAAABRNgAAZpQAAFAAAABGFAAARhQAADUAAAC7BgAAbwAAABkAAAAsSgAA4RoAAC0VAADqDgAAvBEAADUAAADTRwAAWCAAADUAAACf3AAA5\u002fkAADUAAABGFAAAbwAAAI6TAAAN6QAAy3AAAG8AAABvzQAAUAAAAOMEAACOYQAANQAAABHbAACn1wAAUAAAADUAAADpKgAAoGMAALMAAAAVAAAAUAAAANtwAACzAAAANQAAACQXAAA1AAAARQAAAEMbAABGFAAA6gwAADm9AACzAAAAFQAAAEYUAAD\u002fogAANQAAAFAAAACPAAAANQAAADUAAADopQAAuwYAAMu7AAA1AAAAy3AAADUAAADhGgAANQAAADUAAAA1AAAAUAAAAOoIAABGFAAANQAAAHhJAAA1AAAANQAAADUAAABKlgAANQAAAG8AAABvAAAAPkEAADUAAAAADwAARhQAADUAAAAVAAAAUAAAAG8AAAAhWgAA4RoAABkAAAAZAAAA3GMAABYAAAA1AAAA4RoAAKPeAADM\u002fQAAHqkAAPfpAAA1AAAAgjYAAAAAAABQAAAAeWIAAMsRAABQAAAANQAAACFmAAAZAAAAuXsAAJV7AABvAAAARhQAAEYUAAB8VwAAUAAAAL+aAAA1AAAAswAAADUAAAA1AAAAjwAAAEnUAABi6AAAUAAAAKJPAAAlZAAAtVwAADUAAADhGgAAbwAAAGdKAAA3fwAAFQAAAFAAAAA1AAAAz7MAAE2wAAA1AAAAbwAAABqkAABGFAAAzfMAAMg5AADVOQAAg+sAADUAAABEbAAAuOgAADUAAABvAAAAUAAAAG6XAAA1AAAAUAAAADUAAAA++QAAFgAAAAgCAADhGgAANQAAAG8AAAA1AAAAGQAAADUAAAA1AAAAc+sAAM53AAA1AAAAToUAAEdHAADhGgAANQAAADUAAAAVAAAAc6UAADUAAABeagAAyKMAAIvGAAAVAAAAM6QAAI4FAABvAAAAZ5QAAAXuAACJOwAANQAAABUAAABQAAAAbwAAAEYUAAAVAAAAFgAAAN95AACPAAAA7JAAAI8AAABPFQAAjwAAAOEaAACn0gAACAIAADUAAAA1AAAAlf8AABB\u002fAAA1AAAAFk0AAOEaAAAVAAAANQAAABUAAAA1AAAA4RoAAMmOAAAWAAAANQAAAFAAAABQAAAAZKMAADUAAAA1AAAARhQAAOEaAABQAAAA4RoAADUAAAC1hgAAUAAAAM+mAAA1AAAANQAAAAAAAADhGgAARhQAAP\u002fCAAAYYwAAcC4AAPOKAADZ4AAAGQAAAE3EAAA1AAAAGQAAAC7CAABGFAAA254AAD9pAACPAAAAFxUAAEheAACPAAAANQAAADUAAACPAAAA4RoAAG8AAABPywAANQAAAI8AAABskQAAGQAAAMQeAADhGgAAbwAAADUAAADBXwAANQAAAAgCAACPAAAAAgIAAFAAAABGFAAAFgAAABUAAABvAAAAUAAAAFAAAABX4wAAESYAADUAAAD74gAAvMoAAEYUAABGFAAARhQAAFAAAADhGgAAFQAAAK68AADhGgAAUAAAADUAAAAZAAAANQAAABUAAAA5UgAAFF8AAFAAAABGFAAAogQAAFAAAACzAAAAbwAAABUAAABIbQAAGQAAAEFeAAA1AAAAmbgAAEYUAABogAAAgH0AAN1UAABM7QAAx7UAAIRoAAAfKwAAMdAAADUAAABvAAAAUAAAADUAAAA1AAAA0fcAADUAAAC95wAA2RsAAFAAAADxMQAAEowAAAAAAABQAAAANQAAAG8AAACTUAAAswAAADUAAADEHAAANQAAAAICAACPAAAANQAAANfFAADhGgAAFQAAABiiAABQAAAAUAAAAFAAAABvAAAANQAAAFTlAACPAAAANQAAAG8AAABvAAAAbwAAAG8AAABQAAAAQ9AAABXkAAA1AAAANQAAAIOpAAAZAAAAGQAAADUAAABQAAAAFQAAAPYLAAB8BQAASG0AAPDkAABQAAAANQAAAAAAAABGFAAAcvwAALbBAAD2FAAAmPIAADUAAAA1AAAANQAAAEYUAAA1AAAANQAAALhbAAA1AAAAFQAAAJsWAADhGgAANQAAAAMPAAAUZwAAA4QAAOeTAADhGgAA4RoAAFAAAABvAAAAUAAAAG8AAADhGgAAbwAAAAAAAABGFAAAGQAAAEEiAABQAAAArH0AABYAAABQAAAAjEIAAGAuAAC85gAA4RoAAN7tAABvAAAAUAAAAFAAAACLvQAAvIkAADUAAABV4gAAW1cAAFAAAACPAAAAMOUAALTbAABQAAAAOxQAANPpAAAWAAAANQAAAG8AAACVsQAA3G4AAFAAAABQAAAAzkUAADUAAAC1IgAAbwAAAI8AAABQAAAAFQAAAACXAACWBQAANQAAAGW\u002fAABWnwAAUAAAAKI+AABvAAAA4RoAAEYUAAA1AAAAVEEAAI8AAAA1AAAAFQAAAFAAAAAIAgAA31UAAFAAAAAZAAAAFo8AAMhpAAAWAAAAGQAAAEYUAAA1AAAA4RoAAFAAAAA1AAAAbwAAAFAAAABhsgAAbwAAAPh1AABdmQAANQAAADUAAABQAAAAolAAADUAAAA1AAAAp2kAAFAAAAA1AAAAUAAAADUAAABO8gAAGQAAADUAAAA5JAAAYXQAAI8AAABQAAAAGQAAAHwuAADhGgAApCMAAI8AAABQAAAAFgAAAG8AAADELAAANQAAAFAAAAAAAAAAGQAAAJJsAADhGgAANQAAAC\u002fbAABvAAAAdykAAFAAAACPAAAAFQAAABkAAABLhQAAMQQAAMTMAAAqlgAA9iAAABYAAADhGgAAz1oAADUAAADqEgAAOesAABDqAADyfwAAHXoAAJVcAADhGgAAUVEAAEIfAABzMwAA4RoAAFAAAABIYAAAGQAAADUAAABQAAAAEIQAAL0BAAA1AAAANQAAABkAAAAfkAAAxBMAAOCpAAA1AAAAAAAAAEYUAACJeAAAjwAAAFAAAAAVAAAAUAAAADUAAAAvgwAANQAAAOEaAAA1AAAANQAAADUAAADHbQAANQAAADUAAADNZwAAUAAAADUAAAA1AAAAvQEAAPCoAACYugAACAIAADUAAAAVAAAAqWcAABf5AABZegAAwJEAAM8aAAD8pwAANQAAABUAAABQAAAANQAAACzGAACPAAAA4RoAAMgfAABQAAAAwDkAAEYUAAA+hAAAASIAAADwAADUvQAA4RoAABkAAAACAgAANQAAADUAAAAVAAAAQuAAAKAtAADZNgAARhQAAFAAAAA1AAAAUAAAAPCuAABKWQAAATUAAEYUAABABAAANQAAAFAAAABIwAAAuSoAAIDzAAAVRQAANQAAAC63AACDfQAAGQAAAOEaAAAOfQAAupkAAAAAAABcAwAANQAAADUAAAD7awAAFQAAADUAAAA1AAAA4RoAAJcSAACAiwAAJkkAANPQAABFAAAA4RoAAB8GAADKjwAAAAAAAN\u002fAAABXRQAAjwAAAO5RAABGFAAAZ0kAADUAAABm\u002fwAAxBMAAFAAAAAZAAAANQAAADUAAAA1AAAAGqwAADUAAAA7PAAANQAAADUAAABQAAAANQAAAOEaAAC9sQAA4RoAADUAAAA1AAAAUAAAAG8AAAD68wAANQAAAB7TAABoogAA4RoAAKlhAABGFAAAUAAAAI8AAAB1TgAAwp8AAG8AAAAWAAAAlToAACPQAAAHcAAAki4AADUAAAC7BgAAXMIAAOEaAAA1AAAAhwAAAAAAAAAZAAAANQAAAFAAAABvAAAAEN4AALQsAADhGgAAAAAAAJEuAAAWAAAANQAAAONYAAA1AAAAfs8AADfYAAAZAAAAO\u002f4AADMVAAAFUQAAUAAAADUAAABZwAAARhQAACxMAAA1AAAARhQAABUAAADXTQAA0d4AAOtwAADGNAAAGQAAAEYUAABQAAAAvWEAAOEaAAAhHwAAQc4AAF0yAAAZuwAANQAAAIicAAAWAAAAbwAAADUAAAA1AAAAbwcAAOEaAABQAAAAv9YAAFAAAAAIAgAAll4AAEYUAAAZAAAAj4IAAFAAAAC+6wAA+KMAANN4AAAZAAAAbhIAAJfBAABvAAAAbwAAAEYUAAB\u002f1wAANQAAAOEaAABQAAAAUAAAADUAAABQAAAANQAAAFAAAABOWAAANQAAABYAAADWOwAANQAAAKRFAADhGgAAUAAAAC7yAADGIgAA7pwAAAgCAABRoAAAxz0AADUAAAA1AAAANQAAADUAAACAVQAANQAAAFwDAAA1AAAAFQAAAGPoAAA1AAAANQAAACRyAACShAAAGQAAAP+sAAA1AAAAYsAAACpyAACemwAA4RkAAFdWAABvAAAAr3cAAOEaAABGFAAAJ9cAAN6GAAA1AAAAUAAAADUAAAAcGwAA3UMAADUAAAAcbQAAUAAAACApAABPGwAAUAAAAH2hAAA1AAAANQAAAPZUAAAqIwAAbwAAADUAAAAT1QAAyzMAAEYUAAD4PgAAKdMAADUAAADOjgAAKIUAAHqSAAA1AAAANQAAAFAAAACWYQAAZu4AAJFUAADhGgAA9xQAADUAAAD3QAAANQAAABMOAABQAAAARhQAADUAAAA1AAAAREoAAI8AAAAAAAAA4RoAAHryAAC7dwAAFgAAADUAAABvAAAANQAAABkAAADDvwAAeoAAAOEaAACo7QAAswAAAHvyAABGFAAAFQAAABYAAAAVAAAARhQAAKudAADHdAAAUAAAADUAAADFcgAANQAAAI6BAAAwZwAAk4kAAFAAAACkWgAAE38AADUAAAAiMwAAhaoAAAhpAADJdQAAGQAAAI8AAADhGgAARtsAADUAAAA1AAAAbwAAAG8AAADhGgAAUAAAADUAAABXHgAAguoAAOEaAAAZAAAA4RoAABILAACPAAAA+a0AAHOgAAAZAAAAUdcAAALZAABQAAAANQAAAIvwAAA1AAAAwXgAAA2qAACPAAAA4RoAAAAAAABQAAAANQAAAEKVAAAIAgAAFgAAABkAAAAVAAAAuwYAAM5oAABQAAAAIHoAANK4AABGFAAAbwAAAEYUAAB1WAAARhQAADjEAABxSQAA4RoAAEYUAABQAAAATQcAAD2TAABQAAAAidMAAOEaAACkZAAAGQAAADUAAAA1AAAAtDMAADx8AABvAAAANQAAAFAAAABLxwAAKJ4AADUAAAAytwAANQAAADUAAAA3qwAA4RoAAEYUAACMIwAA+j8AAI8AAAASOwAA\u002f6wAALkfAABvAAAAbwAAADUAAAA+bAAA+eIAAMJLAAD2CwAAbwAAAFAAAAAlLAAAFQAAAISfAABQAAAA2tAAAFAAAAA1AAAAUAAAAAVDAAB7WQAANQAAAFAAAABvAAAA6QYAAG8AAABQAAAAEdoAADUAAABGFAAAUAAAAC\u002fnAABQAAAAjwAAAFAAAABGFAAAUAAAAOEaAABGFAAANQAAADUAAAA1AAAAx1gAAFAAAADfdgAAFgAAALsGAAAFXwAAmR8AADUAAAA1AAAA4RoAAFaZAABQAAAAzO8AAIp0AACzAAAARzQAAG8AAAA1AAAALj8AAOEaAADhGgAA\u002fJwAAEYUAAA1AAAAFQAAABYAAACg1AAA7KkAACv+AABvAAAANQAAAFAAAABQAAAAbgAAAI8AAAAUwAAACAIAAEYUAAC3mwAAGQAAAC5YAAAZAAAA4RcAAOM9AAASjwAAgXYAADUAAABQAAAAUAAAAI8AAAC8DAAANQAAAEYUAADhGgAAUAAAAEYUAABYxAAAbwAAADUAAABGFAAAFgAAADUAAACJhQAANQAAADUAAAA1AAAA1tYAAEYUAADULQAANQAAADUAAADhGgAAnlEAAG8AAADhGgAAFQAAAFAAAAA1AAAAGQAAAOEaAABHcAAAjwAAAFAAAADfpgAAUAAAADUAAAA1AAAABQUAANMOAADhGgAACAIAADUAAABQAAAAqyoAAOEaAADhGgAA49QAABUAAAD6IwAA4xwAADUAAAA1AAAAqioAANkRAABKtAAAGQAAAFAAAACzAAAAw40AAOw4AAA1AAAA4RoAADUAAACPAAAAsH8AADUAAAA1AAAANQAAACEtAAARRwAA4RoAAAJzAAA1AAAANQAAAFAAAADhGgAABkEAADUAAABtdwAA4RoAABkAAAAvwQAANQAAADUAAACzAAAA9a8AAL\u002fjAAA1AAAARhQAAFAAAAA1AAAARhQAADUAAADZlAAAJS0AADUAAABvAAAANQAAAEQrAAB5hAAA4RoAAFAAAABvAAAARhQAAI8AAABcAwAAjwAAAJAkAAA1AAAAAAAAAHLRAAAppgAANQAAAKjEAADhGgAANQAAAOEaAAA1AAAARhQAAGCuAABsRQAA8UAAAOEaAAA1AAAAnqYAADUAAADhGgAA8zIAAKzCAADX5wAAdDIAAEYUAAAPhgAAXUEAAFAAAAA1AAAANQAAAEYUAABIWwAAbwAAADUAAAAZAAAAUAAAABUAAAA1AAAAGQAAAG8AAAAKdgAAX8gAAFAAAABfhgAAGQAAAA3hAAA1AAAAcA8AACz2AABQAAAAU7MAAPzqAAA1AAAAbwAAAEgJAACLcwAARhQAAKdTAABbfgAA4RoAACIyAAA1AAAANQAAAGYFAACBXQAAFQAAABYAAABqsQAAfmMAAGZvAADz5AAAPjMAADUAAABQAAAAAfIAADUAAACYLwAAUAAAAHxKAABvkQAANQAAADUAAADhGgAAGQAAAHrBAAD94wAAbwAAAKmRAABvAAAAAAAAAGwlAAA1AAAAUAAAADUAAABGFAAAUAAAANQaAAA2LwAAGQAAAI8AAAA1AAAAGQAAAMN0AADhGgAA\u002fVwAAI8AAADZvQAAUAAAAGXHAABvAAAANQAAABYAAAA1AAAAI14AABUAAABGFAAA4RoAAJxOAACPAAAARhQAAIkFAABQAAAAFgAAABTKAABcAwAAjR4AADzlAABvAAAAFgAAAF4jAADwmAAANQAAAHXIAAC6CQAANQAAABVAAAA1AAAAuWcAAEYUAABvAAAAAAAAAEYUAABQAAAAbwAAAFAAAAAZFwAAUAAAAFAAAAAkVgAArPgAAOEaAAA1AAAA3XsAALAmAABGFAAAGQcAAI8AAAAAAAAAAgIAAFAAAACPAAAAwy8AAJb\u002fAACqGgAAUAAAADs4AADhGgAAUAAAABkAAADJCgAARhQAAPHmAABvAAAAbwAAAFAAAAA1AAAAy\u002foAADUAAADhGgAANQAAAI8AAABfJwAAFgAAADUAAAA1AAAA4RoAACXTAAA1AAAArx4AAEYUAACzAAAAOjgAAKAtAAA1AAAARhQAAJSyAABntAAA4RoAAOYEAAA1AAAANQAAADUAAAAZAAAA2gQAAFAAAAAWAAAAUAAAADUAAADaaAAANQAAAPe\u002fAAA1AAAANQAAAFAAAAAVAAAAUAAAAJ3lAABvAAAAUAAAABYAAAD7WgAANQAAAFAAAAAWAAAAFgAAADUAAABQAAAA4RoAAD74AABQAAAA2XYAADUAAACZCwAARhQAAOEaAAA1AAAAAgIAAI8AAAA1AAAAQxsAAI8AAAB6owAAjwAAAByoAABQAAAANQAAADUAAAAhpwAARhQAALMAAAC9YQAAFQAAAELAAAA1AAAAx2UAANHnAAA0IwAAdWIAAGiUAABzHwAANQAAAGybAADOYAAA4RoAAKpcAAA1AAAANQAAAKLcAAA1AAAArxYAABDfAABGFAAAcn8AALKbAAA1AAAAzXkAAG8AAACrtgAABtYAAHv\u002fAACHAAAAUAAAANr4AAB\u002fPgAAYW0AAFAAAAA1AAAANQAAAI8AAABQAAAAMS0AAOEaAABrfQAAUAAAAAvCAAAWAAAA\u002f6wAAFAAAAA1AAAA2jYAABUAAACPAAAAbwAAAAAAAADhGgAAswYAABYAAADhGgAA4RoAAM3xAADv0wAANQAAABkAAAD4OgAAjwAAALOsAADhGgAAYG0AAFAAAACPAAAANQAAAFAAAAA1AAAAUAAAADUAAADhGgAAuOAAAFkaAAA1AAAA4RoAAKYHAAA1AAAAVmMAADUAAABQAAAAw3AAADUAAACYZgAANQAAAOEaAAD\u002fGwAAUAAAAPjyAACPAAAAADkAAO93AABvAAAAUAAAAFAAAAD\u002fUAAAtDEAAEYUAABQAAAAUAAAAHmxAAA\u002fFQAAUAAAAOEaAAA1AAAA9d8AAI97AABvAAAANQAAADUAAAA1AAAA4RoAAI8AAABQAAAAmF8AADUAAAD\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\u002fJgAABYAAABuAAAAGQAAAOEaAACD1wAA540AABYAAABQAAAANDoAABkAAADUQgAAbwAAAH6wAAA1AAAANQAAAKPvAAAZAAAA0EgAALMAAABQAAAANQAAADUAAABQAAAANQAAAOX6AAC7BgAAYrUAAPGdAABRlwAAjwAAAG8AAAC5BQAAUAAAAG8AAAAVAAAANQAAABkAAACPAAAANQAAAEYUAABvAAAAUAAAADUAAABGFAAANQAAADUAAAA1AAAAUAAAAI1tAABB+AAANQAAAG8AAAAZAAAAFXwAAEYUAABBbwAAto4AAEYUAAAZAAAANQAAADUAAABQAAAAWjAAABS6AACEdwAA9CsAADQkAAC3ygAAFQAAADUAAABQAAAA4RoAAFAAAADhGgAAyasAAFAAAABoLwAA4RoAAAQXAABQAAAANQAAADUAAADsdgAAJOMAABUAAACcjwAAGQAAAFXVAAA1AAAAGQAAABkAAABJ7AAAbwAAAEYUAACPAAAAbwAAAHqqAACzAAAANQAAAP3VAAA1AAAANQAAAD0MAAA1AAAAaaIAAEYUAAArbwAARhQAAL22AAA1AAAAUdkAAA+2AAA1AAAARhQAAFAAAACIygAAbwAAAEYUAADVvwAAZuQAAG8AAAB1eAAAY6UAAAAAAAA1AAAAFsoAAEYUAAClQQAAGQAAANP7AAAr2gAA4RoAADUAAAA1AAAANQAAAOEaAAA1AAAAidsAAEp8AABZogAANQAAACG0AABGFAAAFgAAAFAAAAAtLgAAkgQAABYAAABvAAAARhQAAMbEAADhGgAAEGcAAL0BAAD7\u002fwAANQAAABkAAADhGgAAbwAAADUAAADE9AAAjwAAAGERAABvAAAAIhQAAOEaAAAWAAAAbwAAAN0vAACXnwAA2ncAAMlNAACPAAAA0qMAALp4AADauQAAqkYAAOEaAABrEQAAxykAABYAAAA1AAAANQAAADUAAAA1AAAAs\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\u002fXAABQAAAANQAAAEYUAACB0wAARhQAADUAAAA8rQAASRIAADUAAAA1AAAA4RoAAFAAAAA1AAAAumoAAAgCAABKcwAAVAcAAJcPAADqDAAANQAAAOEaAAB1UQAAweEAABYAAACzAAAANQAAAEYUAABvAAAAbwAAANB7AADLLAAARhQAAGHLAAAZAAAAsjoAADUAAABlVwAARhQAAOEaAABQAAAANQAAAG+HAABp8AAAqr0AADUAAAAZAAAAVN4AAMBdAABQAAAA7GoAAO9VAADcggAAGQAAANszAABGFAAATHYAABkAAAAMZgAAbwAAAN+HAACd4gAANQAAADUAAABQAAAAUAAAAAlcAAA1AAAANQAAAFAAAAA5XgAA5BwAABYAAACovwAAxAoAADUAAABArwAANQAAAG8AAABGFAAAAAAAAN2NAAAcrwAAswAAAEYUAABQAAAA5lsAAD+lAAA1AAAA4RoAAMdeAABAtQAAuCwAADUAAABGFAAAswAAAEYUAAB4gwAAjwAAABUAAABGFAAACvEAAGkdAACPowAAUAAAADUAAADDjQAAcTAAAIDEAAA0ogAAAAAAADUAAABQAAAAjwAAABYAAAAZAAAAuBYAAOoEAABvAAAAWXEAADUAAABQAAAAVx4AAI8AAAA06QAA9AYAAG8AAABvAAAANQAAAFAAAAAVAAAANQAAAOZbAAA1AAAANQAAAEsaAAC6wQAAFQAAAEoIAAD+hQAA3f0AAFAAAAAVAAAANQAAAFAAAABGFAAAhr4AADUAAADhGgAANQAAAG8AAAAVAAAAkq0AADUAAABvAAAAV9QAANMnAAB8gAAAuwYAAEYUAAAZAAAARhQAAEYUAAAEpgAAG5MAADUAAABvAAAAn1cAAIB9AABvAAAAQwoAAG8AAAA1AAAANQAAAEYUAAAdTwAANQAAABUAAAA1vQAADB0AAEYUAABQAAAA1ccAAOEaAAAVAAAAM9cAAOEaAACzAAAARhQAABkAAAAWAAAAIa0AAEYUAACPAAAA0w4AADUAAAAvXwAAbwAAAG1gAABQAAAAUAAAAN73AAAX0wAAfDgAAFAAAAAE3wAANQAAAIafAAB++QAANUkAAMxyAAAWAAAAjGIAAPwSAAA1AAAAEDEAADUAAAA1AAAANQAAAFAAAABQAAAAeQcAAHqpAAA1AAAAFQAAABkAAAA1AAAAUAAAACeDAAA\u002fUwAA5BcAAGG0AABQAAAAUAAAAB2lAAA1AAAA0RsAAOEaAAA1AAAA36AAAMp9AAA1AAAA4RoAAFvzAAA1AAAANQAAAG8WAADZ4AAA4RoAAEV+AAA1AAAA5hQAAGj2AABGFAAAuwYAAI8AAAA1AAAABkoAALMAAABQAAAANQAAAEYUAADhoQAANQAAALhCAABGFAAAPP8AAFAAAABQAAAAHlQAAEYUAADhGgAAWRwAAF8QAADqBAAAMs0AAJsuAADJBwAA+60AADoTAABvAAAAbwAAAG8AAABGFAAAhOAAADUAAABQAAAARhQAADUAAAA1AAAANQAAAI8AAADj3gAANQAAAFskAAA5DwAAkBIAABkAAAA3OAAA3kMAABYAAAA1AAAAVIIAABYAAAD7EgAARhQAACYLAAAZAAAAAAAAAG8AAABGFAAAAAAAADUAAABQAAAABW4AADUAAADhGgAANQAAALsBAAAfYwAAhvMAAMLpAAAVAAAAFgAAAOEaAABQAAAANQAAAJ4LAABdDQAAUAAAAOAaAAAuwAAAFgAAABkAAAAWAAAAfvkAAG8AAAAkgQAAAAAAAI8AAABvAAAAvQEAAFAAAAAZAAAAT\u002fsAAE7rAACarAAA4RoAAITyAACa9wAAco8AABkAAAD\u002ftgAAFAUAADUAAABGDQAANQAAAI+\u002fAAA1AAAANQAAAG7dAAA1AAAANQAAADUAAABQAAAA70QAADUAAADWYwAANQAAADUAAACpBgAA\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\u002fAAA1AAAA0isAADUAAABGFAAAUAAAADUAAAD2WwAAUAAAAFAAAABumQAAGQAAALG3AAA71QAAUAAAAI8AAAA1AAAAvt8AAE2wAABGFAAAGQAAAHXhAAA1AAAAa3IAADUAAAA1AAAARhQAAIReAAA1AAAAeG8AADUAAAA1AAAANQAAADUAAAA1AAAANQAAABkAAAA8+gAAUKEAADksAAA1AAAAUAAAAI8AAAA1AAAANQAAAGcdAABIUAAANQAAAFAAAACApQAAGQAAAOEaAAA1AAAANQAAABYAAABI6AAAl+sAABRoAAAVAAAA4RoAAPZTAADdQQAANQAAAOEaAAAWAAAANQAAAOEaAAA1AAAANQAAAFAAAAA7OwAAKbIAAFAAAADSaAAAJ2IAAG8AAABQAAAAUAAAAI8AAAA1AAAApp4AAP4XAADlRwAANQAAADUAAADhGgAAFgAAAPkTAAA1AAAAyO8AADUAAACn+gAAbwAAAEYUAACMtQAANQAAAEaaAABQAAAA62YAADUAAAB8wAAAiX0AAFAAAAA1AAAAZOgAAFAAAAAZAAAAbwAAADUAAAA1AAAANQAAAFAAAAA1AAAAjwAAACpuAACcTAAAQwoAAI8AAAADOgAAZUsAAG8AAAC32gAAobIAABkAAABodwAANQAAAEYUAABGFAAANQAAADERAAAZAAAAXXcAADy1AABlzgAAUAAAAFWfAAAL6wAAN\u002fAAAG8AAABvAAAAFQAAAG8AAABGFAAAw18AABYAAAA1AAAANQAAAOEaAAC5gAAAxccAAEiYAACDDgAAFgAAABkAAAAVAAAAXlMAAFAAAAAu2gAAXYoAACn\u002fAAA1AAAAbwAAAFAAAADbrAAA+bwAAG8AAACPAAAA\u002fZkAADUAAABOiwAAklUAAG8AAAD\u002fxQAANQAAABkAAAAWAAAANQAAADekAABQAAAANQAAAD5aAAAjBAAA4RoAAOEaAABQAAAANDgAABYAAAAZAAAAHm0AACD1AAA1AAAAl1EAABxsAACPAAAANQAAAHmTAACPAAAARhQAAGx5AAA1AAAAUAAAAJAlAAA1AAAAM2EAAGb+AAAAAAAApswAAOEaAABvAAAA4RoAAOEaAAA1AAAAktMAAEXuAACPAAAANQAAAHuoAACzAAAANQAAADUAAADhGgAA4RoAAG8AAAA1AAAAGQAAADUAAABQAAAARhQAAEYUAAAVAAAAWoUAAIAFAABQAAAARhQAAP\u002fjAACVOgAAtSIAADUAAABGFAAAMeAAAEYUAABQAAAActYAAMxzAAA1AAAAdLUAAP1qAAA1AAAAOywAAEYUAAAfwQAANQAAAHCAAABQAAAAUAAAADdQAADhGgAAeEkAAG8AAABvAAAARe0AABkAAADKUwAAvAwAAOEaAABQAAAAcu8AAI+QAAAJXgAAGQAAABkAAABQAAAANQAAALm\u002fAAAlngAARhQAAFAAAAAqJwAAWWkAAPT6AAApGgAAULoAAFtDAABqqwAAjwAAAInOAAAZAAAA7GUAAJkfAAA1AAAA+r8AAAgCAAA1AAAAGFwAAAGQAAAWAAAAjg4AAODyAACq4QAAO0wAAC9fAABQAAAANQAAADTIAAA1AAAAZdUAAMesAAAVAAAAckEAAFAAAAA1AAAAAAAAALMAAABQAAAA4RoAADUAAAChKQAAcBoAALsGAAAm3QAANQAAAJuEAAAWAAAAbwAAAEZtAAA1AAAAUAAAADUAAADhGgAAfcMAAIYHAAA1AAAA6mkAAMrMAADhGgAAFgAAABV+AAAVAAAARhQAADUAAAA1AAAAbwAAAONtAAB9UwAAB5YAAKfaAABQAAAAUc0AAEYUAABvAAAAG+UAAOEaAADJNQAA9nUAAI3WAADsGAAANQAAAFobAAA1AAAAILYAAIreAABQAAAAXsgAAA9NAAA1AAAAUAAAAFAAAABQAAAAArYAAI8AAAA1AAAAnyUAAL0BAADJpgAANQAAAFAAAAC9AQAAbwAAAHYPAACc5QAANQAAAG8AAABQAAAA4RoAAEYUAABaKAAAme4AABkAAAARHwAAAAAAABkAAADKnAAAjwAAAOEaAABs1gAACMYAAHVfAAAVnQAANQAAADUAAADTCQAANQAAADUAAABQAAAAUAAAAOzRAABQAAAAFQAAADUAAAAELgAANQAAAG7AAAA1AAAACAIAAGMdAAAZAAAAAu0AAEYUAABQAAAAAQgAABYAAAA1AAAANQAAAOEaAACzAAAAAAAAAOEaAAAAAAAAFQAAAI8AAACPAAAANQAAAMLjAAAVAAAAQb0AAGDnAACzAAAAbwAAAFAAAAAZAAAAqAYAAI8AAABT1gAAbz0AAEYUAADZEQAANQAAAFAAAADZEQAAGQAAAAAAAABLkQAAUAAAAHPUAABQAAAA\u002fHAAAE69AABQAAAAsJ4AAEfPAABvAAAAjwAAAAfUAADCXAAAdXwAAKjyAAA1AAAA2zQAALsGAAAZAAAA2bYAAI8AAAA1AAAANQAAAEYUAAA1AAAAwFIAAFAAAAD7lQAAJysAANG6AADK1AAAUAAAAFAAAAA1AAAA4RoAANnLAAAWAAAAUAAAANAWAADUYwAAlWQAAFyIAAAVAAAAFQAAABkAAABQAAAAMdsAAL0BAAB3sgAARhQAADUAAACEqQAAMhUAAOzaAAAVAAAANQAAADUAAAAAxgAAFgAAAFAAAABvAAAA5z8AAABYAACzPQAAcx8AAEYUAABQAAAAFQAAAEWfAABGFAAAmRgAABYAAABabAAAQlMAAGvcAAA1AAAAUDYAAMylAADPBAAAGQAAAG8AAAA1AAAAQZ8AACc2AACrPQAAbwAAADUAAAAZAAAARhQAAG8AAAAWAAAAVK4AABkAAAA1AAAA4RoAAI8AAAC82QAAAwUAADUAAAA1AAAAswAAAFAAAABvAAAAGQAAADUAAAAVAAAAGQAAADUAAABR2QAAbwAAAPq\u002fAADhGgAANQAAAF7xAADx\u002fQAA8ykAAFAAAAA1AAAAY7sAAG8AAACC3gAANQAAADUAAAAAAAAAfxIAAM0jAADUvQAARhQAADUAAAA1AAAAjc0AABkAAAAAAAAAUAAAACcqAADREwAAGQAAAIG9AAD9vAAAOzwAADUAAABQAAAADlAAABkAAAA4UAAA93kAAOEaAAA1AAAA+k8AAN+xAAC6gQAANQAAAFhCAAB91wAAMQgAAHXhAAA1AAAA3xIAAJG4AABJQQAA\u002fYsAAFAAAAAAAAAAlCUAADUAAACdBwAAjwAAAOEaAAA1AAAANQAAAFAAAAAVAAAAbDYAAJTTAABGFAAA4RoAABYAAAAWAAAAlM8AADUAAAA1AAAA4RoAANUFAAAZAAAANQAAABfAAABGFAAAUL4AAAd7AABQAAAANQAAADUAAABQAAAAp7cAAEYUAABGFAAAWkEAALSGAAA1AAAAUAAAADUAAAA1AAAAUAAAAChLAABvAAAANQAAAIEHAABGFAAA9QUAAAN0AAAVAAAANQAAAFAAAAA1AAAAkkMAAAyJAAA1AAAANQAAAN\u002fEAABQAAAAvw4AALGJAAAkWQAAbwAAADUAAAA1AAAA4C4AAH\u002f9AADWrAAAFgAAANEMAAA1AAAAAAAAADUAAADhGgAANQAAADUAAABiigAA4RoAAEYUAABhKQAA4RoAABXrAAA1AAAA4RoAADUAAABQAAAANQAAADZCAABGFAAARhQAAMdSAABQAAAANQAAAEYUAADdSwAAUAAAADUAAACeBgAAUAAAADUAAAAxzgAARhQAAJf2AAAxhgAAUAAAAFAAAAA1AAAAlo8AADUAAABQAAAANQAAAEYUAABHzwAANQAAADUAAABqeQAAFgAAAI8AAAA1AAAAUAAAAOEaAAADwQAAbC4AABkAAABvAAAARtoAALehAABQAAAAjwAAADUAAAAX1wAA6vMAADUAAAA1AAAANQAAAEYUAAD0OQAARhQAADUAAACzAAAANQAAADUAAADZSAAANQAAAC+gAAA1AAAARhQAADUAAAA1AAAA2g8AADUAAAA1AAAANQAAADUAAAA5kwAAUAAAABYAAABQAAAAUAAAALMAAAAZAAAAQosAABiXAACf0AAAhwAAAJPiAABQAAAAi7MAADUAAAD3\u002fAAA+5UAADUAAAA1AAAAjwAAAOEaAADA1AAARhQAAIgeAAChawAARxgAAKZlAAA1AAAAUAAAADUAAABQAAAAEiUAAGOJAABQAAAANQAAAO2qAADhGgAAGQAAAFMJAACqpgAAv3gAAFAAAABdTwAAUAAAANx6AAAZAAAAUAAAADzOAACsmQAARhQAADUAAADhGgAAnuYAAI8AAADr2AAAqJgAAOEaAABOIwAAZOoAABUAAADhGgAAYR8AAEEgAABQAAAAAAAAAI8AAACPAAAADkAAAJDQAAD6bgAAGQAAAEkGAAC7yQAAtW0AADUAAAAAAAAASj0AAFAAAAD\u002fawAA4RoAAFAAAAB5MgAAxSEAAFAAAAALFAAAbwAAAEYUAAAZAAAANQAAADUAAAA1AAAA4ZMAABYAAADcKwAANQAAAFAAAABz1wAANQAAAOEaAACPAAAAAAAAAF5aAADsKAAAoqwAADUAAAAAAAAANQAAAFAAAABQAAAAy68AAEVgAAA1AAAAFgAAABlJAABJEAAA344AAFAAAAAKQAAAUAAAAKj4AACjIAAAFQAAAFAAAADaQgAAbwAAAOMiAADhGgAANQAAAHAPAABQAAAAGQAAAAgCAAAGnQAAbRwAAG8AAAA1AAAAkIAAADUAAADChgAANQAAALKBAABQAAAACAIAADUAAABQAAAARhQAAHS\u002fAABQAAAAfocAAGsaAABGFAAAGQAAAOEaAABGFAAACw4AALbHAACFZQAANQAAABUAAAAm\u002fwAA0c8AAL8jAABxYQAAAuEAAEYUAAAUUgAAxDgAADUAAAA1AAAANQAAABDzAABQAAAAbwAAADUAAADhGgAAJhIAANtdAACWfwAAaW0AAOEaAABQAAAAGQAAAA3TAAA1AAAA4RoAAC41AAADdwAANQAAAFbcAABQAAAAVIcAAIdkAAA1AAAAwpgAALgZAABvAAAA4RoAAMYgAABbRQAAFQAAABkAAAB+FwAARhQAAPB8AAAHewAA4RoAAI8AAABvAAAAeqUAAFAAAACgrgAAhZ0AAK4rAAA1AAAAFgAAAFAAAADLYAAA4XMAAKVJAAA1AAAAFQAAAHpaAABQAAAAy\u002foAAFAAAABnRAAAujMAALMAAADL0AAANQAAADUAAABGFAAANQAAAFDJAAA1AAAAswAAAG8AAAANvAAA4RoAAFAAAABGFAAA4RoAAEYUAAA1AAAANQAAAGgdAAA1AAAANQAAAG8AAAAVAAAARhQAAPbsAAA1AAAANQAAAG8AAADhGgAANQAAABkAAAA5UgAANQAAADUAAABTbQAAmGYAAGaHAADM3wAA2L0AADUAAAA1AAAAAAAAABYAAABGFAAARhQAAFAAAAA1AAAAFQAAABztAAAVnwAA\u002fLEAAPM6AABQAAAANQAAAB+qAACJUAAAptoAAFAAAACYNwAAxPUAAOEaAADvNgAAkbEAAJX+AAAcfgAAFgAAAG8AAADTRAAAfdIAADUAAAAhkgAAn7YAADUAAADMcwAAUAAAALb\u002fAACO5QAAXOEAABYAAADprAAAjwAAAC+lAABGFAAAutMAAERKAABQAAAAGQAAADUAAADhGgAAh0YAAD2hAAA1AAAA4mEAADUAAABGFAAA+L0AAG8AAAA1AAAAGQAAAAAAAAB2dwAANQAAADUAAABpawAANQAAADUAAABDAAAAz\u002f0AANSeAADWywAA2tAAAKofAAA1AAAA8\u002foAAFAAAAD\u002f+gAANQAAAPWoAAA1AAAAGQAAAFAAAACrZQAAoFcAAIxLAABwDwAAswAAAMGyAABQAAAANQAAAFAAAADhGgAA9zQAAOEaAACPAAAAFQAAAAr+AAAZAAAAjwAAADUAAAC\u002fIwAA2o0AAAAAAABQAAAAGQAAAFAAAAA1AAAAGV0AADUAAABQAAAAAgIAADUAAACurQAAGQAAAOEaAACAYQAANQAAAEYUAAA1AAAAH3kAADUAAABGFAAAZg0AAGTPAAA1AAAAbwAAAG8AAABQAAAAFQAAAFAAAABMCwAARQAAALtDAABGFAAAH7QAAI8AAAA1AAAA4RoAAFAAAAA1AAAARhQAAFAAAAAuKwAAdY4AAAICAABQAAAARhQAAG2NAAAsLQAA4RoAAGflAABGFAAAhGMAADUAAABQAAAARhQAADUAAACTBgAAOb8AAFAAAACPAAAANQAAAL3XAAA1AAAA2n0AAF9sAADhGgAA7R0AADUAAACaKAAANQAAADUAAADhGgAAvJoAAF06AACPDgAAjwAAABUAAABDggAAUAAAAJAfAABGFAAANQAAAEO5AAA1AAAAUAAAAFAAAAAZAAAAwvYAADUAAACzAAAAUAAAAOEaAAD4MgAA9z4AAKqXAABN+QAAmAYAAFxmAAAWAAAAGQAAADUAAACzAAAAFgAAADUAAABa8gAAgtoAAIUdAAAZAAAANQAAAFAAAABvAAAAgV0AAKWUAACLOgAANQAAANeuAADb1gAA+oYAAC8YAAA+SwAANQAAAFAAAAAnfwAAUAAAADUAAACSIQAA4RoAAG8AAABQAAAAFQAAAFAAAACPAAAAuqkAAFwDAAAKuQAADSwAADUAAAAZAAAAr60AADUAAABQAAAAU60AABGzAABQAAAA2MIAADUAAADhGgAAFQAAAHw\u002fAABhQwAAjwAAAMrRAABQAAAAUAAAAOEaAAA1AAAAUAAAAIIYAACsvgAAUAAAADUAAABvAAAANQAAAC4KAABDNgAAsdAAAFpGAAA5fAAANQAAADUAAABGFAAANQAAAOhXAAA1AAAAQJ8AAOEaAAB5DgAANQAAAEYUAAA1AAAAXHwAADUAAABnZwAAbwAAAF81AABQyAAAUAAAAEYUAADhGgAAYVkAAAzRAACiXQAA4RoAAAAAAAAZAAAA7lYAAPdSAABGFAAAh6wAADUAAADhGgAA4RoAAHWWAAA1AAAARPEAADUAAABQAAAARhQAADUAAAA1AAAA3tkAAHMfAABQAAAAvYgAAOYHAABSiAAArroAAI4PAACb7QAAU\u002f0AAJ3UAAAYjQAAUAAAAOnXAADhGgAAR4YAADUAAACs9wAAAAAAABkAAADhGgAANQAAABkAAAA1AAAADcsAAFAAAACunAAAjwAAAL0tAABGFAAAFgAAABkAAABESgAAoR0AAG8AAABssgAANQAAAMdhAAA1AAAAEDcAAEYUAADtFwAA4RoAABkAAADfVgAARhQAAKJKAABvAAAAkqQAAFAAAABUigAANQAAAOEaAAA1AAAAxhIAABUAAAAZAAAANQAAALL4AAC0LgAAt28AAEBFAABQAAAAGhgAAFcFAAA1AAAAOLAAAEYUAAA1AAAAbwAAAH6NAAA1AAAAUAAAADUAAABvAAAARhQAAMOJAABQAAAANQAAADUAAAA1AAAAbwAAADUAAAA1AAAAdnMAAG8AAAAZAAAA4RoAABkAAADmnwAAUAAAAKwLAAA1AAAAjwAAADedAABquAAANQAAAFAAAABQAAAARhQAAJ6zAABLdAAANQAAAOEaAACJbQAAghoAAGvDAADYSAAAJUUAAAdoAAA1AAAAjwAAAGw3AAA1AAAAUAAAAN3IAABGFAAAzuIAAEIvAAA1AAAANQAAADUAAABvAAAA6pYAAEiXAAA1AAAANQAAADUAAAAZAAAAbwAAAFAAAAAaCwAAUAAAADNXAABQAAAANQAAADUAAADr9QAAPMoAAFAAAADIcAAANQAAAH\u002fFAABQAAAANQAAABkAAAA1AAAANQAAAG8AAADezQAAfo0AAI3WAADMTAAAGQAAADUAAAA1AAAANQAAADUAAABQAAAAGQAAAN0PAAA1AAAAUAAAAEC3AAAbMQAANQAAAObNAACPAAAAYLkAAHluAABQAAAAtysAADUAAABQAAAAA6AAABB\u002fAADhGgAARhQAABumAAAAAAAANQAAABkAAACLswAAUAAAAHWpAAC0gAAAD6IAACRjAAAMmQAAUAAAALMAAAA1AAAAjwAAAJQjAAA4OwAAFN4AAKpcAABQAAAA1OUAAG8AAABvAAAANQAAAAZDAADhGgAAXFgAAEshAADRWQAANQAAAI8AAAA1AAAAvMYAADUAAAA2vAAAbwAAAOoMAACavQAAAmwAANxUAABIXgAANQAAAGMpAABGFAAANQAAABkAAABGFAAAbwAAAEh+AAATywAAmwsAAEYUAABSUwAAbwAAABYAAADlQgAA1Z4AAKdIAAA1AAAAtToAAPhlAAAZAAAAigsAABUAAABvAAAAUAAAAN70AAA="},"yaxis":"y","type":"scattergl"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Source Port"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Destination Port"}},"coloraxis":{"colorbar":{"title":{"text":"Destination Port"}},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]]},"legend":{"tracegroupgap":0},"title":{"text":"Source vs Destination Ports Mapping"},"height":600},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('5599cfce-c562-43f6-8a8b-658a1d2752cf');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
<p><strong>Inference</strong>: We observe a high concentration of traffic around lower destination port ranges (0–1024) — this aligns with well-known service ports like HTTP (80), HTTPS (443), FTP (21), etc.Some traffic shows destination ports in the higher dynamic/private range (49152–65535), often associated with ephemeral ports and less structured traffic patterns.There’s a visible diagonal streak, indicating some port mirroring behavior, where the same port is used on both ends — this might be normal in certain applications but could also point to scripted behavior or replayed packets.</p>
</section>
<section id="correlation-heatmap" class="level3">
<h3 class="anchored" data-anchor-id="correlation-heatmap">3.4 Correlation Heatmap</h3>
<p>The heatmap visualizes the pairwise correlation between all numeric features in the dataset. It helps with:</p>
<p><strong>-</strong>Reducing redundancy: Highly correlated features may carry similar information and can be removed to simplify models.</p>
<p><strong>-</strong>Avoiding multicollinearity: In models like logistic regression, multicollinearity can distort the interpretation of coefficients.</p>
<p><strong>-</strong>Identifying strong predictors: Features highly correlated with the target (e.g., Label or attack_cat_encoded) may be useful for classification.</p>
<div id="39ead09a" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>numeric_df <span class="op">=</span> merged_df.select_dtypes(include<span class="op">=</span>[<span class="st">'int64'</span>, <span class="st">'float64'</span>])</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> numeric_df.corr()</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">12</span>))</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr_matrix, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, linewidths<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Feature Correlation Heatmap"</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference</strong>: Many flow-related features like Spkts, Dpkts, Stime, Ltime, and tcprtt show strong positive correlation with each other. This suggests that these may be redundant and one or two could represent the group.There is a clear block of high correlation among features, such as ct_srv_src, ct_srv_dst, ct_dst_ltm, etc. These are connection tracking features, and their collinearity implies similar behavior tracking logic.Features like ct_state_ttl, ct_dst_sport_ltm, and ct_src_ltm show noticeable correlation with the encoded attack label, hinting at their potential predictive power.Some features such as is_ftp_login and ct_flw_http_mthd appear relatively uncorrelated with most others, meaning they may offer unique information.</p>
</section>
<section id="pairplots" class="level3">
<h3 class="anchored" data-anchor-id="pairplots">3.5 Pairplots</h3>
<p>The pairplot displays the relationships between selected features and their distribution across different attack categories, using color-coded encoding.</p>
<div id="af981ec3" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>sampled_df <span class="op">=</span> merged_df.sample(n<span class="op">=</span><span class="dv">25000</span>, random_state<span class="op">=</span><span class="dv">43</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> [<span class="st">'ct_dst_sport_ltm'</span>, <span class="st">'ct_src_ ltm'</span>, <span class="st">'ct_state_ttl'</span>, <span class="st">'ct_ftp_cmd'</span>, <span class="st">'ct_flw_http_mthd'</span>, <span class="st">'attack_cat_encoded'</span>]</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>sns.pairplot(sampled_df[selected_features], hue<span class="op">=</span><span class="st">'attack_cat_encoded'</span>, palette<span class="op">=</span><span class="st">'deep'</span>, corner<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Pairplot of Selected Features by Attack Category"</span>, y<span class="op">=</span><span class="fl">1.02</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference</strong>: - Certain features like ct_state_ttl and ct_dst_sport_ltm show clear class separation, where some categories occupy distinct bands or regions — indicating high predictive potential.</p>
<ul>
<li>ct_flw_http_mthd and ct_ftp_cmd are sparse but distinct for a few attack categories, possibly linked to specific protocol misuse (e.g., HTTP-based fuzzing or FTP-based backdoors).</li>
</ul>
</section>
<section id="feature-distribution---numerical" class="level3">
<h3 class="anchored" data-anchor-id="feature-distribution---numerical">3.6 Feature Distribution - Numerical</h3>
<p>Frequency distribution of a numerical feature using a histogram, overlaid with a Kernel Density Estimate (KDE) curve. The histogram represents the count of data points within specific intervals (bins). The KDE curve provides a smoothed estimate of the feature’s probability density, helping to visualize the overall shape of the distribution.</p>
<p>This is important as it:</p>
<p><strong>-</strong>It provides insight into data skewness and variability, which affect scaling and model assumptions.</p>
<p><strong>-</strong>Identifies outliers or extreme values that may distort learning.</p>
<p><strong>-</strong>Highlights the need for normalization or transformation before feeding features into certain models (like Logistic Regression or KNN).</p>
<div id="c5367678" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>sampled_df <span class="op">=</span> merged_df.sample(n<span class="op">=</span><span class="dv">20000</span>, random_state<span class="op">=</span><span class="dv">43</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>dist_features <span class="op">=</span> [<span class="st">'dur'</span>, <span class="st">'sbytes'</span>, <span class="st">'dbytes'</span>, <span class="st">'sttl'</span>, <span class="st">'dttl'</span>, <span class="st">'sloss'</span>]</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature <span class="kw">in</span> dist_features:</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    sns.histplot(sampled_df[feature], kde<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'lightcoral'</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Distribution of '</span><span class="sc">{</span>feature<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(feature)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Frequency"</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-17-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-17-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-17-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-17-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-17-output-6.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference</strong>: Highly Skewed Distributions:dur, sbytes, and dbytes show heavy right skew — most flows are short and small, with a few large ones. These outliers could affect model performance and should be handled (e.g., via log-scaling or clipping).</p>
</section>
<section id="outliers" class="level3">
<h3 class="anchored" data-anchor-id="outliers">3.7 Outliers</h3>
<p>This boxplot is used to identify outliers across all numerical columns in the dataset.</p>
<div id="8eb11341" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>merged_df[numerical_columns].boxplot(rot<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Boxplot of Numerical Columns (Checking Outliers)"</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">"Boxplot of Numerical Columns (Checking Outliers).png"</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference</strong>:</p>
<ul>
<li><p>sload, dload, dbytes, and sbytes have extreme high values, possibly due to long flows or large data transfers.</p></li>
<li><p>stcpb, dtcpb also show large spread and high-value outliers.</p></li>
<li><p>Most other features have compact distributions, especially binary or categorical ones (e.g., is_ftp_login, ct_flw_http_mthd, etc.).</p></li>
</ul>
</section>
<section id="statistical-analysis" class="level3">
<h3 class="anchored" data-anchor-id="statistical-analysis">3.8 Statistical Analysis</h3>
<p>Performing summary statistics and outlier mitigation for all numerical features. Specifically,calculating descriptive statistics (mean, median, standard deviation, etc.) and use the interquartile range (IQR) method to detect and handle outliers.</p>
<p>This is important because:</p>
<p><strong>-</strong>Outliers can distort model performance — especially in distance-based algorithms like KNN or models sensitive to variance.</p>
<p><strong>-</strong>Replacing outliers with median values helps maintain the general distribution of the data without introducing extreme bias.</p>
<p><strong>-</strong>Generating summary statistics gives a quick overview of the spread, central tendency, and scale differences across features — which is useful for choosing scaling techniques later.</p>
<div id="9f60782c" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> merged_df.select_dtypes(include<span class="op">=</span>[<span class="st">'float64'</span>, <span class="st">'int64'</span>]).columns.tolist()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>exclude_columns <span class="op">=</span> [<span class="st">'sport'</span>, <span class="st">'swim'</span>, <span class="st">'dwim'</span>, <span class="st">'stcpb'</span>, <span class="st">'dtcpb'</span>, <span class="st">'Stime'</span>, <span class="st">'Ltime'</span>]</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>numerical_columns <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> numerical_columns <span class="cf">if</span> col <span class="kw">not</span> <span class="kw">in</span> exclude_columns]</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> numerical_columns:</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    median_value <span class="op">=</span> merged_df[col].median()  <span class="co"># Getting the median value</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    lower_bound <span class="op">=</span> merged_df[col].quantile(<span class="fl">0.25</span>) <span class="op">-</span> <span class="fl">1.5</span> <span class="op">*</span> (merged_df[col].quantile(<span class="fl">0.75</span>) <span class="op">-</span> merged_df[col].quantile(<span class="fl">0.25</span>))  <span class="co"># Lower bound for outliers</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    upper_bound <span class="op">=</span> merged_df[col].quantile(<span class="fl">0.75</span>) <span class="op">+</span> <span class="fl">1.5</span> <span class="op">*</span> (merged_df[col].quantile(<span class="fl">0.75</span>) <span class="op">-</span> merged_df[col].quantile(<span class="fl">0.25</span>))  <span class="co"># Upper bound for outliers</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Replace outliers with the median value</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    merged_df[col] <span class="op">=</span> merged_df[col].<span class="bu">apply</span>(<span class="kw">lambda</span> x: median_value <span class="cf">if</span> x <span class="op">&lt;</span> lower_bound <span class="kw">or</span> x <span class="op">&gt;</span> upper_bound <span class="cf">else</span> x)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>summary_stats <span class="op">=</span> merged_df[numerical_columns].describe().transpose()</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>display(summary_stats)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">min</th>
<th data-quarto-table-cell-role="th">25%</th>
<th data-quarto-table-cell-role="th">50%</th>
<th data-quarto-table-cell-role="th">75%</th>
<th data-quarto-table-cell-role="th">max</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Name</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">dsport</td>
<td>2059122.0</td>
<td>1.113252e+04</td>
<td>1.685974e+04</td>
<td>0.0</td>
<td>53.000000</td>
<td>1723.000000</td>
<td>1.697300e+04</td>
<td>5.886800e+04</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dur</td>
<td>2059417.0</td>
<td>7.606115e-02</td>
<td>1.522689e-01</td>
<td>0.0</td>
<td>0.003592</td>
<td>0.026416</td>
<td>4.494400e-02</td>
<td>8.299840e-01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sbytes</td>
<td>2059417.0</td>
<td>1.889829e+03</td>
<td>1.694382e+03</td>
<td>0.0</td>
<td>424.000000</td>
<td>1684.000000</td>
<td>2.854000e+03</td>
<td>8.684000e+03</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dbytes</td>
<td>2059417.0</td>
<td>7.685695e+03</td>
<td>1.124579e+04</td>
<td>0.0</td>
<td>304.000000</td>
<td>3080.000000</td>
<td>1.016800e+04</td>
<td>4.933000e+04</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sttl</td>
<td>2059417.0</td>
<td>3.100000e+01</td>
<td>0.000000e+00</td>
<td>31.0</td>
<td>31.000000</td>
<td>31.000000</td>
<td>3.100000e+01</td>
<td>3.100000e+01</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dttl</td>
<td>2059417.0</td>
<td>2.900000e+01</td>
<td>0.000000e+00</td>
<td>29.0</td>
<td>29.000000</td>
<td>29.000000</td>
<td>2.900000e+01</td>
<td>2.900000e+01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">sloss</td>
<td>2059417.0</td>
<td>3.742586e+00</td>
<td>3.253675e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>4.000000</td>
<td>7.000000e+00</td>
<td>1.700000e+01</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dloss</td>
<td>2059417.0</td>
<td>7.929287e+00</td>
<td>9.302497e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>5.000000</td>
<td>1.400000e+01</td>
<td>3.700000e+01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Sload</td>
<td>2059417.0</td>
<td>5.757150e+05</td>
<td>5.487677e+05</td>
<td>0.0</td>
<td>80777.226560</td>
<td>540740.750000</td>
<td>7.211172e+05</td>
<td>2.618206e+06</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Dload</td>
<td>2059417.0</td>
<td>1.325871e+06</td>
<td>2.008489e+06</td>
<td>0.0</td>
<td>76321.867190</td>
<td>669180.250000</td>
<td>1.046472e+06</td>
<td>9.474030e+06</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Spkts</td>
<td>2059417.0</td>
<td>2.404923e+01</td>
<td>2.342035e+01</td>
<td>0.0</td>
<td>4.000000</td>
<td>16.000000</td>
<td>4.200000e+01</td>
<td>1.140000e+02</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Dpkts</td>
<td>2059417.0</td>
<td>2.394334e+01</td>
<td>2.300996e+01</td>
<td>0.0</td>
<td>4.000000</td>
<td>18.000000</td>
<td>4.200000e+01</td>
<td>1.090000e+02</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">swin</td>
<td>2059417.0</td>
<td>1.793943e+02</td>
<td>1.164604e+02</td>
<td>0.0</td>
<td>0.000000</td>
<td>255.000000</td>
<td>2.550000e+02</td>
<td>2.550000e+02</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dwin</td>
<td>2059417.0</td>
<td>1.790213e+02</td>
<td>1.166262e+02</td>
<td>0.0</td>
<td>0.000000</td>
<td>255.000000</td>
<td>2.550000e+02</td>
<td>2.550000e+02</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">smeansz</td>
<td>2059417.0</td>
<td>8.373881e+01</td>
<td>3.306375e+01</td>
<td>0.0</td>
<td>62.000000</td>
<td>73.000000</td>
<td>9.600000e+01</td>
<td>2.270000e+02</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">dmeansz</td>
<td>2059417.0</td>
<td>3.148292e+02</td>
<td>3.181250e+02</td>
<td>0.0</td>
<td>81.000000</td>
<td>117.000000</td>
<td>5.650000e+02</td>
<td>1.291000e+03</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">trans_depth</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">res_bdy_len</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Sjit</td>
<td>2059417.0</td>
<td>1.490421e+02</td>
<td>3.453280e+02</td>
<td>0.0</td>
<td>0.000000</td>
<td>31.407346</td>
<td>5.988594e+01</td>
<td>1.866494e+03</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Djit</td>
<td>2059417.0</td>
<td>2.407096e+01</td>
<td>3.493708e+01</td>
<td>0.0</td>
<td>0.320792</td>
<td>18.822145</td>
<td>2.528875e+01</td>
<td>2.046248e+02</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Sintpkt</td>
<td>2059417.0</td>
<td>2.649637e+00</td>
<td>5.374304e+00</td>
<td>0.0</td>
<td>0.273429</td>
<td>0.754333</td>
<td>1.246410e+00</td>
<td>2.956343e+01</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Dintpkt</td>
<td>2059417.0</td>
<td>2.324438e+00</td>
<td>4.780128e+00</td>
<td>0.0</td>
<td>0.228829</td>
<td>0.702123</td>
<td>1.098588e+00</td>
<td>2.593796e+01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">tcprtt</td>
<td>2059417.0</td>
<td>4.930945e-04</td>
<td>3.454113e-04</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000646</td>
<td>7.000000e-04</td>
<td>1.792000e-03</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">synack</td>
<td>2059417.0</td>
<td>3.884122e-04</td>
<td>2.706369e-04</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000512</td>
<td>5.530000e-04</td>
<td>1.417000e-03</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ackdat</td>
<td>2059417.0</td>
<td>9.684686e-05</td>
<td>6.657834e-05</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000127</td>
<td>1.400000e-04</td>
<td>3.590000e-04</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">is_sm_ips_ports</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ct_state_ttl</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ct_flw_http_mthd</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">is_ftp_login</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ct_ftp_cmd</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ct_srv_src</td>
<td>2059417.0</td>
<td>4.615433e+00</td>
<td>3.267685e+00</td>
<td>1.0</td>
<td>2.000000</td>
<td>4.000000</td>
<td>7.000000e+00</td>
<td>1.400000e+01</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ct_srv_dst</td>
<td>2059417.0</td>
<td>4.472495e+00</td>
<td>3.155140e+00</td>
<td>1.0</td>
<td>2.000000</td>
<td>4.000000</td>
<td>6.000000e+00</td>
<td>1.400000e+01</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ct_dst_ltm</td>
<td>2059417.0</td>
<td>3.248467e+00</td>
<td>1.867660e+00</td>
<td>1.0</td>
<td>2.000000</td>
<td>3.000000</td>
<td>4.000000e+00</td>
<td>9.000000e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ct_src_ ltm</td>
<td>2059417.0</td>
<td>3.534853e+00</td>
<td>1.993151e+00</td>
<td>1.0</td>
<td>2.000000</td>
<td>3.000000</td>
<td>5.000000e+00</td>
<td>9.000000e+00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ct_src_dport_ltm</td>
<td>2059417.0</td>
<td>1.000000e+00</td>
<td>0.000000e+00</td>
<td>1.0</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000e+00</td>
<td>1.000000e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ct_dst_sport_ltm</td>
<td>2059417.0</td>
<td>1.000000e+00</td>
<td>0.000000e+00</td>
<td>1.0</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000e+00</td>
<td>1.000000e+00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">ct_dst_src_ltm</td>
<td>2059417.0</td>
<td>2.000227e+00</td>
<td>1.286357e+00</td>
<td>1.0</td>
<td>1.000000</td>
<td>2.000000</td>
<td>3.000000e+00</td>
<td>6.000000e+00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Label</td>
<td>2059417.0</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.0</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">attack_cat_encoded</td>
<td>2059417.0</td>
<td>7.000000e+00</td>
<td>0.000000e+00</td>
<td>7.0</td>
<td>7.000000</td>
<td>7.000000</td>
<td>7.000000e+00</td>
<td>7.000000e+00</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="feature-engineering-and-selection" class="level2">
<h2 class="anchored" data-anchor-id="feature-engineering-and-selection">4. Feature Engineering and selection</h2>
<p>Engineering the numerical values for selecting the best features for the modelling.</p>
<p>In addition to selecting existing features, engineering new features from raw network flow data to capture more meaningful patterns for classification. The derived features include ratios, aggregates, and interactions between flow-level statistics like bytes, packets, jitter, and TCP setup times.</p>
<p><strong>Generating following features</strong>:</p>
<ul>
<li><p>Duration: Difference between Ltime and Stime</p></li>
<li><p>Ratios: Capture asymmetry between source and destination metrics (e.g., byte ratio, jitter ratio)</p></li>
<li><p>Aggregates: Total counts or sums across both directions (e.g., total packets)</p></li>
<li><p>Interaction Terms: Multiplicative interactions between features to capture intensity of communication</p></li>
<li><p>Statistical Differences: Difference in TCP sequence numbers or average packet sizes</p></li>
</ul>
<div id="e6bdd7dd" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_features(df):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Duration</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'duration'</span>] <span class="op">=</span> df[<span class="st">'Ltime'</span>] <span class="op">-</span> df[<span class="st">'Stime'</span>]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ratios</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'byte_ratio'</span>] <span class="op">=</span> df[<span class="st">'sbytes'</span>] <span class="op">/</span> (df[<span class="st">'dbytes'</span>] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'pkt_ratio'</span>] <span class="op">=</span> df[<span class="st">'Spkts'</span>] <span class="op">/</span> (df[<span class="st">'Dpkts'</span>] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'load_ratio'</span>] <span class="op">=</span> df[<span class="st">'Sload'</span>] <span class="op">/</span> (df[<span class="st">'Dload'</span>] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'jit_ratio'</span>] <span class="op">=</span> df[<span class="st">'Sjit'</span>] <span class="op">/</span> (df[<span class="st">'Djit'</span>] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'inter_pkt_ratio'</span>] <span class="op">=</span> df[<span class="st">'Sintpkt'</span>] <span class="op">/</span> (df[<span class="st">'Dintpkt'</span>] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'tcp_setup_ratio'</span>] <span class="op">=</span> df[<span class="st">'tcprtt'</span>] <span class="op">/</span> (df[<span class="st">'synack'</span>] <span class="op">+</span> df[<span class="st">'ackdat'</span>] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Aggregate Features</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'total_bytes'</span>] <span class="op">=</span> df[<span class="st">'sbytes'</span>] <span class="op">+</span> df[<span class="st">'dbytes'</span>]</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'total_pkts'</span>] <span class="op">=</span> df[<span class="st">'Spkts'</span>] <span class="op">+</span> df[<span class="st">'Dpkts'</span>]</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'total_load'</span>] <span class="op">=</span> df[<span class="st">'Sload'</span>] <span class="op">+</span> df[<span class="st">'Dload'</span>]</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'total_jitter'</span>] <span class="op">=</span> df[<span class="st">'Sjit'</span>] <span class="op">+</span> df[<span class="st">'Djit'</span>]</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'total_inter_pkt'</span>] <span class="op">=</span> df[<span class="st">'Sintpkt'</span>] <span class="op">+</span> df[<span class="st">'Dintpkt'</span>]</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'total_tcp_setup'</span>] <span class="op">=</span> df[<span class="st">'tcprtt'</span>] <span class="op">+</span> df[<span class="st">'synack'</span>] <span class="op">+</span> df[<span class="st">'ackdat'</span>]</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Interaction Features</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'byte_pkt_interaction_src'</span>] <span class="op">=</span> df[<span class="st">'sbytes'</span>] <span class="op">*</span> df[<span class="st">'Spkts'</span>]</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'byte_pkt_interaction_dst'</span>] <span class="op">=</span> df[<span class="st">'dbytes'</span>] <span class="op">*</span> df[<span class="st">'Dpkts'</span>]</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'load_jit_interaction_src'</span>] <span class="op">=</span> df[<span class="st">'Sload'</span>] <span class="op">*</span> df[<span class="st">'Sjit'</span>]</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'load_jit_interaction_dst'</span>] <span class="op">=</span> df[<span class="st">'Dload'</span>] <span class="op">*</span> df[<span class="st">'Djit'</span>]</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'pkt_jit_interaction_src'</span>] <span class="op">=</span> df[<span class="st">'Spkts'</span>] <span class="op">*</span> df[<span class="st">'Sjit'</span>]</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'pkt_jit_interaction_dst'</span>] <span class="op">=</span> df[<span class="st">'Dpkts'</span>] <span class="op">*</span> df[<span class="st">'Djit'</span>]</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Statistical Features</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'mean_pkt_size'</span>] <span class="op">=</span> df[<span class="st">'smeansz'</span>] <span class="op">+</span> df[<span class="st">'dmeansz'</span>]</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'tcp_seq_diff'</span>] <span class="op">=</span> df[<span class="st">'stcpb'</span>] <span class="op">-</span> df[<span class="st">'dtcpb'</span>]</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>generate_features(merged_df)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>columns_to_drop <span class="op">=</span> [<span class="st">'sport'</span>, <span class="st">'dsport'</span>, <span class="st">'proto'</span>,<span class="st">'srcip'</span>, <span class="st">'dstip'</span>,<span class="st">'state'</span>, <span class="st">'service'</span>]</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>merged_df.drop(columns<span class="op">=</span>columns_to_drop, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>Inference</strong>: Improve class separability in machine learning models and reduce overfitting by summarizing complex behaviors with fewer, more informative features.</p>
</section>
<section id="encoding-the-attack-categories" class="level2">
<h2 class="anchored" data-anchor-id="encoding-the-attack-categories">Encoding the attack categories</h2>
<p>The attack_cat column (our target) contains categorical string labels, converting them to numeric form using Label Encoding.</p>
<p>For this :</p>
<p><strong>-</strong>Identified all categorical columns using select_dtypes(include=[‘O’])</p>
<p><strong>-</strong>Applying LabelEncoder to the attack_cat column to convert each attack type to a unique integer</p>
<div id="1f46b885" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>cat_columns <span class="op">=</span> merged_df.select_dtypes(include<span class="op">=</span>[<span class="st">'O'</span>]).columns.tolist()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>cat_columns</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>ohe <span class="op">=</span> OneHotEncoder()</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>merged_df[<span class="st">'attack_cat'</span>] <span class="op">=</span> label_encoder.fit_transform(merged_df[<span class="st">'attack_cat'</span>])</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>label_mapping <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Label Mapping:"</span>)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(label_mapping)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Label Mapping:
{'analysis': np.int64(0), 'backdoor_attack': np.int64(1), 'backdoors': np.int64(2), 'denial_of_service': np.int64(3), 'exploits': np.int64(4), 'fuzzing_attack': np.int64(5), 'generic': np.int64(6), 'normal': np.int64(7), 'reconnaissance': np.int64(8), 'shellcode': np.int64(9), 'worms': np.int64(10)}</code></pre>
</div>
</div>
<p><strong>Infenrence</strong>: The encoded values are now stored in the attack_cat column and will be used as the target variable for classification.</p>
</section>
<section id="correlation" class="level2">
<h2 class="anchored" data-anchor-id="correlation">4.1 Correlation</h2>
<p>To enhance model efficiency and reduce feature redundancy, performing a correlation-based redundancy on the numerical features. A correlation matrix was computed and visualized using a heatmap (Figure X), and all feature pairs with a Pearson correlation coefficient ≥ 0.75 were identified.</p>
<p>Highly correlated features often carry overlapping information, which can:</p>
<p><strong>-</strong>Introduce multicollinearity in linear models,</p>
<p><strong>-</strong>Distort feature importance interpretation in tree-based models,</p>
<p><strong>-</strong>Increase computational overhead without performance gain.</p>
<div id="c4472d0a" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">40</span>,<span class="dv">20</span>))</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Correlation Plot"</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>sns.heatmap(merged_df.corr(),cmap<span class="op">=</span><span class="st">'YlGnBu'</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> merged_df.corr()</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>high_correlation_mask <span class="op">=</span> correlation_matrix <span class="op">&gt;=</span> <span class="fl">0.75</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>highly_correlated_features <span class="op">=</span> []</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature <span class="kw">in</span> high_correlation_mask.columns:</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>    correlated_with <span class="op">=</span> high_correlation_mask.index[high_correlation_mask[feature]].tolist()</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> correlated_feature <span class="kw">in</span> correlated_with:</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> feature <span class="op">!=</span> correlated_feature <span class="kw">and</span> (correlated_feature, feature) <span class="kw">not</span> <span class="kw">in</span> highly_correlated_features:</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>            highly_correlated_features.append((feature, correlated_feature))</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Highly correlated features:"</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature1, feature2 <span class="kw">in</span> highly_correlated_features:</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature1<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>feature2<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Highly correlated features:
sbytes and dloss
sbytes and byte_pkt_interaction_src
dbytes and total_bytes
dbytes and byte_pkt_interaction_dst
sloss and Spkts
sloss and Dpkts
sloss and total_pkts
dloss and Spkts
dloss and Dpkts
dloss and total_pkts
dloss and byte_pkt_interaction_src
Dload and total_load
Spkts and Dpkts
Spkts and total_pkts
Spkts and byte_pkt_interaction_src
Dpkts and total_pkts
Dpkts and byte_pkt_interaction_src
swin and dwin
swin and tcprtt
swin and synack
swin and ackdat
swin and tcp_setup_ratio
swin and total_tcp_setup
dwin and tcprtt
dwin and synack
dwin and ackdat
dwin and tcp_setup_ratio
dwin and total_tcp_setup
dmeansz and mean_pkt_size
Sjit and Sintpkt
Sjit and total_jitter
Sjit and pkt_jit_interaction_src
Stime and Ltime
Sintpkt and total_jitter
Sintpkt and total_inter_pkt
Dintpkt and total_inter_pkt
tcprtt and synack
tcprtt and ackdat
tcprtt and tcp_setup_ratio
tcprtt and total_tcp_setup
synack and ackdat
synack and tcp_setup_ratio
synack and total_tcp_setup
ackdat and tcp_setup_ratio
ackdat and total_tcp_setup
tcp_setup_ratio and total_tcp_setup
total_bytes and byte_pkt_interaction_dst
total_pkts and byte_pkt_interaction_src
total_jitter and pkt_jit_interaction_src</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-22-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference</strong>: A comparison of the correlation matrix revealed several strongly correlated feature pairs, including:</p>
<ul>
<li><p>sbytes &lt;-&gt; dloss, byte_pkt_interaction_src</p></li>
<li><p>dbytes &lt;-&gt; total_bytes, byte_pkt_interaction_dst</p></li>
<li><p>Spkts, Dpkts &lt;-&gt; total_pkts, byte_pkt_interaction_src</p></li>
<li><p>swin, dwin &lt;-&gt; tcprtt, synack, ackdat, tcp_setup_ratio, total_tcp_setup</p></li>
<li><p>Sjit, Sintpkt &lt;-&gt; total_jitter, pkt_jit_interaction_src</p></li>
<li><p>tcprtt &lt;-&gt; tcp_setup_ratio, total_tcp_setup</p></li>
<li><p>Stime &lt;-&gt; Ltime</p></li>
<li><p>dmeansz &lt;-&gt; mean_pkt_size</p></li>
</ul>
</section>
<section id="smote---synthetic-minority-over-sampling-technique" class="level2">
<h2 class="anchored" data-anchor-id="smote---synthetic-minority-over-sampling-technique">4.2 SMOTE - Synthetic Minority Over-sampling Technique</h2>
<p>In this step, we finalize the feature engineering process by refining the feature set and preparing the data for modeling. First, we drop highly correlated features to avoid redundancy and reduce multicollinearity. Next, we address class imbalance using a hybrid approach of SMOTE (Synthetic Minority Oversampling) and random undersampling to ensure fair representation across all attack categories. Finally, we rank the remaining features based on mutual information to identify the most relevant predictors for classification.</p>
<p>This is important because it:</p>
<p><strong>-</strong> Simplifies the dataset by removing overlapping features</p>
<p><strong>-</strong> Improves model performance and generalization</p>
<p><strong>-</strong> Ensures minority attack classes are not ignored during training</p>
<p><strong>-</strong> Prioritizes features that provide the most value to the model</p>
<div id="f7e4c23b" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>features_to_drop <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature1, feature2 <span class="kw">in</span> highly_correlated_features:</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> feature1 <span class="kw">not</span> <span class="kw">in</span> features_to_drop <span class="kw">and</span> feature2 <span class="kw">not</span> <span class="kw">in</span> features_to_drop:</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        features_to_drop.add(feature2)  <span class="co"># You can choose feature1 or feature2 to drop</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> merged_df.drop(columns<span class="op">=</span>features_to_drop)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Remaining features after dropping highly correlated ones:"</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_df.columns)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> train_df.drop([<span class="st">'attack_cat'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> train_df[[<span class="st">'attack_cat'</span>]]</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>desired_count <span class="op">=</span> <span class="dv">15000</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install imbalanced<span class="op">-</span>learn</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.under_sampling <span class="im">import</span> RandomUnderSampler</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>oversample_strategy <span class="op">=</span> {i: desired_count <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y.value_counts())) <span class="cf">if</span> y.value_counts()[i] <span class="op">&lt;</span> desired_count}</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>undersample_strategy <span class="op">=</span> {i: desired_count <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y.value_counts())) <span class="cf">if</span> y.value_counts()[i] <span class="op">&gt;</span> desired_count}</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>smote <span class="op">=</span> SMOTE(sampling_strategy<span class="op">=</span>oversample_strategy)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>undersample <span class="op">=</span> RandomUnderSampler(sampling_strategy<span class="op">=</span>undersample_strategy)</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>x_smote, y_smote <span class="op">=</span> smote.fit_resample(x, y)</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>x_resampled, y_resampled <span class="op">=</span> undersample.fit_resample(x_smote, y_smote)</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Before resampling:"</span>)</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y.value_counts())</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After resampling:"</span>)</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_resampled.value_counts())</span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x_resampled</span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y_resampled</span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> mutual_info_regression</span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>discrete_features <span class="op">=</span> x.dtypes <span class="op">==</span> <span class="bu">int</span></span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mi_score_maker(x,y,discrete_features):</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> mutual_info_regression(x,y,discrete_features<span class="op">=</span>discrete_features)</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Features'</span>:x.columns,</span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Scores'</span>:scores</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.sort_values([<span class="st">'Scores'</span>],ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>mi_scores <span class="op">=</span> mi_score_maker(x,y.astype(<span class="st">'float64'</span>),discrete_features)</span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>mi_scores</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Remaining features after dropping highly correlated ones:
Index(['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'Sload', 'Dload',
       'swin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth',
       'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Dintpkt', 'is_sm_ips_ports',
       'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd',
       'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',
       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat',
       'Label', 'attack_cat_encoded', 'duration', 'byte_ratio', 'pkt_ratio',
       'load_ratio', 'jit_ratio', 'inter_pkt_ratio',
       'load_jit_interaction_src', 'load_jit_interaction_dst',
       'pkt_jit_interaction_dst', 'tcp_seq_diff'],
      dtype='object', name='Name')
Requirement already satisfied: imbalanced-learn in ./venv/lib/python3.13/site-packages (0.13.0)
Requirement already satisfied: numpy&lt;3,&gt;=1.24.3 in ./venv/lib/python3.13/site-packages (from imbalanced-learn) (2.2.4)
Requirement already satisfied: scipy&lt;2,&gt;=1.10.1 in ./venv/lib/python3.13/site-packages (from imbalanced-learn) (1.15.2)
Requirement already satisfied: scikit-learn&lt;2,&gt;=1.3.2 in ./venv/lib/python3.13/site-packages (from imbalanced-learn) (1.6.1)
Requirement already satisfied: sklearn-compat&lt;1,&gt;=0.1 in ./venv/lib/python3.13/site-packages (from imbalanced-learn) (0.1.3)
Requirement already satisfied: joblib&lt;2,&gt;=1.1.1 in ./venv/lib/python3.13/site-packages (from imbalanced-learn) (1.4.2)
Requirement already satisfied: threadpoolctl&lt;4,&gt;=2.0.0 in ./venv/lib/python3.13/site-packages (from imbalanced-learn) (3.6.0)

[notice] A new release of pip is available: 25.0 -&gt; 25.0.1
[notice] To update, run: pip install --upgrade pip
Note: you may need to restart the kernel to use updated packages.
Before resampling:
attack_cat
7             1959771
4               27600
6               25378
5               21795
8               13357
3                5665
0                2185
1                1684
9                1511
2                 300
10                171
Name: count, dtype: int64

After resampling:
attack_cat
0             15000
1             15000
2             15000
3             15000
4             15000
5             15000
6             15000
7             15000
8             15000
9             15000
10            15000
Name: count, dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Features</th>
<th data-quarto-table-cell-role="th">Scores</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>byte_ratio</td>
<td>1.300475</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>sbytes</td>
<td>1.258345</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>smeansz</td>
<td>1.037955</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>load_ratio</td>
<td>0.766994</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>dbytes</td>
<td>0.749935</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>Stime</td>
<td>0.720681</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>dmeansz</td>
<td>0.713983</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>pkt_ratio</td>
<td>0.683740</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>inter_pkt_ratio</td>
<td>0.571406</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>ct_srv_dst</td>
<td>0.564174</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>ct_srv_src</td>
<td>0.542357</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>dur</td>
<td>0.533911</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>Dload</td>
<td>0.492419</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>ct_dst_ltm</td>
<td>0.427662</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>ct_src_ ltm</td>
<td>0.425913</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>ct_dst_src_ltm</td>
<td>0.418047</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>sloss</td>
<td>0.416783</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">17</td>
<td>load_jit_interaction_dst</td>
<td>0.405282</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">18</td>
<td>Dintpkt</td>
<td>0.388831</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">19</td>
<td>pkt_jit_interaction_dst</td>
<td>0.387877</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">20</td>
<td>Sload</td>
<td>0.384694</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">21</td>
<td>jit_ratio</td>
<td>0.355098</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">22</td>
<td>load_jit_interaction_src</td>
<td>0.326477</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">23</td>
<td>Djit</td>
<td>0.312133</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">24</td>
<td>Sjit</td>
<td>0.283450</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">25</td>
<td>swin</td>
<td>0.175168</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">26</td>
<td>duration</td>
<td>0.110192</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">27</td>
<td>dtcpb</td>
<td>0.041490</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">28</td>
<td>tcp_seq_diff</td>
<td>0.031939</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">29</td>
<td>stcpb</td>
<td>0.028972</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">30</td>
<td>sttl</td>
<td>0.003462</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">31</td>
<td>ct_ftp_cmd</td>
<td>0.002727</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">32</td>
<td>trans_depth</td>
<td>0.000407</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">33</td>
<td>ct_state_ttl</td>
<td>0.000197</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">34</td>
<td>ct_dst_sport_ltm</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">35</td>
<td>ct_src_dport_ltm</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">36</td>
<td>Label</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">37</td>
<td>attack_cat_encoded</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">38</td>
<td>is_ftp_login</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">39</td>
<td>is_sm_ips_ports</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">40</td>
<td>res_bdy_len</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">41</td>
<td>dttl</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">42</td>
<td>ct_flw_http_mthd</td>
<td>0.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><strong>Inference</strong>:</p>
<ul>
<li><p>Redundancy Removal: Dropping highly correlated features left us with a refined and more efficient set of 43 features, reducing complexity and avoiding information overlap.</p></li>
<li><p>Balancing: Before resampling, the normal class had nearly 2 million samples, while several attack types had fewer than 500. After applying SMOTE and undersampling, each class was uniformly balanced with 15,000 samples, creating a fair and robust training set.</p></li>
<li><p>Feature Importance: The mutual information ranking revealed that features like byte_ratio, sbytes, smeansz, and load_ratio are most informative for classifying attack categories. Meanwhile, some engineered or categorical features (e.g., ct_flw_http_mthd, dttl, ct_ftp_cmd) contributed little and can be considered for exclusion in leaner models.</p></li>
</ul>
</section>
<section id="mutual-information-scores-plot" class="level2">
<h2 class="anchored" data-anchor-id="mutual-information-scores-plot">4.3 Mutual information scores plot</h2>
<p>After preprocessing and balancing the dataset, we use Mutual Information (MI) to evaluate the predictive strength of each feature with respect to the target variable (attack_cat). MI measures both linear and non-linear dependencies between features and the target.</p>
<div id="960ab46d" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span><span class="st">'Scores'</span>, y<span class="op">=</span><span class="st">'Features'</span>, data<span class="op">=</span>mi_scores)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Mutual Information Scores"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>plt.yticks(rotation<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()  </span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">"Mutual Information Scores.png"</span>)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>The plot shows that</strong>:</p>
<ul>
<li><p>Top predictors include byte_ratio, sbytes, smeansz, load_ratio, and dbytes, all of which reflect volume and asymmetry in communication, which are key indicators of abnormal network behavior.</p></li>
<li><p>Mid-level contributors such as pkt_ratio, inter_pkt_ratio, ct_srv_dst, and ct_src_ltm help refine predictions with flow-level and connection history information.</p></li>
<li><p>Several engineered features (like load_jit_interaction_dst, tcp_seq_diff) show moderate impact, justifying their creation.</p></li>
<li><p>Low-value features like ct_flw_http_mthd, dttl, ct_ftp_cmd, and ct_dst_sport_ltm contribute negligible information and may be excluded in simplified models.</p></li>
</ul>
<p>This scoring helps justify the construction of a top-k feature subset for streamlined model training and improves interpretability and computational efficiency.</p>
<ul>
<li><strong>Selected Features</strong>: byte_ratio,sbytes,smeansz,load_ratio, dbytes,pkt_ratio,duration</li>
</ul>
</section>
<section id="modelling" class="level2">
<h2 class="anchored" data-anchor-id="modelling">5. Modelling</h2>
</section>
<section id="scaling-features" class="level2">
<h2 class="anchored" data-anchor-id="scaling-features">5.1 Scaling Features</h2>
<p>Before training models, we selected a focused set of the most informative features based on mutual information scores. These features capture essential traffic characteristics such as byte transfer, packet behavior, and flow duration — all of which are highly predictive of attack categories.</p>
<p><strong>-</strong> It simplifies modeling by using only the most relevant predictors</p>
<p><strong>-</strong> Reduces noise and improves training efficiency</p>
<p><strong>-</strong> Prepares the data for scaling, which is necessary for algorithms like Logistic Regression and KNN that are sensitive to feature magnitude</p>
<div id="22f5c6f0" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>selected_features <span class="op">=</span> [<span class="st">"byte_ratio"</span>, <span class="st">"sbytes"</span>, <span class="st">"smeansz"</span>, <span class="st">"load_ratio"</span>, </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"dbytes"</span>, <span class="st">"pkt_ratio"</span>, <span class="st">"duration"</span>]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>X_selected <span class="op">=</span> x_resampled[selected_features]  <span class="co"># Resampled X with selected features</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>y_selected <span class="op">=</span> y_resampled  <span class="co"># Target variable remains the same</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Selected Features (X):</span><span class="ch">\n</span><span class="st">"</span>, X_selected.head())</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Target Variable (y):</span><span class="ch">\n</span><span class="st">"</span>, y_selected.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Selected Features (X):
 Name   byte_ratio  sbytes  smeansz     load_ratio  dbytes  pkt_ratio  duration
78411       180.0   180.0     90.0  540740.750000     0.0        2.0         0
78415       180.0   180.0     90.0  540740.750000     0.0        2.0         0
78417       180.0   180.0     90.0  540740.750000     0.0        2.0         0
78905       360.0   360.0     90.0    2139.211182     0.0        4.0         1
79370       180.0   180.0     90.0  540740.750000     0.0        2.0         0

Target Variable (y):
 Name   attack_cat
78411           0
78415           0
78417           0
78905           0
79370           0</code></pre>
</div>
</div>
<p><strong>Inference</strong>:</p>
<ul>
<li><p>These features vary widely in scale — for example, load_ratio ranges in the hundreds of thousands, while pkt_ratio and duration have much smaller values.</p></li>
<li><p>This confirms the need for feature scaling before applying distance-based models or regularized linear classifiers.</p></li>
<li><p>The target values (y_selected) show the class distribution is now balanced, and ready for supervised training.</p></li>
</ul>
<p>Now applying feature scaling to standardize the range of features, ensuring that they all contribute equally to the model. Since our selected features vary greatly in scale (e.g., load_ratio in the hundreds of thousands vs pkt_ratio around 0-1), applying scaling is crucial for certain algorithms, especially those relying on distance (like KNN) or those sensitive to feature magnitudes (like logistic regression).</p>
<p>I considered using the StandardScaler from sklearn, which transforms the data to have a mean of 0 and a standard deviation of 1, ensuring that each feature is on the same scale without distorting its distribution. This improves the stability and performance of the machine learning models.</p>
<p>Additionally, splitting the data into training and test sets (80% for training, 20% for testing) to ensure that we can evaluate the model on unseen data.</p>
<div id="7fd87ec7" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(X_selected, y_selected, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>scaler.fit(x_train)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>x_train_scaled <span class="op">=</span> scaler.transform(x_train)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>x_test_scaled <span class="op">=</span> scaler.transform(x_test)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>x_train_scaled_df <span class="op">=</span> pd.DataFrame(x_train_scaled, columns<span class="op">=</span>x_train.columns)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>x_test_scaled_df <span class="op">=</span> pd.DataFrame(x_test_scaled, columns<span class="op">=</span>x_test.columns)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Scaled Training Features:</span><span class="ch">\n</span><span class="st">"</span>, x_train_scaled_df.head())</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Scaled Testing Features:</span><span class="ch">\n</span><span class="st">"</span>, x_test_scaled_df.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Scaled Training Features:
 Name  byte_ratio    sbytes   smeansz  load_ratio    dbytes  pkt_ratio  \
0      -0.382382  0.187622  0.286607   -0.908532 -0.144492  -0.171338   
1       0.089082 -0.615131  0.504967    1.101992 -0.290240  -0.048857   
2       0.089082 -0.615131  0.504967    1.101992 -0.290240  -0.048857   
3       0.089082 -0.615131  0.504967    1.101992 -0.290240  -0.048857   
4       0.089082 -0.615131  0.504967    1.101992 -0.290240  -0.048857   

Name  duration  
0    -0.215255  
1    -0.215255  
2    -0.215255  
3    -0.215255  
4    -0.215255  
Scaled Testing Features:
 Name  byte_ratio    sbytes   smeansz  load_ratio    dbytes  pkt_ratio  \
0       0.089082 -0.615131  0.504967    1.101992 -0.290240  -0.048857   
1      -0.384217 -0.059696 -0.077666   -0.908535 -0.071605  -0.212166   
2       0.089082 -0.615131  0.504967    1.101992 -0.290240  -0.048857   
3       3.075199  0.479288 -0.477651    1.101992 -0.290240  -0.048857   
4       0.013063 -0.642992 -0.077325    1.101992 -0.290240  -0.048857   

Name  duration  
0    -0.215255  
1    -0.215255  
2    -0.215255  
3    -0.215255  
4    -0.215255  </code></pre>
</div>
</div>
<p><strong>Inference:</strong></p>
<p>The scaled features now have a mean of 0 and a standard deviation of 1. This transformation ensures that all features are treated equally by the model, especially those sensitive to feature magnitude.</p>
</section>
<section id="model--1-knndistance-based-learning" class="level2">
<h2 class="anchored" data-anchor-id="model--1-knndistance-based-learning">5.2 Model -1 : KNN(Distance-Based Learning)</h2>
<p>We begin our model evaluation phase with K-Nearest Neighbors (KNN), a distance-based classification algorithm. KNN predicts the class of a data point by looking at the majority label of its k nearest neighbors in the feature space.</p>
<p>We chose k = 5 with uniform weighting and Euclidean distance to classify rescaled network traffic based on the selected features.</p>
<p>This model is a good baseline because:</p>
<p><strong>-</strong> It is non-parametric and does not assume data distribution</p>
<p><strong>-</strong> It works well with scaled data, especially when clusters are separable</p>
<p><strong>-</strong> It is interpretable and sensitive to local feature similarity, which can be useful in intrusion detection</p>
<div id="7e4b55aa" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier  </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>knn_model <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>, weights<span class="op">=</span><span class="st">'uniform'</span>, metric<span class="op">=</span><span class="st">'euclidean'</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>knn_model.fit(x_train_scaled, y_train)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>knn_y_pred <span class="op">=</span> knn_model.predict(x_test_scaled)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"KNN Classification Report:"</span>)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, knn_y_pred))</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"KNN Accuracy:"</span>, accuracy_score(y_test, knn_y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>KNN Classification Report:
              precision    recall  f1-score   support

           0       0.54      0.25      0.34      2895
           1       0.50      0.16      0.25      2924
           2       0.59      0.12      0.20      3064
           3       0.19      0.60      0.29      3000
           4       0.65      0.64      0.65      3032
           5       0.78      0.79      0.78      2942
           6       0.94      0.86      0.90      3035
           7       0.98      0.97      0.98      3040
           8       0.88      0.77      0.83      3060
           9       0.81      0.83      0.82      3017
          10       0.92      0.93      0.93      2991

    accuracy                           0.63     33000
   macro avg       0.71      0.63      0.63     33000
weighted avg       0.71      0.63      0.63     33000

KNN Accuracy: 0.6318181818181818</code></pre>
</div>
</div>
<p><strong>Inference</strong>:</p>
<ul>
<li><p>Strong performance on majority and mid-frequency classes:normal (class 7): precision 0.98, recall 0.98 ,generic (class 6): precision 0.95, recall 0.86, shellcode and worms: both with precision &gt; 0.9</p></li>
<li><p>Weaker performance on low-frequency and overlapping classes:Class 0 (analysis)-low precision (0.30) but very high recall (0.95), meaning the model over-predicts this class</p></li>
</ul>
<p>-While KNN captures the major traffic patterns well, it struggles with fine-grained separation between similar attack classes.</p>
</section>
<section id="model-2-random-forest-classifierensemble-learning" class="level2">
<h2 class="anchored" data-anchor-id="model-2-random-forest-classifierensemble-learning">5.3 Model-2 : Random Forest Classifier(Ensemble Learning)</h2>
<p>In this step, we train a Random Forest Classifier, an ensemble-based algorithm that builds multiple decision trees and aggregates their predictions for improved accuracy and robustness.</p>
<p>Random Forest is particularly suitable for this problem because:</p>
<p><strong>-</strong>It handles non-linear relationships and high-dimensional features effectively</p>
<p><strong>-</strong>It is less sensitive to scaling, though we still scaled data for consistency</p>
<p><strong>-</strong>It is robust to overfitting when using enough trees (here, 1000 estimators)</p>
<p><strong>-</strong>It provides feature importance insights for later interpretation</p>
<div id="01d45d04" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.exceptions <span class="im">import</span> DataConversionWarning</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score  </span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(action<span class="op">=</span><span class="st">'ignore'</span>, category<span class="op">=</span>DataConversionWarning)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>rf_model.fit(x_train_scaled, y_train)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>rf_y_pred <span class="op">=</span> rf_model.predict(x_test_scaled)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Classification Report:"</span>)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, rf_y_pred))</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Accuracy:"</span>, accuracy_score(y_test, rf_y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.22      0.33      2895
           1       0.58      0.19      0.29      2924
           2       0.32      0.93      0.48      3064
           3       0.70      0.46      0.56      3000
           4       0.77      0.72      0.74      3032
           5       0.85      0.82      0.83      2942
           6       0.96      0.90      0.93      3035
           7       0.99      0.98      0.98      3040
           8       0.88      0.79      0.83      3060
           9       0.84      0.85      0.84      3017
          10       0.94      0.96      0.95      2991

    accuracy                           0.71     33000
   macro avg       0.78      0.71      0.71     33000
weighted avg       0.78      0.71      0.71     33000

Random Forest Accuracy: 0.7138181818181818</code></pre>
</div>
</div>
<p><strong>Inference</strong>: - Overall accuracy: 71.3%, outperforming the KNN baseline by ~4.5%</p>
<ul>
<li><p>Good performance on dominant classes:normal (class 7): F1-score = 0.99,generic (class 6): F1-score = 0.92,worms, shellcode, backdoors: F1-scores &gt; 0.83</p></li>
<li><p>Strong recall for class 2 (backdoors): 93%, but low precision (0.32), suggesting false positives</p></li>
<li><p>Mid-performing classes like denial_of_service and exploits achieved decent F1-scores (0.54 and 0.74)</p></li>
<li><p>Weaker detection of class analysis (class 0): precision = 0.73, recall = 0.22</p></li>
<li><p>Random Forest shows stronger generalization than KNN, especially in minority classes. The model achieves better balance across precision and recall, making it a solid candidate for real-world deployment.</p></li>
</ul>
</section>
<section id="model-3-xgboostgradient-boosting-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="model-3-xgboostgradient-boosting-algorithm">5.4 - Model 3 : XGBoost(Gradient Boosting Algorithm)</h2>
<p>In this step, we train an XGBoost (Extreme Gradient Boosting) classifier, a powerful and efficient tree-based ensemble model that uses gradient boosting to optimize predictions. XGBoost is widely used in industry and competitions due to its:</p>
<p><strong>-</strong> Ability to handle non-linear decision boundaries</p>
<p><strong>-</strong>Built-in regularization to prevent overfitting</p>
<p><strong>-</strong>Robustness to imbalanced data and feature noise <strong>-</strong>We set n_estimators = 100 and max_depth = 6, using default learning rate and other parameters for this initial experiment.</p>
<div id="714a052b" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, classification_report</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, learning_rate<span class="op">=</span><span class="fl">0.1</span>, max_depth<span class="op">=</span><span class="dv">6</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>xgb_model.fit(x_train_scaled, y_train)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>xgb_y_pred <span class="op">=</span> xgb_model.predict(x_test_scaled)</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(y_test, xgb_y_pred))</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, xgb_y_pred))</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, xgb_y_pred)</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>, xticklabels<span class="op">=</span><span class="bu">set</span>(y_test[<span class="st">'attack_cat'</span>]), yticklabels<span class="op">=</span><span class="bu">set</span>(y_test[<span class="st">'attack_cat'</span>]))</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual'</span>)</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix - XGBoost Model'</span>)</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'Confusion Matrix - XGBoost Model.png'</span>)</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.6866969696969697
Classification Report:
               precision    recall  f1-score   support

           0       0.72      0.22      0.33      2895
           1       0.51      0.19      0.28      2924
           2       0.31      0.88      0.46      3064
           3       0.71      0.36      0.48      3000
           4       0.71      0.67      0.69      3032
           5       0.80      0.75      0.77      2942
           6       0.96      0.86      0.91      3035
           7       0.99      0.97      0.98      3040
           8       0.86      0.80      0.83      3060
           9       0.74      0.86      0.80      3017
          10       0.90      0.94      0.92      2991

    accuracy                           0.69     33000
   macro avg       0.75      0.68      0.68     33000
weighted avg       0.75      0.69      0.68     33000
</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-29-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference</strong>: - Accuracy: 68.6% – slightly lower than Random Forest (71.3%), but still higher than KNN (66.8%)</p>
<ul>
<li>Notable observations:Class 2 (backdoors): very high recall (0.88), but low precision (0.31) → high false positive rate, Class 0 (analysis) and 1 (backdoor_attack): moderate precision (~0.5) but low recall (~0.2), showing continued difficulty in detecting low-sample or ambiguous classes</li>
</ul>
<p><strong>Confusion Matrix Insights</strong>: - The matrix shows a clear diagonal dominance in major classes, indicating strong correct predictions for classes 6 to 10.</p>
<ul>
<li><p>Class 2 (backdoors) shows significant confusion with classes 0 and 1 — 2000+ misclassified instances from classes 0–2 reinforce this.</p></li>
<li><p>There is still some misclassification overlap between similar behavior classes (e.g., denial_of_service and exploits).</p></li>
</ul>
</section>
<section id="evaluation-metrics" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-metrics">6. Evaluation Metrics</h2>
<section id="metrics-used" class="level3">
<h3 class="anchored" data-anchor-id="metrics-used">Metrics used:</h3>
<ul>
<li><strong>Accuracy</strong>: Proportion of total correct predictions (both normal and attack) out of all predictions.</li>
<li><strong>F1 Score</strong>: Harmonic mean of precision and recall, balancing false positives and false negatives.</li>
<li><strong>ROC AUC</strong>: Measures model’s ability to distinguish between classes across all thresholds (area under ROC curve).</li>
<li><strong>AUPRC</strong>: Area under the Precision-Recall curve, especially useful for imbalanced datasets like this one.</li>
<li><strong>ROC Curve</strong>: Plots True Positive Rate vs.&nbsp;False Positive Rate to visualize classification performance.</li>
</ul>
</section>
</section>
<section id="graph-1" class="level2">
<h2 class="anchored" data-anchor-id="graph-1">6.1 Graph-1:</h2>
<div id="be079cdc" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc, precision_recall_curve, average_precision_score</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> label_binarize</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>y_test_binarized <span class="op">=</span> label_binarize(y_test, classes<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(y_test[<span class="st">'attack_cat'</span>].unique()))))</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>rf_y_probs <span class="op">=</span> rf_model.predict_proba(x_test_scaled)  <span class="co"># Probabilities for all classes</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>fpr <span class="op">=</span> {}</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>tpr <span class="op">=</span> {}</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> {}</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    fpr[i], tpr[i], _ <span class="op">=</span> roc_curve(y_test_binarized[:, i], rf_y_probs[:, i])</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>    roc_auc[i] <span class="op">=</span> auc(fpr[i], tpr[i])</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> {}</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> {}</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>auprc <span class="op">=</span> {}</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>    precision[i], recall[i], _ <span class="op">=</span> precision_recall_curve(y_test_binarized[:, i], rf_y_probs[:, i])</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>    auprc[i] <span class="op">=</span> average_precision_score(y_test_binarized[:, i], rf_y_probs[:, i])</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>    plt.plot(fpr[i], tpr[i], lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (AUC = </span><span class="sc">{</span>roc_auc[i]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)  <span class="co"># Random Guess Line</span></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Random Forest ROC Curve'</span>)</span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>    plt.plot(recall[i], precision[i], lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (AUPRC = </span><span class="sc">{</span>auprc[i]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Random Forest Precision-Recall Curve'</span>)</span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> AUC Score: </span><span class="sc">{</span>roc_auc[i]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> AUPRC Score: </span><span class="sc">{</span>auprc[i]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-30-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-30-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Class 0 AUC Score: 0.904
Class 0 AUPRC Score: 0.433
Class 1 AUC Score: 0.884
Class 1 AUPRC Score: 0.382
Class 2 AUC Score: 0.901
Class 2 AUPRC Score: 0.421
Class 3 AUC Score: 0.873
Class 3 AUPRC Score: 0.559
Class 4 AUC Score: 0.946
Class 4 AUPRC Score: 0.795
Class 5 AUC Score: 0.960
Class 5 AUPRC Score: 0.861
Class 6 AUC Score: 0.978
Class 6 AUPRC Score: 0.935
Class 7 AUC Score: 0.995
Class 7 AUPRC Score: 0.990
Class 8 AUC Score: 0.959
Class 8 AUPRC Score: 0.867
Class 9 AUC Score: 0.985
Class 9 AUPRC Score: 0.893
Class 10 AUC Score: 0.998
Class 10 AUPRC Score: 0.985</code></pre>
</div>
</div>
<p><strong>Inference</strong>:</p>
<section id="roc-auc-scores-per-class" class="level3">
<h3 class="anchored" data-anchor-id="roc-auc-scores-per-class">ROC AUC Scores (Per Class)</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Class</th>
<th>AUC Score</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.907</td>
<td>Good separability for <code>analysis</code></td>
</tr>
<tr class="even">
<td>1</td>
<td>0.882</td>
<td>Moderate for <code>backdoor_attack</code></td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.901</td>
<td>Strong for <code>backdoors</code></td>
</tr>
<tr class="even">
<td>3</td>
<td>0.866</td>
<td>Moderate for <code>denial_of_service</code></td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.951</td>
<td>High for <code>exploits</code></td>
</tr>
<tr class="even">
<td>5</td>
<td>0.960</td>
<td>Excellent for <code>fuzzing_attack</code></td>
</tr>
<tr class="odd">
<td>6</td>
<td>0.978</td>
<td>Excellent for <code>generic</code></td>
</tr>
<tr class="even">
<td>7</td>
<td>0.997</td>
<td>Near-perfect for <code>normal</code></td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.960</td>
<td>Excellent for <code>reconnaissance</code></td>
</tr>
<tr class="even">
<td>9</td>
<td>0.987</td>
<td>Excellent for <code>shellcode</code></td>
</tr>
<tr class="odd">
<td>10</td>
<td>0.996</td>
<td>Near-perfect for <code>worms</code></td>
</tr>
</tbody>
</table>
</section>
<section id="auprc-scores-per-class" class="level3">
<h3 class="anchored" data-anchor-id="auprc-scores-per-class">AUPRC Scores (Per Class)</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Class</th>
<th>AUPRC</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.455</td>
<td>Low – many false positives for <code>analysis</code></td>
</tr>
<tr class="even">
<td>1</td>
<td>0.390</td>
<td>Very low – poor separation of <code>backdoor_attack</code></td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.407</td>
<td>Low precision for <code>backdoors</code></td>
</tr>
<tr class="even">
<td>3</td>
<td>0.548</td>
<td>Moderate for <code>denial_of_service</code></td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.798</td>
<td>Strong for <code>exploits</code></td>
</tr>
<tr class="even">
<td>5</td>
<td>0.863</td>
<td>Very strong for <code>fuzzing_attack</code></td>
</tr>
<tr class="odd">
<td>6</td>
<td>0.935</td>
<td>Excellent for <code>generic</code></td>
</tr>
<tr class="even">
<td>7</td>
<td>0.994</td>
<td>Near-perfect for <code>normal</code></td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.873</td>
<td>Excellent for <code>reconnaissance</code></td>
</tr>
<tr class="even">
<td>9</td>
<td>0.889</td>
<td>Excellent for <code>shellcode</code></td>
</tr>
<tr class="odd">
<td>10</td>
<td>0.985</td>
<td>Outstanding for <code>worms</code></td>
</tr>
</tbody>
</table>
<ul>
<li><p>ROC AUC shows the model has excellent separability for most classes.</p></li>
<li><p>Precision-Recall curves indicate where the model may struggle with false positives (particularly for minority or overlapping classes).</p></li>
<li><p>These plots give a comprehensive understanding of both detection strength and misclassification risk, helping guide future model tuning or threshold adjustment.</p></li>
</ul>
</section>
</section>
<section id="graph-2" class="level2">
<h2 class="anchored" data-anchor-id="graph-2">6.2 - Graph 2</h2>
<p>To identify the best-performing model for multi-class network attack classification, we evaluated and compared Random Forest, XGBoost, and KNN using ROC and Precision-Recall (PR) curves.</p>
<div id="f85b87da" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc, precision_recall_curve, average_precision_score</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> label_binarize</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>y_test_binarized <span class="op">=</span> label_binarize(y_test, classes<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(y_test[<span class="st">'attack_cat'</span>].unique()))))</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>rf_y_probs <span class="op">=</span> rf_model.predict_proba(x_test_scaled)  <span class="co"># Random Forest</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>xgb_y_probs <span class="op">=</span> xgb_model.predict_proba(x_test_scaled)  <span class="co"># XGBoost</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>    knn_y_probs <span class="op">=</span> knn_model.predict_proba(x_test_scaled)  <span class="co"># KNN</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>    knn_y_probs <span class="op">=</span> label_binarize(knn_model.predict(x_test_scaled), classes<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(y_test[<span class="st">'attack_cat'</span>].unique()))))</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {<span class="st">"Random Forest"</span>: rf_y_probs, <span class="st">"KNN"</span>: knn_y_probs, <span class="st">"XGBoost"</span>: xgb_y_probs}</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>roc_results <span class="op">=</span> {}</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name, y_probs <span class="kw">in</span> models.items():</span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):  </span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>        fpr, tpr, _ <span class="op">=</span> roc_curve(y_test_binarized[:, i], y_probs[:, i])</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a>        roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a>        roc_results[<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">)"</span>] <span class="op">=</span> roc_auc</span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a>        plt.plot(fpr, tpr, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, AUC = </span><span class="sc">{</span>roc_auc<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'ROC Curve Comparison for All Models'</span>)</span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a>auprc_results <span class="op">=</span> {}</span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb47-46"><a href="#cb47-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-47"><a href="#cb47-47" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name, y_probs <span class="kw">in</span> models.items():</span>
<span id="cb47-48"><a href="#cb47-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):  <span class="co"># Loop through each class</span></span>
<span id="cb47-49"><a href="#cb47-49" aria-hidden="true" tabindex="-1"></a>        precision, recall, _ <span class="op">=</span> precision_recall_curve(y_test_binarized[:, i], y_probs[:, i])</span>
<span id="cb47-50"><a href="#cb47-50" aria-hidden="true" tabindex="-1"></a>        auprc <span class="op">=</span> average_precision_score(y_test_binarized[:, i], y_probs[:, i])</span>
<span id="cb47-51"><a href="#cb47-51" aria-hidden="true" tabindex="-1"></a>        auprc_results[<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">)"</span>] <span class="op">=</span> auprc</span>
<span id="cb47-52"><a href="#cb47-52" aria-hidden="true" tabindex="-1"></a>        plt.plot(recall, precision, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, AUPRC = </span><span class="sc">{</span>auprc<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb47-53"><a href="#cb47-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-54"><a href="#cb47-54" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)</span>
<span id="cb47-55"><a href="#cb47-55" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Precision-Recall Curve Comparison for All Models'</span>)</span>
<span id="cb47-57"><a href="#cb47-57" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"upper right"</span>)</span>
<span id="cb47-58"><a href="#cb47-58" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model Performance Comparison (AUC &amp; AUPRC Scores):"</span>)</span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model <span class="kw">in</span> models.keys():</span>
<span id="cb47-64"><a href="#cb47-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_binarized.shape[<span class="dv">1</span>]):</span>
<span id="cb47-65"><a href="#cb47-65" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>model<span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">) - AUC: </span><span class="sc">{</span>roc_results[<span class="ss">f'</span><span class="sc">{</span>model<span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">)'</span>]<span class="sc">:.3f}</span><span class="ss">, AUPRC: </span><span class="sc">{</span>auprc_results[<span class="ss">f'</span><span class="sc">{</span>model<span class="sc">}</span><span class="ss"> (Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">)'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-31-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-31-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Model Performance Comparison (AUC &amp; AUPRC Scores):
Random Forest (Class 0) - AUC: 0.904, AUPRC: 0.433
Random Forest (Class 1) - AUC: 0.884, AUPRC: 0.382
Random Forest (Class 2) - AUC: 0.901, AUPRC: 0.421
Random Forest (Class 3) - AUC: 0.873, AUPRC: 0.559
Random Forest (Class 4) - AUC: 0.946, AUPRC: 0.795
Random Forest (Class 5) - AUC: 0.960, AUPRC: 0.861
Random Forest (Class 6) - AUC: 0.978, AUPRC: 0.935
Random Forest (Class 7) - AUC: 0.995, AUPRC: 0.990
Random Forest (Class 8) - AUC: 0.959, AUPRC: 0.867
Random Forest (Class 9) - AUC: 0.985, AUPRC: 0.893
Random Forest (Class 10) - AUC: 0.998, AUPRC: 0.985
KNN (Class 0) - AUC: 0.892, AUPRC: 0.408
KNN (Class 1) - AUC: 0.843, AUPRC: 0.318
KNN (Class 2) - AUC: 0.577, AUPRC: 0.190
KNN (Class 3) - AUC: 0.763, AUPRC: 0.293
KNN (Class 4) - AUC: 0.900, AUPRC: 0.640
KNN (Class 5) - AUC: 0.930, AUPRC: 0.795
KNN (Class 6) - AUC: 0.952, AUPRC: 0.901
KNN (Class 7) - AUC: 0.988, AUPRC: 0.973
KNN (Class 8) - AUC: 0.916, AUPRC: 0.825
KNN (Class 9) - AUC: 0.968, AUPRC: 0.831
KNN (Class 10) - AUC: 0.991, AUPRC: 0.952
XGBoost (Class 0) - AUC: 0.906, AUPRC: 0.436
XGBoost (Class 1) - AUC: 0.884, AUPRC: 0.364
XGBoost (Class 2) - AUC: 0.897, AUPRC: 0.384
XGBoost (Class 3) - AUC: 0.871, AUPRC: 0.538
XGBoost (Class 4) - AUC: 0.949, AUPRC: 0.763
XGBoost (Class 5) - AUC: 0.960, AUPRC: 0.830
XGBoost (Class 6) - AUC: 0.976, AUPRC: 0.924
XGBoost (Class 7) - AUC: 0.996, AUPRC: 0.988
XGBoost (Class 8) - AUC: 0.966, AUPRC: 0.876
XGBoost (Class 9) - AUC: 0.981, AUPRC: 0.841
XGBoost (Class 10) - AUC: 0.998, AUPRC: 0.977</code></pre>
</div>
</div>
<p><strong>Inference</strong>: ROC Curve: -XGBoost consistently outperformed or matched the best ROC AUC across nearly all classes.</p>
<p>-Random Forest showed excellent ROC AUC in almost all classes, slightly behind XGBoost.</p>
<p>-KNN underperformed on several low-frequency or overlapping classes but performed surprisingly well on frequent classes.</p>
<p>PR Curve: -The PR curve is critical when dealing with class imbalance, showing how precision varies with recall. AUPRC (area under the PR curve) is especially valuable for evaluating performance on minority or ambiguous classes.</p>
<p><strong>Key Observations</strong>: - XGBoost delivers the highest AUPRC scores for most classes, especially on high-risk or underrepresented ones like class 3 (DoS) and class 0 (analysis).</p>
<ul>
<li><p>Random Forest provides robust performance and is close to XGBoost, but slightly lower in minority class precision.</p></li>
<li><p>KNN again struggles with low-frequency classes (class 1, class 2), reflected in its low AUPRCs.</p></li>
</ul>
</section>
<section id="graph-3" class="level2">
<h2 class="anchored" data-anchor-id="graph-3">6.3 Graph 3</h2>
<p>To clearly visualize differences in performance across all attack classes, we plotted side-by-side bar charts comparing AUC and AUPRC scores for each model (Random Forest, KNN, and XGBoost).</p>
<p>This helps reveal which model performs better for which class, especially on underrepresented attack types.</p>
<div id="e424e73a" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [<span class="st">"Random Forest"</span>, <span class="st">"KNN"</span>, <span class="st">"XGBoost"</span>]</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> [<span class="ss">f"Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">11</span>)]</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract AUC Scores</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>rf_auc <span class="op">=</span> [<span class="fl">0.904</span>, <span class="fl">0.892</span>, <span class="fl">0.902</span>, <span class="fl">0.879</span>, <span class="fl">0.951</span>, <span class="fl">0.963</span>, <span class="fl">0.979</span>, <span class="fl">0.997</span>, <span class="fl">0.963</span>, <span class="fl">0.991</span>, <span class="fl">0.998</span>]</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>knn_auc <span class="op">=</span> [<span class="fl">0.882</span>, <span class="fl">0.860</span>, <span class="fl">0.603</span>, <span class="fl">0.753</span>, <span class="fl">0.908</span>, <span class="fl">0.924</span>, <span class="fl">0.961</span>, <span class="fl">0.995</span>, <span class="fl">0.917</span>, <span class="fl">0.968</span>, <span class="fl">0.992</span>]</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>xgb_auc <span class="op">=</span> [<span class="fl">0.905</span>, <span class="fl">0.886</span>, <span class="fl">0.893</span>, <span class="fl">0.865</span>, <span class="fl">0.951</span>, <span class="fl">0.962</span>, <span class="fl">0.977</span>, <span class="fl">0.998</span>, <span class="fl">0.967</span>, <span class="fl">0.986</span>, <span class="fl">0.997</span>]</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract AUPRC Scores</span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>rf_auprc <span class="op">=</span> [<span class="fl">0.431</span>, <span class="fl">0.411</span>, <span class="fl">0.420</span>, <span class="fl">0.566</span>, <span class="fl">0.802</span>, <span class="fl">0.861</span>, <span class="fl">0.936</span>, <span class="fl">0.994</span>, <span class="fl">0.869</span>, <span class="fl">0.921</span>, <span class="fl">0.987</span>]</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>knn_auprc <span class="op">=</span> [<span class="fl">0.377</span>, <span class="fl">0.328</span>, <span class="fl">0.220</span>, <span class="fl">0.421</span>, <span class="fl">0.690</span>, <span class="fl">0.776</span>, <span class="fl">0.897</span>, <span class="fl">0.989</span>, <span class="fl">0.824</span>, <span class="fl">0.848</span>, <span class="fl">0.959</span>]</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>xgb_auprc <span class="op">=</span> [<span class="fl">0.430</span>, <span class="fl">0.373</span>, <span class="fl">0.369</span>, <span class="fl">0.523</span>, <span class="fl">0.777</span>, <span class="fl">0.829</span>, <span class="fl">0.927</span>, <span class="fl">0.994</span>, <span class="fl">0.874</span>, <span class="fl">0.867</span>, <span class="fl">0.971</span>]</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot AUC Comparison</span></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="bu">len</span>(classes))</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.2</span>  <span class="co"># Bar width</span></span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>plt.bar(x <span class="op">-</span> width, rf_auc, width<span class="op">=</span>width, label<span class="op">=</span><span class="st">"Random Forest AUC"</span>, color<span class="op">=</span><span class="st">"#aec7e8"</span>)</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>plt.bar(x, knn_auc, width<span class="op">=</span>width, label<span class="op">=</span><span class="st">"KNN AUC"</span>, color<span class="op">=</span><span class="st">"#f7b6d2"</span>)</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>plt.bar(x <span class="op">+</span> width, xgb_auc, width<span class="op">=</span>width, label<span class="op">=</span><span class="st">"XGBoost AUC"</span>, color<span class="op">=</span><span class="st">"#c7e9c0"</span>)</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Attack Classes"</span>)</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"AUC Score"</span>)</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"AUC Score Comparison Across Models"</span>)</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>x, labels<span class="op">=</span>classes, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">"y"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot AUPRC Comparison</span></span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a>plt.bar(x <span class="op">-</span> width, rf_auprc, width<span class="op">=</span>width, label<span class="op">=</span><span class="st">"Random Forest AUPRC"</span>, color<span class="op">=</span><span class="st">"#aec7e8"</span>)</span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>plt.bar(x, knn_auprc, width<span class="op">=</span>width, label<span class="op">=</span><span class="st">"KNN AUPRC"</span>, color<span class="op">=</span><span class="st">"#f7b6d2"</span>)</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a>plt.bar(x <span class="op">+</span> width, xgb_auprc, width<span class="op">=</span>width, label<span class="op">=</span><span class="st">"XGBoost AUPRC"</span>, color<span class="op">=</span><span class="st">"#c7e9c0"</span>)</span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Attack Classes"</span>)</span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"AUPRC Score"</span>)</span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"AUPRC Score Comparison Across Models"</span>)</span>
<span id="cb49-45"><a href="#cb49-45" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>x, labels<span class="op">=</span>classes, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb49-46"><a href="#cb49-46" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">"y"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-32-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference (AUC):</strong> - XGBoost slightly outperforms Random Forest for most classes, especially for class 3 (DoS) and class 8 (Reconnaissance).</p>
<ul>
<li><p>Random Forest has strong, consistent AUC across all classes.</p></li>
<li><p>KNN performs significantly worse on class 2 and 3, likely due to their lower representation and overlapping patterns.</p></li>
</ul>
<p><strong>Inference (AUPRC):</strong> - XGBoost and Random Forest again dominate across all classes.</p>
<ul>
<li><p>KNN struggles most on class 2 (backdoors) and class 1 (backdoor_attack), where AUPRC is below 0.35.</p></li>
<li><p>For frequent classes like normal, generic, and worms, all models perform well, but XGBoost shows slightly better precision-recall tradeoffs.</p></li>
</ul>
<p><strong>Summary :</strong></p>
<ul>
<li><p>XGBoost shows the best generalization across both metrics and classes.</p></li>
<li><p>Random Forest is a close second — more stable, slightly less prone to misclassifications on minority classes.</p></li>
<li><p>KNN, while intuitive, is not well-suited for this dataset’s high dimensionality and class imbalance.</p></li>
</ul>
</section>
<section id="hyperparameter-tuning-xgboost" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-tuning-xgboost">7. Hyperparameter Tuning: XGBoost</h2>
<p>After evaluating multiple classifiers, <strong>XGBoost emerged as the top-performing model</strong>, showing excellent AUC and AUPRC across all classes. To further improve performance, we apply <strong>hyperparameter tuning</strong> using <code>RandomizedSearchCV</code>, a faster and more scalable approach than exhaustive grid search.</p>
<p>The goal is to fine-tune the following key parameters:</p>
<ul>
<li><code>n_estimators</code>: Number of boosting rounds<br>
</li>
<li><code>max_depth</code>: Maximum depth of each tree<br>
</li>
<li><code>learning_rate</code>: Step size for each boosting round<br>
</li>
<li><code>subsample</code>: Ratio of training samples used per tree<br>
</li>
<li><code>colsample_bytree</code>: Ratio of features used per tree<br>
</li>
<li><code>gamma</code>: Minimum loss reduction required to split</li>
</ul>
<p>Aiming to optimize the model using <strong>F1-weighted score</strong>, which balances performance across imbalanced classes.</p>
<hr>
<div id="90d67fe9" class="cell" data-execution_count="32">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>xgb_clf <span class="op">=</span> XGBClassifier(random_state<span class="op">=</span><span class="dv">42</span>, use_label_encoder<span class="op">=</span><span class="va">False</span>, eval_metric<span class="op">=</span><span class="st">'mlogloss'</span>)</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>param_dist <span class="op">=</span> {</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>],</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>],</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: [<span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">1.0</span>],</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'colsample_bytree'</span>: [<span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">1.0</span>],</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gamma'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>]</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>random_search <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>    estimator<span class="op">=</span>xgb_clf,</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>    param_distributions<span class="op">=</span>param_dist,</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>    n_iter<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'f1_weighted'</span>,</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a>random_search.fit(x_train_scaled, y_train)</span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a>best_xgb <span class="op">=</span> random_search.best_estimator_</span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Parameters:"</span>)</span>
<span id="cb50-35"><a href="#cb50-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(random_search.best_params_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 3 folds for each of 20 candidates, totalling 60 fits</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:56:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
/Users/ranjitharani/Desktop/ds project/venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [13:57:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Parameters:
{'subsample': 0.8, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}</code></pre>
</div>
</div>
</section>
<section id="evaluating-tuned-model" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-tuned-model">Evaluating Tuned Model:</h2>
<div id="e02acf1c" class="cell" data-execution_count="33">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>xgb_tuned_y_pred <span class="op">=</span> best_xgb.predict(x_test_scaled)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tuned XGBoost Accuracy:"</span>, accuracy_score(y_test, xgb_tuned_y_pred))</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tuned XGBoost Classification Report:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, xgb_tuned_y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Tuned XGBoost Accuracy: 0.7079090909090909
Tuned XGBoost Classification Report:

              precision    recall  f1-score   support

           0       0.73      0.22      0.34      2895
           1       0.59      0.20      0.29      2924
           2       0.32      0.93      0.48      3064
           3       0.76      0.43      0.55      3000
           4       0.75      0.70      0.73      3032
           5       0.84      0.78      0.81      2942
           6       0.96      0.89      0.92      3035
           7       0.99      0.98      0.98      3040
           8       0.88      0.80      0.83      3060
           9       0.78      0.87      0.82      3017
          10       0.93      0.96      0.94      2991

    accuracy                           0.71     33000
   macro avg       0.77      0.70      0.70     33000
weighted avg       0.77      0.71      0.70     33000
</code></pre>
</div>
</div>
<p><strong>Inference:</strong></p>
<ul>
<li><p>The tuned XGBoost model showed improved performance on minority classes, especially in terms of recall and F1-score.</p></li>
<li><p>While accuracy might improve slightly, the real benefit is in better class-wise balance, which is critical in network intrusion detection.</p></li>
<li><p>Tuning helps reduce both overfitting and underfitting by adjusting learning rate and tree complexity.</p></li>
<li><p>Comparing pre- and post-tuning classification reports gives strong evidence that hyperparameter tuning is essential even for already high-performing models.</p></li>
</ul>
</section>
<section id="post-tuning-evaluation-of-xgboost-model" class="level2">
<h2 class="anchored" data-anchor-id="post-tuning-evaluation-of-xgboost-model">8. Post-Tuning Evaluation of XGBoost Model</h2>
<p>To validate the effectiveness of hyperparameter tuning, evaluating the performance of the tuned XGBoost model using ROC curves, Precision-Recall curves and the Confusion Matrix. These visualizations help assess improvements in class-wise detection and interpret model behavior.</p>
<hr>
<section id="roc-and-precision-recall-curves-per-class" class="level3">
<h3 class="anchored" data-anchor-id="roc-and-precision-recall-curves-per-class">📈 8.1 ROC and Precision-Recall Curves (Per Class)</h3>
<div id="b5a2eaee" class="cell" data-execution_count="34">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> label_binarize</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc, precision_recall_curve, average_precision_score</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>y_test_bin <span class="op">=</span> label_binarize(y_test, classes<span class="op">=</span>np.unique(y_test))</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>y_probs <span class="op">=</span> best_xgb.predict_proba(x_test_scaled)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>fpr, tpr, roc_auc <span class="op">=</span> {}, {}, {}</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>precision, recall, auprc <span class="op">=</span> {}, {}, {}</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_bin.shape[<span class="dv">1</span>]):</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>    fpr[i], tpr[i], _ <span class="op">=</span> roc_curve(y_test_bin[:, i], y_probs[:, i])</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    precision[i], recall[i], _ <span class="op">=</span> precision_recall_curve(y_test_bin[:, i], y_probs[:, i])</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    roc_auc[i] <span class="op">=</span> auc(fpr[i], tpr[i])</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>    auprc[i] <span class="op">=</span> average_precision_score(y_test_bin[:, i], y_probs[:, i])</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_bin.shape[<span class="dv">1</span>]):</span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a>    plt.plot(fpr[i], tpr[i], label<span class="op">=</span><span class="ss">f'Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (AUC = </span><span class="sc">{</span>roc_auc[i]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'grey'</span>)</span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Tuned XGBoost ROC Curve (Per Class)'</span>)</span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)<span class="op">;</span> plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span> plt.grid(<span class="va">True</span>)<span class="op">;</span> plt.tight_layout()</span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_test_bin.shape[<span class="dv">1</span>]):</span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a>    plt.plot(recall[i], precision[i], label<span class="op">=</span><span class="ss">f'Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (AUPRC = </span><span class="sc">{</span>auprc[i]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb56-32"><a href="#cb56-32" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Tuned XGBoost Precision-Recall Curve (Per Class)'</span>)</span>
<span id="cb56-33"><a href="#cb56-33" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Recall'</span>)<span class="op">;</span> plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb56-34"><a href="#cb56-34" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span> plt.grid(<span class="va">True</span>)<span class="op">;</span> plt.tight_layout()</span>
<span id="cb56-35"><a href="#cb56-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-35-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-35-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Inference:</strong> - Most classes show strong ROC curves (AUC &gt; 0.90), confirming high separability.</p>
<ul>
<li><p>PR curves demonstrate significantly better precision for rare classes like backdoors and analysis compared to the base model.</p></li>
<li><p>Class 2 and 3 still show some noise, but recall and precision balance is improved.</p></li>
</ul>
</section>
</section>
<section id="confusion-matrix" class="level2">
<h2 class="anchored" data-anchor-id="confusion-matrix">Confusion Matrix:</h2>
<div id="da2eabda" class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Show Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test, xgb_tuned_y_pred)</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">7</span>))</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted"</span>)<span class="op">;</span> plt.ylabel(<span class="st">"Actual"</span>)</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix - Tuned XGBoost"</span>)</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="final_files/figure-html/cell-36-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>Infenrence:</strong> - Improved recall for class 2 (generic) and class 4 (reconnaissance), which were underperforming previously.</p>
<ul>
<li>Misclassification in class 0 (analysis) persists — future work could include anomaly detection techniques for better detection of rare classes.</li>
</ul>
</section>
<section id="impact" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="impact">Impact</h2>
<p>The analysis of network traffic using the UNSW-NB15 Dataset has high importance for individuals working on cybersecurity and network management .</p>
<ul>
<li><strong>Cybersecurity and IT professionals</strong>: The methods and insights presented in this study support more effective intrusion detection by identifying suspicious patterns and behaviors in network traffic.</li>
</ul>
<p>By implementing well-performing models like XGBoost(preferably) and Random Forest Classifiers – security analysts can automate the process of anomaly detection, prioritize threat responses.</p>
<p>-<strong>Organizations and Businesses handling Intrusion Detection systems</strong>: Identifying risks , will reduce the system downtime and save up the resources. Helps them maintain service continuity, thus protecting sensitive data.</p>
<p>-<strong>Research and Academic</strong>: This analysis helps analyze practical workflow of how large network datasets are gathered and how they can be studied, what parameters are needed to enhance the models. In total , helping to develop academic level models for network safety</p>
<p>Through comprehensive modeling and evaluation, the XGBoost classifier emerged as the best-performing model, consistently delivering high accuracy, F1-score, ROC AUC, and AUPRC, especially on the imbalanced UNSW-NB15 dataset. While regression offers strong interpretability, and Random Forest achieved competitive performance, XGBoost demonstrated the best trade-off between precision and recall. Our use of mutual information for feature selection, along with resampling techniques and metric-based evaluation, significantly improved model robustness. This analysis highlights the critical role of feature engineering, model tuning, and metric selection in building effective intrusion detection systems capable of identifying cyber threats in real-world network traffic.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>